# 서울시 범죄 현황 분석

## 학습 목표

- 서울시 구별 범죄 발생과 검거율 지표 사용
- pandas pivot_table 사용법 학습
- Google Maps API 사용하여 지도 정보 획득
- Seaborn(시각화 라이브러리) 사용법 학습

---

## 서울시 경차서벌 범죄 발생과 검거율 데이터 분석
  
```
# csv 파일을 읽어서 데이터프레임으로 생성
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=',' # 천자리 구분자 지정 및 콤마 제외와 문자열을 정수로 변환 역할
    ,encoding='euc-kr'
)
crime_anal_police.head()

```
![image](https://github.com/user-attachments/assets/8bbc7bfc-f872-4847-ae99-7a8252ced58d)

---

## 구글 맵 API 사용해서 경찰서의 위치 정보 받아오기

```
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)
crime_anal_police['관서명'] # Series 오브젝트
```
![image](https://github.com/user-attachments/assets/5497d3fa-58fc-4c68-9c5d-9784e8a155d5)

```
#구글 map API
import googlemaps # 모듈이 없어서 실패를 한다.
```
![image](https://github.com/user-attachments/assets/07e5be75-481a-4853-a2cd-b984d8d3ecdc)

```
conda install googlemaps # conda로 설치할 때는 Anaconda의 레포지토리를 갖고 와서 실패 할수도 있다.
```
![image](https://github.com/user-attachments/assets/b4e77bd6-bf47-470d-92a2-92b100596d1e)

```
#실패시 아래 명령어를 실행하면 된다.
pip install googlemaps 
```
![image](https://github.com/user-attachments/assets/75b2c621-3484-4b5d-99ce-e65a8e8981a1)


```
import googlemaps # 모듈을 설치하여 성공
```

![image](https://github.com/user-attachments/assets/14929f1c-9028-4fc9-b970-34059cae1f2f)

```
# 구글 map API
# 구글 서버에 접속해서 데이터 요청할 수 있는 클라이언트 생성 처리
import googlemaps

# 클라이언트 생성만 한 것
# 실행 할때 에러가 발생하지 않을것이다.

gmaps_key ='구글 개인키'

gmaps = googlemaps.Client(key=gmaps_key)

# 서울중부경찰서 검색해서 주소 정보 추출
addr_list = gmaps.geocode(
    '서울중부경찰서' # 검색할 문자열
    , language='ko'
)

addr_list
```
![image](https://github.com/user-attachments/assets/108d5747-7577-4178-a6c8-83b151126a0a)

**개인키는 소중한 정보여서 아래 부터는 gmaps_key는 생략하겠습니다.**

```
# 구글 map API
# 구글 서버에 접속해서 데이터 요청할 수 있는 클라이언트 생성 처리

import googlemaps

# 클라이언트 생성만 한 것
# 실행 할때 에러가 발생하지 않을것이다.

gmaps = googlemaps.Client(key=gmaps_key)

# 서울중부경찰서 검색해서 주소 정보 추출
addr_list = gmaps.geocode(
    '서울중부경찰서' # 검색할 문자열
    , language='ko'
)

# 위 addr_list로 주소 추출
addr_list[0].get('formatted_address')
```
![image](https://github.com/user-attachments/assets/dad05856-342b-4003-9a6c-9ddacceff29a)

```
# 구글 map API
import googlemaps


gmaps = googlemaps.Client(key=gmaps_key)

addr_list = gmaps.geocode(
    '서울중부경찰서' 
    , language='ko'
)

addr_list[0].get('geometry')
```
![image](https://github.com/user-attachments/assets/e9119761-fe1a-43f4-93de-5c79b33cb399)

```
# 구글 map API
import googlemaps


gmaps = googlemaps.Client(key=gmaps_key)

addr_list = gmaps.geocode(
    '서울중부경찰서' 
    , language='ko'
)

addr_list[0].get('geometry')['location']
```
![image](https://github.com/user-attachments/assets/86e7c49e-0cd1-4c93-afe0-ea0c5081e93a)

```
# 구글 map API
import googlemaps


gmaps = googlemaps.Client(key=gmaps_key)

addr_list = gmaps.geocode(
    '서울중부경찰서' 
    , language='ko'
)

addr_list[0].get('geometry')['location']['lat']
```
![image](https://github.com/user-attachments/assets/965001bb-ebbb-4802-b02f-9aa368c1515d)

```
# 관서명 : 31개
# 중부서를 서울 중부 경찰서로 바꾸는 작업이 필요
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)
crime_anal_police['관서명'][0]
```
![image](https://github.com/user-attachments/assets/07df4db7-a34f-4c28-aaf9-3098e2fef3fe)

```
# 관서명 : 31개
# 중부서를 서울 중부 경찰서로 바꾸는 작업이 필요
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)

name = crime_anal_police['관서명'][0]


print('서울'+name[:-1]+'경찰서')

```
![image](https://github.com/user-attachments/assets/f9b5e7fe-3b45-4e09-86bc-8728321b2655)

```
# 관서명 : 31개
# 예를 들어 중부서를 서울 중부 경찰서로 바꾸는 작업이 필요
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)

# 1. 기존 관서명 (OO서) => 서울OO경찰서로 변경
station_name= [] # 변경된 관서명을 저장하는 리스트

for name in crime_anal_police['관서명']:
    station_name.append('서울'+name[:-1]+'경찰서')

station_name
```
![image](https://github.com/user-attachments/assets/35967cb7-99ee-4752-9774-34237b45f81b)

```
# 관서명 : 31개
# 예를 들어 중부서를 서울 중부 경찰서로 바꾸는 작업이 필요
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)

# 1. 기존 관서명 (OO서) => 서울OO경찰서로 변경
station_name= [] # 변경된 관서명을 저장하는 리스트

for name in crime_anal_police['관서명']:
    station_name.append('서울'+name[:-1]+'경찰서') #문자열 + 오브젝트+ 문자열 이어서 오류가 발생할 수 도 있다.

crime_anal_police['관서명'].dtype
```
![image](https://github.com/user-attachments/assets/1246e718-8350-4c3b-a093-640861ab87b0)

```
# 오류가 발생하면 아래와 같이 실행하면 된다.
import numpy as np
import pandas as pd

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)

# 1. 기존 관서명 (OO서) => 서울OO경찰서로 변경
station_name= [] # 변경된 관서명을 저장하는 리스트

for name in crime_anal_police['관서명']:
    station_name.append('서울'+str(name[:-1])+'경찰서')

station_name
```
![image](https://github.com/user-attachments/assets/1b586e44-b456-4bc1-9480-499f5922a36a)

```
import numpy as np
import pandas as pd
import googlemaps

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)

station_name= []

for name in crime_anal_police['관서명']:
    station_name.append('서울'+str(name[:-1])+'경찰서')

gmaps = googlemaps.Client(key=gmaps_key)

# 구글 map에서 3개 지도 정보 추출
# 전체 주소, 위도, 경도
# 위 정보를 저장하는 저장소 : list 
station_address=[]
station_lat=[]
station_lng=[]

for name in station_name: # name : 서울OOO경찰서 경찰서명이 31번 반복
    # 구글 지도 서버에 경찰서명 보내서 지도 정보를 받는다
    tmp = gmaps.geocode(
        name 
        , language='ko'
    )
    # 전체 정보 추출해서 station_address에 추가
    station_address.append(tmp[0].get('formatted_address'))
    # lat,lng 추출
    tmp_loc = tmp[0].get('geometry')
    station_lat.append(tmp_loc['location']['lat'])
    station_lng.append(tmp_loc['location']['lng'])
    
    # 경찰서 정보 출력 : 경찰서명, 전체 주소 출력
    print(name + '------>' + tmp[0].get('formatted_address'))
```
![image](https://github.com/user-attachments/assets/25c9a6d2-9e8f-4c4d-a154-7c2dcecfa4eb)

```
import pickle

with open('./data/station_address.pickle','wb') as f:
    pickle.dump(station_address,f)

with open('./data/station_lat.pickle','wb') as f:
    pickle.dump(station_lat,f)

with open('./data/station_lng.pickle','wb') as f:
    pickle.dump(station_lng,f)

```
![image](https://github.com/user-attachments/assets/8ac1c5cd-5030-4e6e-ba90-868803e807ad)

```
# 전체 주소에서 구를 추출

gu='대한민국 서울특별시 성북구 보문로 170'

print(gu.split()) #전체 주소를 공백으로 분리 리스트 변환

print('----------------------------------------------------')
for addr in gu.split():
    if addr[-1] =='구':
        print(addr)
```
![image](https://github.com/user-attachments/assets/887a7542-2906-4c1c-b5a3-fb2a655c755a)

```
import numpy as np
import pandas as pd
import googlemaps

crime_anal_police = pd.read_csv(
    './data/02. crime_in_Seoul.csv'
    , thousands=','
    ,encoding='euc-kr'
)

station_name= []

for name in crime_anal_police['관서명']:
    station_name.append('서울'+str(name[:-1])+'경찰서')

gmaps = googlemaps.Client(key=gmaps_key)

station_address=[]
station_lat=[]
station_lng=[]

for name in station_name: 
    tmp = gmaps.geocode(
        name 
        , language='ko'
    )
    # 전체 정보 추출해서 station_address에 추가
    station_address.append(tmp[0].get('formatted_address'))
    # lat,lng 추출
    tmp_loc = tmp[0].get('geometry')
    station_lat.append(tmp_loc['location']['lat'])
    station_lng.append(tmp_loc['location']['lng'])
    
gu_name = []
for addr in station_address:
    addr_split = addr.split()
    for gu in addr_split:
        if gu[-1] =='구':
            gu_name.append(gu)
                
crime_anal_police['구별'] = gu_name
crime_anal_police.head()
```
![image](https://github.com/user-attachments/assets/a346f66c-555c-427c-8176-8e643e9e3bf4)

```
import numpy as np
import pandas as pd
# 현재까지 처리한 결과를 파일에 저장 -> csv file
crime_anal_police.to_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,sep=',' # 파일 저장시 데이터 구분 무엇으로 할 것인지 지정 default ','
    , encoding='utf-8'
)
```
![image](https://github.com/user-attachments/assets/fdeced29-5fa8-461a-85d9-f5a7c6d8bdba)

---

## 판다스 pivot_table() 사용

```
import numpy as np
import pandas as pd

# 데이터 읽기
df = pd.read_excel(
    './data/02. sales-funnel.xlsx'
)
df
```
![image](https://github.com/user-attachments/assets/2538ac17-18e7-417d-9e18-161cd5e3ba11)

모듈이 존재하지 않아 오류가 발생한다.

```
conda install openpyxl
```
![image](https://github.com/user-attachments/assets/260306fd-33b0-4180-86f2-10ea90149a59)

설치가 완료되면 아래 명령이 잘 실행이 된 것을 알 수가 있다.
```
import numpy as np
import pandas as pd

# 데이터 읽기
df = pd.read_excel(
    './data/02. sales-funnel.xlsx'
)
df
```
![image](https://github.com/user-attachments/assets/9d48517b-125a-4510-b503-fe07125f2dce)

예제 데이터
```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}
df = pd.DataFrame(data)
df
```
![image](https://github.com/user-attachments/assets/ee274021-d6a5-4df1-b00c-cd872488fccd)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜 기준으로 도시별 매출 합계를 피벗 테이블로 생성

pivot = pd.pivot_table(
    data=df
    , values='매출'
    , index='날짜'
    ,columns='도시'
    ,aggfunc='sum'
)

pivot
```
![image](https://github.com/user-attachments/assets/201104a1-ad7b-403a-920f-c118d68d7e24)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜 기준으로 도시별 매출 합계를 피벗 테이블로 생성

pivot = pd.pivot_table(
    data=df
    , values='매출'
    , index='날짜'
    ,columns='도시'
    ,aggfunc='sum'
    ,fill_value=0 # NaN 인 값을 0으로 바꾼다
)

pivot
```
![image](https://github.com/user-attachments/assets/e77623b8-0886-4e38-bdfe-f56b075af63d)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜 기준으로 도시별 판매량 합계와 매출 평균을 피벗 테이블로 생성

pivot_multi = pd.pivot_table(
    data=df
    , values=['판매량','매출']
    , index='날짜'
    ,columns='도시'
    ,aggfunc={
        '판매량':'sum'
        ,'매출' :'mean'
        }
    ,fill_value=0 
)

pivot_multi
```
![image](https://github.com/user-attachments/assets/06a28045-9222-4071-a4e0-ad618047d766)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜별 도시별 매출의 합계를 구하고, 총계를 표시

pivot_margin = pd.pivot_table(
    data=df
    , values='매출'
    , index='날짜'
    ,columns='도시'
    ,aggfunc='sum'
    ,fill_value=0 
    ,margins=True
    ,margins_name='총계'
)

pivot_margin
```
![image](https://github.com/user-attachments/assets/92641521-84d4-4305-aeb1-836c142e88ee)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜별 도시별 매출의 합계를 구하는데 index로 날짜랑 도시를 지정
# 다중 인덱스 처리

pivot_multi_index = pd.pivot_table(
    data=df
    , values='매출'
    , index=['날짜','도시']
    ,aggfunc='sum'
)

pivot_multi_index
```
![image](https://github.com/user-attachments/assets/09dd5c5a-98f9-4209-8c71-1d13f5f7c813)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# sum, mean, count, max, min 등은 aggfunc에 만들어져있는 함수인데 이외를 사용하고 싶으면 lambda를 사용해서 새로운 함수를 생성
# 예제 : 도시별(인덱스) 판매량의 중간값 적용



pivot_custom_func = pd.pivot_table(
    data=df
    , values='판매량'
    , index='도시'
    ,aggfunc=np.median
)

pivot_custom_func
```
![image](https://github.com/user-attachments/assets/ff6713f7-8cad-4884-96e0-ab72f3d8f238)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# sum, mean, count, max, min 등은 aggfunc에 만들어져있는 함수인데 이외를 사용하고 싶으면 lambda를 사용해서 새로운 함수를 생성
# 예제 : 도시별(인덱스) 판매량의 중간값 적용



pivot_custom_lambda_func = pd.pivot_table(
    data=df
    , values='판매량'
    , index='도시'
    ,aggfunc=lambda x: x.median()
)

pivot_custom_lambda_func
```
![image](https://github.com/user-attachments/assets/7c22dc0a-3799-4f3c-8f51-9238816b9f59)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜별 도시별 매출 합



pivot_test = pd.pivot_table(
    data=df
    , values='매출'
    , index='날짜'
    , columns='도시'
    ,aggfunc= lambda x : x.sum()
)

pivot_test
```
![image](https://github.com/user-attachments/assets/fd06030d-af7c-4ead-8352-fc0b84f860da)

```
import numpy as np
import pandas as pd

data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울'],
    '판매량': [100, 200, 150, 250, 300],
    '매출': [1000, 2000, 1500, 2500, 3000]
}


df = pd.DataFrame(data)

# pivot_table 사용한 주 이유 : 데이터 그룹화하고 특정 컬럼을 기준으로 집계하여 새로운 형태의 데이터프레임 생성
# pivot_table()의 주요 매개변수 설명
# pd.pivot_table(data,                  => DataFrame object
#                values=None,           => 집계할 컬럼 지정(여러개 지정 가능)
#                index=None,            => 행 인덱스로 사용할 컬럼 지정
#                columns=None,          => 컬럼으로 사용할 컬럼 지정
#                aggfunc='mean',        => 적용할 집계함수 (기본값 : mean)
#                fill_value=None,       => 결측값(NaN)을 대체할 값 지정
#                margins=False,         => 총합/평균 등의 요약 행과 열 추가
#                margins_name='All',    => 추가된 이름 부여
#                dropna=True)           => NaN 값이 들어있는 칼럼 삭제 여부 지정 (True : 삭제, False : 삭제 x)

# 예제 : 날짜별 도시별 매출 합

pivot_test = pd.pivot_table(
    data=df
    , values='매출'
    , index='날짜'
    , columns='도시'
    ,aggfunc= lambda x : x.sum()
    ,dropna=True # NaN 칼럼에 하나라도 값이 존재하면 칼럼이 삭제가 안된다.
)

pivot_test
```
![image](https://github.com/user-attachments/assets/5a5b4f7b-5a2a-4fa2-8dd2-e52d7def99d1)

```
import numpy as np
import pandas as pd


# 데이터 생성
data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울', '부산'],
    '판매량': [100, 200, 150, 250, 300, 100],
    '매출': [1000, 2000, 1500, 2500, 3000, 800]
}


df = pd.DataFrame(data)

# aggfunc 적용시 여러 개의 집계 함수 사용

# 예제 : 도시별 판매량의 합계, 평균, 개수와 매출액의 합계, 평균, 개수 구하기


pivot_aggfunc_test = pd.pivot_table(
    data=df
    , values=['판매량','매출']
    , index='도시'
    ,aggfunc= {
        '판매량' : ['sum','mean','count']
        ,'매출' : ['sum','mean','count']
    }
)

pivot_aggfunc_test
```
![image](https://github.com/user-attachments/assets/74dff66f-b6b1-48e4-8c60-64fe73a74444)

```
import numpy as np
import pandas as pd


# 데이터 생성
data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울', '부산'],
    '판매량': [100, 200, 150, 250, 300, 100],
    '매출': [1000, 2000, 1500, 2500, 3000, 800]
}


df = pd.DataFrame(data)


# 예제 : 도시별 매출 합

# pivot

pivot_sum=pd.pivot_table(
    data=df
    ,values='매출'
    ,index='도시'
    ,aggfunc='sum'
)


print('-------------------------------------------------')
print('피벗  결과 \n',pivot_sum)
print('-------------------------------------------------')

# df.groupby('그룹핑할 컬럼들 지정 : list') => return DataFrameGroupBy 
print('groupby  결과 \n',df.groupby(['도시'])['매출'].sum())

# pivot은 column을 사용할 수 있고 DataFrame을 반환을 한다
# groupby는 column을 지정할 수 없고 그룹핑 컬럼이 인덱스로 지정이 된다. 시리즈로 반환이된다.
```
![image](https://github.com/user-attachments/assets/8f83bceb-d1ea-486c-b2a0-e7f8728d3c8d)

```
import numpy as np
import pandas as pd


# 데이터 생성
data = {
    '날짜': ['2024-03-01', '2024-03-01', '2024-03-02', '2024-03-02', '2024-03-03', '2024-03-03'],
    '도시': ['서울', '부산', '서울', '부산', '서울', '부산'],
    '판매량': [100, 200, 150, 250, 300, 100],
    '매출': [1000, 2000, 1500, 2500, 3000, 800]
}


df = pd.DataFrame(data)

print('groupby  결과 \n',df.groupby(['도시'])['매출'].sum()['서울'])
```
![image](https://github.com/user-attachments/assets/a6d398d5-d4da-4da1-9d70-f0cf69e65dda)

---

## 범죄 데이터 구별로 정리하기

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
)

crime_anal_raw.head()
```
![image](https://github.com/user-attachments/assets/c51da5e0-8524-4f2d-8c88-c84f82b08281)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal_raw.head()
```
![image](https://github.com/user-attachments/assets/94c8d3aa-ce0e-4047-86b8-a57fc2ea5d34)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal =pd.pivot_table(
    data=crime_anal_raw
    # , values = values를 생략하면 컬럼 전체 다 가져와라
    , index='구별'
    , aggfunc='sum' # 'sum' 대신 np.sum 써도 됨
)

crime_anal
```
![image](https://github.com/user-attachments/assets/95e0442e-8e56-406d-8594-e1fed0696512)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal =pd.pivot_table(
    data=crime_anal_raw
    , index='구별'
    , aggfunc=np.sum
)

# 검거율 구하기 : 구별로 비교를 위해
crime_anal['강간 검거율']=crime_anal['강간 검거']/crime_anal['강간 발생'] * 100
crime_anal['강도 검거율']=crime_anal['강도 검거']/crime_anal['강도 발생'] * 100
crime_anal['살인 검거율']=crime_anal['살인 검거']/crime_anal['살인 발생'] * 100
crime_anal['절도 검거율']=crime_anal['절도 검거']/crime_anal['절도 발생'] * 100
crime_anal['폭력 검거율']=crime_anal['폭력 검거']/crime_anal['폭력 발생'] * 100

# 검거 데이터 삭제
crime_anal.drop(labels='강간 검거',axis=1,inplace=True)
crime_anal.drop(labels='강도 검거',axis=1,inplace=True)
crime_anal.drop(labels='살인 검거',axis=1,inplace=True)
crime_anal.drop(labels='절도 검거',axis=1,inplace=True)
crime_anal.drop(labels='폭력 검거',axis=1,inplace=True)

# 관서명 삭제
del crime_anal['관서명']

crime_anal
```
![image](https://github.com/user-attachments/assets/b385c822-1c30-463d-9d62-6e8976806c01)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal = pd.pivot_table(
    data=crime_anal_raw,
    index='구별',
    aggfunc=np.sum
)

crime_types = ['강간', '강도', '살인', '절도', '폭력']

# 검거율 구하기 : for문으로 처리
for crime in crime_types:
    crime_anal[f'{crime} 검거율'] = crime_anal[f'{crime} 검거'] / crime_anal[f'{crime} 발생'] * 100

# 검거 데이터 삭제 : for문으로 처리
for crime in crime_types:
    crime_anal.drop(labels=f'{crime} 검거', axis=1, inplace=True)

# 관서명 삭제
del crime_anal['관서명']

crime_anal
```
![image](https://github.com/user-attachments/assets/6d43c3de-1daf-4da7-983d-c3c2a7b6141d)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal = pd.pivot_table(
    data=crime_anal_raw,
    index='구별',
    aggfunc=np.sum
)

crime_types = ['강간', '강도', '살인', '절도', '폭력']

# 검거율 구하기 : for문으로 처리
for crime in crime_types:
    crime_anal[f'{crime} 검거율'] = crime_anal[f'{crime} 검거'] / crime_anal[f'{crime} 발생'] * 100

# 검거 데이터 삭제 : for문으로 처리
for crime in crime_types:
    crime_anal.drop(labels=f'{crime} 검거', axis=1, inplace=True)

# 관서명 삭제
del crime_anal['관서명']

# 검거율이 100보다 큰 값은 100으로 표기
col_list=crime_anal.columns[6:] # ['강도 검거율', '살인 검거율', '절도 검거율', '폭력 검거율'] 

for col in col_list:
    crime_anal.loc[crime_anal[col]>100,col] = 100
crime_anal
```
![image](https://github.com/user-attachments/assets/3c706ee4-5df7-4b59-9f97-b82fa7829584)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal = pd.pivot_table(
    data=crime_anal_raw,
    index='구별',
    aggfunc=np.sum
)

crime_types = ['강간', '강도', '살인', '절도', '폭력']

# 검거율 구하기 : for문으로 처리
for crime in crime_types:
    crime_anal[f'{crime}검거율'] = crime_anal[f'{crime} 검거'] / crime_anal[f'{crime} 발생'] * 100

# 검거 데이터 삭제 : for문으로 처리
for crime in crime_types:
    crime_anal.drop(labels=f'{crime} 검거', axis=1, inplace=True)

# 관서명 삭제
del crime_anal['관서명']

# 검거율이 100보다 큰 값은 100으로 표기
col_list=crime_anal.columns[6:] # ['강도검거율', '살인검거율', '절도검거율', '폭력검거율'] 

for col in col_list:
    crime_anal.loc[crime_anal[col]>100,col] = 100

# 컬럼여 단순화(변경)

crime_anal.rename(
    columns={
        '강간 발생' : '강간'
        ,'강도 발생' : '강도'
        ,'살인 발생' : '살인'
        ,'폭력 발생' : '폭력'
        ,'절도 발생' : '절도'      
    }
    ,inplace=True
)
crime_anal.head()
```
![image](https://github.com/user-attachments/assets/99cabaf7-1edf-4626-b430-920d93158bb3)

```
import numpy as np
import pandas as pd

crime_anal_raw = pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names.csv'
    ,encoding='utf-8'
    ,index_col=0
)

crime_anal = pd.pivot_table(
    data=crime_anal_raw,
    index='구별',
    aggfunc=np.sum
)

crime_types = ['강간', '강도', '살인', '절도', '폭력']

# 검거율 구하기 : for문으로 처리
for crime in crime_types:
    crime_anal[f'{crime}검거율'] = crime_anal[f'{crime} 검거'] / crime_anal[f'{crime} 발생'] * 100

# 검거 데이터 삭제 : for문으로 처리
for crime in crime_types:
    crime_anal.drop(labels=f'{crime} 검거', axis=1, inplace=True)

# 관서명 삭제
del crime_anal['관서명']

# 검거율이 100보다 큰 값은 100으로 표기
col_list=crime_anal.columns[6:] # ['강도검거율', '살인검거율', '절도검거율', '폭력검거율'] 

for col in col_list:
    crime_anal.loc[crime_anal[col]>100,col] = 100

# 컬럼여 단순화(변경)

crime_anal.rename(
    columns={
        '강간 발생' : '강간'
        ,'강도 발생' : '강도'
        ,'살인 발생' : '살인'
        ,'폭력 발생' : '폭력'
        ,'절도 발생' : '절도'      
    }
    ,inplace=True
)

# 지금 까지 처리한 내용 파일에 저장
crime_anal.to_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    ,encoding='utf-8'
)
```
![image](https://github.com/user-attachments/assets/f19b0d24-1ea0-4d0b-a91c-d7c3cc988aa2)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

print('최대 : ',max_)
print('최소 : ',min_)
```
![image](https://github.com/user-attachments/assets/9c80b5b9-c319-47f2-ae77-7d565ee5ea07)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

result_ =(22-min_)/(max_-min_)
print(result_)
```
![image](https://github.com/user-attachments/assets/121df0a2-1d94-4d22-890d-a75ead93b1fb)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)
print(result__)
```
![image](https://github.com/user-attachments/assets/cf02df56-a569-4889-b034-80f57b8ae169)


분석을 위해서 `사이킷런 패키지`를 설치
- 머신러닝과 관련된 알고리즘과 유틸리티 포함된 패키지
- 패키지 : scikit-learn 패키지는 반드시 numpy와 scipy가 설치되어 있어야한다.
- conda/pip install sklearn
- conda/pip install scikit-learn

```
conda install sklearn  
```
![image](https://github.com/user-attachments/assets/a7178ea7-34c5-4500-a60e-429d82d0ab46)

위의 이미지 처럼 실패시 pip로 설치를 하면 된다.

```
pip install sklearn
```
![image](https://github.com/user-attachments/assets/655d141e-eff3-43b4-898d-52a08fc777b8)

위의 그림처럼 또 실패하면

```
conda install scikit-learn
```
![image](https://github.com/user-attachments/assets/ffceca83-8805-4751-aba1-d33183c163a7)

만약에 실패를 하면

```
pip install scikit-learn
```
으로 실행하면 된다.

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
crime_anal[cols_name].values
```
![image](https://github.com/user-attachments/assets/7802729b-b177-4543-b861-26ff70948f19)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

print(x_scaled)
```
![image](https://github.com/user-attachments/assets/6a6ba04c-63ac-4d15-a496-901984f4b6c2)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)
crime_anal_norm
```
![image](https://github.com/user-attachments/assets/1b1316f6-5425-4123-8bd4-257f45dd1fd7)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)
crime_anal_norm.describe()
```
![image](https://github.com/user-attachments/assets/5a61d621-4823-44e7-bf0b-2e15b9b1c4e6)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)

# 기존 crime_anal의 강간,강도,살인,절도,폭력 컬럼을 crime_anal_norm로 바꾸는 방법
# 1. 검거율 추출 : crime_anal
columns_=crime_anal.columns.to_list()[5:]

# 2. crime_anal_norm에 crime_anal의 검거율 추가
crime_anal_norm[columns_] = crime_anal[columns_]

crime_anal_norm
```
![image](https://github.com/user-attachments/assets/b99ed996-8529-4aba-97b4-6ecad6057b6f)

```
import numpy as np
import pandas as pd

# CCTV 인구현황 데이터 read

cctv = pd.read_csv(
    './data/01. CCTV_result.csv'
    , encoding='utf-8'
    ,index_col=0
)
cctv
```
![image](https://github.com/user-attachments/assets/c7da517c-191e-4613-9aa8-35ad3ad4c6b2)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)

# 기존 crime_anal의 강간,강도,살인,절도,폭력 컬럼을 crime_anal_norm로 바꾸는 방법
# 1. 검거율 추출 : crime_anal
columns_=crime_anal.columns.to_list()[5:]

# 2. crime_anal_norm에 crime_anal의 검거율 추가
crime_anal_norm[columns_] = crime_anal[columns_]


# CCTV 인구현황 데이터 read

cctv = pd.read_csv(
    './data/01. CCTV_result.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 범죄 현황과 cctv개수(소계), 인구수 통합한 데이터프레임(crime_anal_norm) 통합

crime_anal_norm[['인구수','소계']]=cctv[['인구수','소계']]

crime_anal_norm
```
![image](https://github.com/user-attachments/assets/3dcc02cd-33e9-47f4-a138-54cb9b290d9e)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)

# 기존 crime_anal의 강간,강도,살인,절도,폭력 컬럼을 crime_anal_norm로 바꾸는 방법
# 1. 검거율 추출 : crime_anal
columns_=crime_anal.columns.to_list()[5:]

# 2. crime_anal_norm에 crime_anal의 검거율 추가
crime_anal_norm[columns_] = crime_anal[columns_]


# CCTV 인구현황 데이터 read

cctv = pd.read_csv(
    './data/01. CCTV_result.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 범죄 현황과 cctv개수(소계), 인구수 통합한 데이터프레임(crime_anal_norm) 통합

crime_anal_norm[['인구수','소계']]=cctv[['인구수','소계']]

# 범죄 컬럼 생성하고 범죄 발생 합 대입
cols = ['강간','강도','살인','절도','폭력']

crime_anal_norm['범죄']=np.sum(
    crime_anal_norm[cols]
    ,axis=1
)

crime_anal_norm
```
![image](https://github.com/user-attachments/assets/4bff4ab6-f79f-4035-9f4d-e12168f15e70)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)

# 기존 crime_anal의 강간,강도,살인,절도,폭력 컬럼을 crime_anal_norm로 바꾸는 방법
# 1. 검거율 추출 : crime_anal
columns_=crime_anal.columns.to_list()[5:]

# 2. crime_anal_norm에 crime_anal의 검거율 추가
crime_anal_norm[columns_] = crime_anal[columns_]


# CCTV 인구현황 데이터 read

cctv = pd.read_csv(
    './data/01. CCTV_result.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 범죄 현황과 cctv개수(소계), 인구수 통합한 데이터프레임(crime_anal_norm) 통합

crime_anal_norm[['인구수','소계']]=cctv[['인구수','소계']]

# 범죄 컬럼 생성하고 범죄 발생 합 대입
cols = ['강간','강도','살인','절도','폭력']

crime_anal_norm['범죄']=np.sum(
    crime_anal_norm[cols]
    ,axis=1
)

# 검거 칼럼 생성, 검거율 합

cols_rate = ['강간검거율','강도검거율','살인검거율','절도검거율','폭력검거율']

crime_anal_norm['검거율']=np.sum(
    crime_anal_norm[cols_rate]
    ,axis=1
)

crime_anal_norm
```
![image](https://github.com/user-attachments/assets/6e375c63-af1f-4cc7-aa70-6e2a4a097d5e)

```
import numpy as np
import pandas as pd

crime_anal=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_names_in32.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 강도 컬럼으로 mimax scaling 처리 : 0-1 사이 값으로 변환
# 1. max, min 구한다
max_ = crime_anal['강도'].max()
min_ = crime_anal['강도'].min()

# 2. 구한 max, min으로 계산
result_ =(22-min_)/(max_-min_)
result__ =(5-min_)/(max_-min_)

#ModuleNotFoundError : pip install -U scikit-learn
from sklearn import preprocessing # 데이터 전처리 하는 클래스가 들어 있는 모델

#강간, 강도, 살인, 절도, 폭력에 대해서 0~1사이로 변경
cols_name=crime_anal.columns.tolist()[:5] # crime_anal.columns의 index 오브젝트를 list로 변환
# crime_anal[cols_name] # crime_anal[강간,강도,살인,절도,폭력]
x = crime_anal[cols_name].values # DataFrame에서 value만 추출 -> ndarray

# 정규화 (표준화) : 일정 범위로 만들겠다! -> 0~1 값으로 변환
# 1.MinMaxScalar() 클래스 -> 오브젝트 생성
min_max_scalar = preprocessing.MinMaxScaler()
# 2. 컬럼별 최대, 최소 구하기 : fit(x)

min_max_scalar.fit(x)

# 3. 변환 : transform() -> 변환된 값이 array로 반환
x_scaled=min_max_scalar.transform(x)

# 처리된 데이터로 데이터프레임 생성
crime_anal_norm = pd.DataFrame(
    data= x_scaled
    ,columns=cols_name
    ,index=crime_anal.index
)

# 기존 crime_anal의 강간,강도,살인,절도,폭력 컬럼을 crime_anal_norm로 바꾸는 방법
# 1. 검거율 추출 : crime_anal
columns_=crime_anal.columns.to_list()[5:]

# 2. crime_anal_norm에 crime_anal의 검거율 추가
crime_anal_norm[columns_] = crime_anal[columns_]


# CCTV 인구현황 데이터 read

cctv = pd.read_csv(
    './data/01. CCTV_result.csv'
    , encoding='utf-8'
    ,index_col=0
)

# 범죄 현황과 cctv개수(소계), 인구수 통합한 데이터프레임(crime_anal_norm) 통합

crime_anal_norm[['인구수','소계']]=cctv[['인구수','소계']]

# 범죄 컬럼 생성하고 범죄 발생 합 대입
cols = ['강간','강도','살인','절도','폭력']

crime_anal_norm['범죄']=np.sum(
    crime_anal_norm[cols]
    ,axis=1
)

# 검거 칼럼 생성, 검거율 합

cols_rate = ['강간검거율','강도검거율','살인검거율','절도검거율','폭력검거율']

crime_anal_norm['검거율']=np.sum(
    crime_anal_norm[cols_rate]
    ,axis=1
)

# 데이터프레임(오브젝트)를 파일에 저장 : pickle
import pickle

with open('./data/02.crime_anal_norm.pickle','wb') as f:
    pickle.dump(
        crime_anal_norm,f
    )
```
![image](https://github.com/user-attachments/assets/5418bdb8-7f62-4f25-b452-454ba193fe93)

```
import numpy as np
import pandas as pd
import pickle
# DataFrame object read
with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm_load = pickle.load(f)
    
crime_anal_norm_load
```
![image](https://github.com/user-attachments/assets/ba760258-85e2-4466-baa8-c1dd0448e3cd)

---

## seaborn library 시각화

```
conda install seaborn
```
![image](https://github.com/user-attachments/assets/b5ab2a3a-f362-439d-a994-c1ae74685983)

```
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

#시각화를 하기 위한 데이터 생성

# x = np.linspace(start,end,나눌구간값)
x = np.linspace(0,14,100)
y1 = np.sin(x)
y2 = 2*np.sin(x+0.5)
y3 = 3*np.sin(x+1.0)
y4 = 4*np.sin(x+1.5)
y5 = 5*np.sin(x+2.0)

plt.figure(figsize=(10,6))
plt.grid()
plt.plot(x,y1)
plt.plot(x,y2)
plt.plot(x,y3) 
plt.plot(x,y4)
plt.plot(x,y5)
plt.show()
```
![image](https://github.com/user-attachments/assets/9f6da0c2-4cd8-40bd-89ef-03c90cd8077b)

```
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

# x = np.linspace(start,end,나눌구간값)
x = np.linspace(0,14,100)
y1 = np.sin(x)
y2 = 2*np.sin(x+0.5)
y3 = 3*np.sin(x+1.0)
y4 = 4*np.sin(x+1.5)
y5 = 5*np.sin(x+2.0)

sns.set_style("ticks")
plt.figure(figsize=(10,6))

plt.plot(x,y1)
plt.plot(x,y2)
plt.plot(x,y3) 
plt.plot(x,y4)
plt.plot(x,y5)
sns.despine()
plt.show()
```
![image](https://github.com/user-attachments/assets/84f1204c-4961-4904-a4e7-002eacc35fbe)

```
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

# x = np.linspace(start,end,나눌구간값)
x = np.linspace(0,14,100)
y1 = np.sin(x)
y2 = 2*np.sin(x+0.5)
y3 = 3*np.sin(x+1.0)
y4 = 4*np.sin(x+1.5)
y5 = 5*np.sin(x+2.0)

sns.set_style("ticks")
plt.figure(figsize=(10,6))

plt.plot(x,y1)
plt.plot(x,y2)
plt.plot(x,y3) 
plt.plot(x,y4)
plt.plot(x,y5)
sns.despine(left=True)
plt.show()
```
![image](https://github.com/user-attachments/assets/fef61d94-617d-4a28-8f38-642eb00d91b3)

```
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

# x = np.linspace(start,end,나눌구간값)
x = np.linspace(0,14,100)
y1 = np.sin(x)
y2 = 2*np.sin(x+0.5)
y3 = 3*np.sin(x+1.0)
y4 = 4*np.sin(x+1.5)
y5 = 5*np.sin(x+2.0)

sns.set_style("ticks")
plt.figure(figsize=(10,6))

plt.plot(x,y1)
plt.plot(x,y2)
plt.plot(x,y3) 
plt.plot(x,y4)
plt.plot(x,y5)
sns.despine(left=True,bottom=True)
plt.show()
```
![image](https://github.com/user-attachments/assets/e179f4e9-176b-491e-a543-6784e8bd48df)

```
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

# x = np.linspace(start,end,나눌구간값)
x = np.linspace(0,14,100)
y1 = np.sin(x)
y2 = 2*np.sin(x+0.5)
y3 = 3*np.sin(x+1.0)
y4 = 4*np.sin(x+1.5)
y5 = 5*np.sin(x+2.0)

sns.set_style("ticks")
plt.figure(figsize=(10,6))

plt.plot(x,y1)
plt.plot(x,y2)
plt.plot(x,y3) 
plt.plot(x,y4)
plt.plot(x,y5)
sns.despine(left=True,bottom=True,right=False)
plt.show()
```
![image](https://github.com/user-attachments/assets/25758433-0824-4808-b4e7-aa40cdaa1106)

```
# 레스트랑 나온 데이터 : Tips data => seaborn lib 들어있다.
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

tips = sns.load_dataset('tips') #DataFrame return

tips.head()
```
![image](https://github.com/user-attachments/assets/eaef3db0-ef73-48ae-862a-fbc170110e5e)

### 데이터 시각화 목적

1. 데이터의 패턴 및 분포 파악
   - 데이터를 그래프로 표현하면 데이터의 특정 패턴(Trend), 분포(Distribution)을 쉽게 파악
   - ex) 히스토그램(Histogram Plot), KDE(Kernel Density Estimation)
2. 데이터의 관계(relationship) 분석
   - 두 개 이상의 변수 간 상관관계(Correlation) 또는 패턴을 시각적으로 분석
   - ex) 산점도(Scatter Plot) 사용
3. 이상치 탐지
   - 데이터셋 내에서 극단적인 값(이상치,outlier)을 찾아내는데 사용
     - 이상치는 모델의 성능을 저하시킨다. 탐지 후 제거 또는 보정 필요
   - 예 : 박스 플롯(Box Plot)
4. 데이터의 비교(그룹별 차이 분석)
   - 데이터를 그룹별로 비교하여 의미있는 차이가 있는지 분석
   - 예 : 그룹별 박스플롯(Box Plot)
5. 시계열 데이터 분석(Trend & Seasonality)
   - 데이터를 시간의 흐름에 따라 분석하여 트렌드(추세) 및 계절성 파악
   - 예 : 선그래프(Line plot)
6. 데이터의 구조 및 분포 이해(차원 축소)
   - 고차원 데이터(High-Dimensional Data) 분석할 때 데이터를 2D 또는 3D로 축소하여 시각화를 하여 분석할때 사용
   - 예 : PCA(주성분 분석)

### 데이터 시각화의 중요성
1. 데이터를 직관적으로 이해 가능
2. 패턴 및 관계 분석이 용이
3. 이상치 및 오류 탐지 가능
4. 데이터 비교 및 그룹 차이 분석 가능
5. 의사 결정에 도움을 준다
6. 머신런닝 모델의 성능 향상 가능
   
#### 산점도
```
#산점도
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.scatterplot(
    x='total_bill'
    , y='tip'
    , data=tips #DataFrame
)
plt.show()
```
![image](https://github.com/user-attachments/assets/6dc6a20c-fc34-4d84-a086-b3a2bd7770b4)

#### 히스토그램

```
#히스토그램 : 분포 확인
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.histplot(
    data=tips['total_bill']
    , bins= 20 # bins는 구간 설정 (20개 구간 구분)
    
)
plt.show()
```
![image](https://github.com/user-attachments/assets/f6cdaf1e-0a00-4b16-a499-6444893412ce)


```
#히스토그램 : 분포 확인
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.histplot(
    data=tips['total_bill']
    , bins= 20 # bins는 구간 설정 (20개 구간 구분)
    ,kde=True # 확률 밀도 곡선 표시
)
plt.show()
```
![image](https://github.com/user-attachments/assets/769100a0-ba20-48d6-8de6-a5dea2565d38)

#### 박스플롯 
1. 중앙값(Median) : 박스 안의 가로선이 중앙값(중위수)
   - 데이터의 중앙값을 의미, 50%의 데이터가 이 값보다 크거나 값다
2. 사분위수수
   - Q1(1사분위수, 25%) : 박스의 아래 경계(데이터의 25%가 이 값보다 작음 의미)
   - Q3(3사분위수, 75%) : 박스의 위쪽 경계(데이터의 75%가 이 값보다 작음 의미)
   - 박스의 높이 : IQR(Interquartile Range)
     - IQR = Q3 - Q1 (데이터의 중간 50%를 포함하는 범위)
3. 수염(Whiskers) => 이상치 제외
   - 최소값 : Q1 -(1.5 X IQR) 보다 크거나 같은 데이터 중 가장 작은 값
   - 최대값 : Q3 +(1.5 X IQR) 보다 작거나 같은 데이터 중 가장 큰 값
   - 수염은 일반적으로 이상치가 아닌 데이터의 최소값과 최대값을 연결하는 선
4. 이상치
   - 이상치는 수염 바깥에 위치한 데이터 포인터(점)
   - 이상치는 점으로 표시
   - 
```
# 박스 플롯 : 이상치 (극단값), 분포 확인시 사용
# 요일별(day), 전체 비용(total_bill)

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.boxplot(
    data=tips
    , x='day'
    ,y='total_bill'
)
plt.show()
```
![image](https://github.com/user-attachments/assets/11896355-0919-4e8d-9e12-271863f829a7)


#### 관계 그래프
```
# 관계 그래프(Pair Plot) : 모든 수치를 데이터의 관계를 한번에 확인
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.pairplot(
    data=tips
    ,hue = 'sex' # xxx별 -> 성별
)
plt.show()
```
![image](https://github.com/user-attachments/assets/32836f08-14be-4653-a14d-f2ba75be5129)

```
# 관계 그래프(Pair Plot) : 모든 수치를 데이터의 관계를 한번에 확인
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.pairplot(
    data=tips
    ,hue = 'day' # xxx별 -> 일별
)
plt.show()
```
![image](https://github.com/user-attachments/assets/b5da8419-3f58-4933-a687-e68692f4c3d8)

```
# 관계 그래프(Pair Plot) : 모든 수치를 데이터의 관계를 한번에 확인
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

plt.figure(figsize=(8,6))

tips = sns.load_dataset('tips') #DataFrame return
sns.pairplot(
    data=tips
    ,hue = 'smoker' # xxx별 -> 담배피는여부
)
plt.show()
```
![image](https://github.com/user-attachments/assets/c2873e5d-9f40-46b5-bf41-38607b4530af)

#### 히트맵
tips 데이터프레임에서 수치데이터(total_bill, tip,size)
상관관계를 구하기 : 데이터프레임에 `corr()` 메소드 사용

```
# 히트맵 
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

tips = sns.load_dataset('tips') #DataFrame return

corr_=tips[['total_bill','tip','size']].corr()

corr_
```
![image](https://github.com/user-attachments/assets/e65a4e24-7183-4278-a73c-2121d4d01d76)

```
# 히트맵 
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

tips = sns.load_dataset('tips') #DataFrame return

corr_=tips[['total_bill','tip','size']].corr()

plt.figure(figsize=(8,6))

sns.heatmap(
    data=corr_
)

plt.show()
```
![image](https://github.com/user-attachments/assets/198fedc2-4228-430d-a446-744b9bc83031)

```
# 히트맵 
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

tips = sns.load_dataset('tips') #DataFrame return

corr_=tips[['total_bill','tip','size']].corr()

plt.figure(figsize=(8,6))

sns.heatmap(
    data=corr_
    ,annot=True
)

plt.show()
```
![image](https://github.com/user-attachments/assets/8bc83a52-0de9-4ffa-b1cd-00902abbb1e7)

```
# 히트맵 
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

flights = sns.load_dataset("flights")

# DataGrame.pivot(인덱스에 들어갈 값, 컬럼에 들어갈 값, 값)
flights = flights.pivot(
    index ='month'
    ,columns='year'
    ,values='passengers'
)

flights
```
![image](https://github.com/user-attachments/assets/3fa6b1d5-6e55-4509-b728-61e56d0ff0e1)

```
# 히트맵 
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

flights = sns.load_dataset("flights")

# DataGrame.pivot(인덱스에 들어갈 값, 컬럼에 들어갈 값, 값)
flights = flights.pivot(
    index ='month'
    ,columns='year'
    ,values='passengers'
)

plt.figure(figsize=(10,8))
sns.heatmap(
    flights
    ,annot=True
    )
plt.show()
```
![image](https://github.com/user-attachments/assets/82c66083-f25e-4147-a7be-5629387a7471)

```
# 히트맵 
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

flights = sns.load_dataset("flights")

# DataGrame.pivot(인덱스에 들어갈 값, 컬럼에 들어갈 값, 값)
flights = flights.pivot(
    index ='month'
    ,columns='year'
    ,values='passengers'
)

plt.figure(figsize=(10,8))
sns.heatmap(
    flights
    ,annot=True
    ,fmt='d'
    )
plt.show()
```
![image](https://github.com/user-attachments/assets/c03a3454-0016-4672-adbe-0c102d6b15a7)

#### 라인 플롯
```
# Line Plot
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

fmri = sns.load_dataset("fmri")
plt.figure(figsize=(10,8))
sns.lineplot(
    data=fmri
    , x='timepoint'
    ,y='signal'
    , hue='event'    
)
plt.show()
```
![image](https://github.com/user-attachments/assets/79a20cd4-ac8d-48ff-93df-a7c9bd8ecc80)

```
# Line Plot
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

fmri = sns.load_dataset("fmri")
plt.figure(figsize=(10,8))
sns.lineplot(
    data=fmri
    , x='timepoint'
    ,y='signal'
    , hue='event'
    ,style='region'
)
plt.show()
```
![image](https://github.com/user-attachments/assets/27ff58da-3f0b-4a81-af86-7933abc1277b)

#### 색상 테마 설정

```
# 색상 테마 설정
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

tips = sns.load_dataset('tips')
plt.figure(figsize=(10,8))

sns.histplot(
    data=tips['total_bill']
    , bins=20
    , kde=True
)
plt.show()
```
![image](https://github.com/user-attachments/assets/c1796078-e8c6-4672-85d4-ce9f96bae288)

```
# 색상 테마 설정
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

tips = sns.load_dataset('tips')
plt.figure(figsize=(10,8))

sns.set_palette('deep')
sns.histplot(
    data=tips['total_bill']
    , bins=20
    , kde=True
)
plt.show()
```
![image](https://github.com/user-attachments/assets/567b7bb2-f854-406b-9492-61abd26a3080)

---
## 범죄 현황 데이터 정리

```
# 범죄 현황 데이터 정리
# 1. 검거 데이터 값을 표준화 처리
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns


with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
crime_anal_norm
```
![image](https://github.com/user-attachments/assets/cc1cfc4c-66c4-4e07-a43f-611c69c42faa)

```
# 검거 ( 검거율의 합) 정규화(표준화)
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns


with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
crime_anal_norm

tmp_max = crime_anal_norm['검거율'].max()
tmp_max
```
![image](https://github.com/user-attachments/assets/3b00e893-8aaf-4de1-b680-4f7a35ccc2bf)

```
# 검거 ( 검거율의 합) 정규화(표준화)
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns


with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
tmp_max = crime_anal_norm['검거율'].max()

# tmp_max 가 분모
crime_anal_norm['검거율'] = crime_anal_norm['검거율'] / tmp_max * 100  # 시각화를 위해 백분율로 변환

crime_anal_norm
```
![image](https://github.com/user-attachments/assets/c814e296-5766-4f3d-bec1-bc9101a4ab9d)

```
# 검거 ( 검거율의 합) 정규화(표준화)
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns


with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
tmp_max = crime_anal_norm['검거율'].max()

# tmp_max 가 분모
crime_anal_norm['검거율'] = crime_anal_norm['검거율'] / tmp_max * 100

# 검거율 기준 정렬 : DESC -> 새로운 변수로 저장
crime_anal_norm_sort=crime_anal_norm.sort_values(
    by = '검거율'
    , ascending = False
)
crime_anal_norm_sort
```
![image](https://github.com/user-attachments/assets/b1b0a6e3-f556-4cc0-bbce-35ff53f7c082)

```
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

import matplotlib as mpl
from matplotlib import rcParams # matplotlib 환경설정 모듈
rcParams['font.family'] = 'Malgun Gothic' # 한글 글꼴 설정
rcParams['axes.unicode_minus'] = False

with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
tmp_max = crime_anal_norm['검거율'].max()

crime_anal_norm['검거율'] = crime_anal_norm['검거율'] / tmp_max * 100

crime_anal_norm_sort=crime_anal_norm.sort_values(
    by = '검거율'
    , ascending = False
)

# 검거율을 히트맵으로 시각화

target_cols=crime_anal_norm_sort.columns.to_list()[5:10]
plt.figure(figsize=(6,5))

sns.heatmap(
    data=crime_anal_norm_sort[target_cols]
)

plt.title('범죄 검거 비율(정규화된 검거의 합으로 정렬)')
plt.show()
```
![image](https://github.com/user-attachments/assets/799f0b84-a874-4d50-8c5b-2b5f6f365c55)

```
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

import matplotlib as mpl
from matplotlib import rcParams # matplotlib 환경설정 모듈
rcParams['font.family'] = 'Malgun Gothic' # 한글 글꼴 설정
rcParams['axes.unicode_minus'] = False

with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
tmp_max = crime_anal_norm['검거율'].max()

crime_anal_norm['검거율'] = crime_anal_norm['검거율'] / tmp_max * 100

crime_anal_norm_sort=crime_anal_norm.sort_values(
    by = '검거율'
    , ascending = False
)

# 검거율을 히트맵으로 시각화

target_cols=crime_anal_norm_sort.columns.to_list()[5:10]
plt.figure(figsize=(6,9))

sns.heatmap(
    data=crime_anal_norm_sort[target_cols]
    ,annot=True
    ,fmt='.2f'
)

plt.title('범죄 검거 비율(정규화된 검거의 합으로 정렬)')
plt.show()
```
![image](https://github.com/user-attachments/assets/34d46944-e84e-4a30-af3a-eba1b1a61137)

```
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

import matplotlib as mpl
from matplotlib import rcParams # matplotlib 환경설정 모듈
rcParams['font.family'] = 'Malgun Gothic' # 한글 글꼴 설정
rcParams['axes.unicode_minus'] = False

with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
tmp_max = crime_anal_norm['검거율'].max()

crime_anal_norm['검거율'] = crime_anal_norm['검거율'] / tmp_max * 100

crime_anal_sort=crime_anal_norm.sort_values(
    by = '범죄'
    , ascending = False
)
crime_anal_sort
```
![image](https://github.com/user-attachments/assets/2ae33ac7-43bb-419d-8e80-cb69fb654881)

```
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

import matplotlib as mpl
from matplotlib import rcParams # matplotlib 환경설정 모듈
rcParams['font.family'] = 'Malgun Gothic' # 한글 글꼴 설정
rcParams['axes.unicode_minus'] = False

with open('./data/02.crime_anal_norm.pickle','rb') as f:
    crime_anal_norm= pickle.load(f)
    
tmp_max = crime_anal_norm['검거율'].max()

crime_anal_norm['검거율'] = crime_anal_norm['검거율'] / tmp_max * 100

crime_anal_sort=crime_anal_norm.sort_values(
    by = '범죄'
    , ascending = False
)

# 범죄 발생 기준 히트맵
plt.figure(figsize=(10,10))
data_target = ['강간','강도','살인','절도','폭력','범죄']
sns.heatmap(
    data= crime_anal_sort[data_target]
    , annot=True
    ,fmt='.2f'
    ,linewidths=0.5
    ,cmap='RdPu'
)
plt.title('범죄 발생 비율(정규화된 발생 건수로 정렬)')
plt.show()
```
![image](https://github.com/user-attachments/assets/b8a57e2f-e473-49dc-a1a7-e823e9ca348b)

---
## 대한민국 시군별 데이터 시각화 
- 지도에 데이터 표시하기 위해 Folium 라이브러리 필요
```
pip install folium
```
![image](https://github.com/user-attachments/assets/412b4bcf-bf5e-4953-9210-7f9fb0273bab)

```
# 대한민국 시도별 수입 시각화
# 필요한 라이브러리
import numpy as np
import pandas as pd     # csv 파일 읽기
import json             # json 파일 읽기 => 딕셔너릴로 반환
import folium as fl     # 지도 시각화 라이브러리
import webbrowser       # 지도를 브라우저에서 오픈해서 확인
```

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]           # 지도의 중심 좌표 설정(서울)
    ,tiles='Cartodb Positron'       # 지도 스타일 지정(Cartodb Positron : 밝은 배경의 지도 스타일 지정)
    ,zoom_start=7                   # 초기줌 레벨 (7정도 대한민국 전체 볼 수 있는)
)
fl_map
```
![image](https://github.com/user-attachments/assets/47887d9c-c928-48cb-a603-9f169cf79f1f)
```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]         
    ,tiles='Cartodb Positron'
    ,zoom_start=7
)

# 행정구역 GEO json 파일 읽기
# 한국의 시군구 행정구역 경계 데이터
geo_data=json.load(
    open(
        './data/skorea_municipalities_geo_simple.json'
        , encoding='utf-8'
    )
)
geo_data
```
![image](https://github.com/user-attachments/assets/3dbcf835-dcb2-4c1d-ac8e-4e4ecedbecd2)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]         
    ,tiles='Cartodb Positron'
    ,zoom_start=7
)

# 행정구역 GEO json 파일 읽기
# 한국의 시군구 행정구역 경계 데이터
geo_data=json.load(
    open(
        './data/skorea_municipalities_geo_simple.json'
        , encoding='utf-8'
    )
)

# 시군구별 수입 데이터 읽기
df = pd.read_csv(
    './data/aaa.csv'
    ,encoding='utf-8'
)
df.head()
```
![image](https://github.com/user-attachments/assets/3eaeb7cb-7bd1-4bd6-8588-80279caf6769)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]         
    ,tiles='Cartodb Positron'
    ,zoom_start=7
)

geo_data=json.load(
    open(
        './data/skorea_municipalities_geo_simple.json'
        , encoding='utf-8'
    )
)

df = pd.read_csv(
    './data/aaa.csv'
    ,encoding='utf-8'
)

# 시군구 구분도(Choropleth class) 생성 및 지도에 추가
# Choropleth : 구역별 데이터 값을 색상으로 표현하는 지도
fl.Choropleth(
    geo_data=geo_data                                           # 행정구역 데이터 설정
    , data = df                                                 # csv 파일에서 불러온 데이터
    , columns=['sigun','avg_income']                            # 데이터에서 사용할 컬럼 지정(지역명, 평균수입)
    , key_on='feature.properties.name'                          # 지도의 시군구 명과 데이터 시군명을 key로 사용
    , fill_color='YlGn'                                         # Yellow-Green
).add_to(fl_map)

fl_map
```
![image](https://github.com/user-attachments/assets/55fd98d3-b306-4b96-87b2-d5587581d897)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]         
    ,tiles='Cartodb Positron'
    ,zoom_start=7
)

geo_data=json.load(
    open(
        './data/skorea_municipalities_geo_simple.json'
        , encoding='utf-8'
    )
)

df = pd.read_csv(
    './data/aaa.csv'
    ,encoding='utf-8'
)

# 시군구 구분도(Choropleth class) 생성 및 지도에 추가
# Choropleth : 구역별 데이터 값을 색상으로 표현하는 지도
fl.Choropleth(
    geo_data=geo_data                                           # 행정구역 데이터 설정
    , data = df                                                 # csv 파일에서 불러온 데이터
    , columns=['sigun','avg_income']                            # 데이터에서 사용할 컬럼 지정(지역명, 평균수입)
    , key_on='feature.properties.name'                          # 지도의 시군구 명과 데이터 시군명을 key로 사용
    , fill_color='YlGn'                                         # Yellow-Green
).add_to(fl_map)

fl_map.save(
    './data/map.html'
)
```
![image](https://github.com/user-attachments/assets/c5d71247-47e3-44cb-8d1b-da8e2ba0a07a)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]         
    ,tiles='Cartodb Positron'
    ,zoom_start=7
)

geo_data=json.load(
    open(
        './data/skorea_municipalities_geo_simple.json'
        , encoding='utf-8'
    )
)

df = pd.read_csv(
    './data/aaa.csv'
    ,encoding='utf-8'
)

# 시군구 구분도(Choropleth class) 생성 및 지도에 추가
# Choropleth : 구역별 데이터 값을 색상으로 표현하는 지도
fl.Choropleth(
    geo_data=geo_data                                           # 행정구역 데이터 설정
    , data = df                                                 # csv 파일에서 불러온 데이터
    , columns=['sigun','avg_income']                            # 데이터에서 사용할 컬럼 지정(지역명, 평균수입)
    , key_on='feature.properties.name'                          # 지도의 시군구 명과 데이터 시군명을 key로 사용
    , fill_color='YlGn'                                         # Yellow-Green
).add_to(fl_map)

fl_map.save(
    './data/map.html'
)
webbrowser.open_new_tab('C://big19//python_dev//workspace//data_collection//data//map.html')
```
![image](https://github.com/user-attachments/assets/4c5aed88-3e02-4093-a1f8-6f8b9a4c0b6a)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 기본 지도 객체 생성
fl_map = fl.Map(
    location = [37.4,127]         
    ,tiles='Cartodb Positron'
    ,zoom_start=7
)

geo_data=json.load(
    open(
        './data/skorea_municipalities_geo_simple.json'
        , encoding='utf-8'
    )
)

df = pd.read_csv(
    './data/aaa.csv'
    ,encoding='utf-8'
)

# 시군구 구분도(Choropleth class) 생성 및 지도에 추가
# Choropleth : 구역별 데이터 값을 색상으로 표현하는 지도
fl.Choropleth(
    geo_data=geo_data                                           # 행정구역 데이터 설정
    , data = df                                                 # csv 파일에서 불러온 데이터
    , columns=['sigun','avg_income']                            # 데이터에서 사용할 컬럼 지정(지역명, 평균수입)
    , key_on='feature.properties.name'                          # 지도의 시군구 명과 데이터 시군명을 key로 사용
    , fill_color='YlGn'                                         # Yellow-Green
    , fill_opacity = 0.5                                        #투명도 설정
).add_to(fl_map)

fl_map.save(
    './data/map.html'
)
webbrowser.open_new_tab('C://big19//python_dev//workspace//data_collection//data//map.html')
```
![image](https://github.com/user-attachments/assets/a3693b47-eb41-42c5-aac8-ce3d17b9b113)


---

## 서울시 범죄 현황 지도 시각화

```
#서울시 행정구역 데이터 및 범죄현황 데이터
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser


geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

geo_str
```
![image](https://github.com/user-attachments/assets/2b8f8a98-c861-4afb-91f3-083603448dc2)

```
#서울시 행정구역 데이터 및 범죄현황 데이터
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser


geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)


crime_anal_norm

```
![image](https://github.com/user-attachments/assets/3e503564-f7fd-413d-be06-eb61a3f9213a)

```
#서울시 행정구역 데이터 및 범죄현황 데이터
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser


geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

geo_str['features'][0]['id']
```
![image](https://github.com/user-attachments/assets/0c28c149-59cf-4a7f-b8dd-d961a5ffeeb1)

```
#서울시 행정구역 데이터 및 범죄현황 데이터
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser


geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

seoul_map = fl.Map(
    location=[37.55002,126.982]                                #지도의 중심(서울 시청)
    ,zoom_start=11
)
seoul_map
```
![image](https://github.com/user-attachments/assets/56e00251-8e5a-4095-9631-11eea0ede826)

```
#서울시 행정구역 데이터 및 범죄현황 데이터
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser


geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

seoul_map = fl.Map(
    location=[37.55002,126.982]                                #지도의 중심(서울 시청)
    ,zoom_start=11
)

fl.Choropleth(
    geo_data=geo_str
    , data= crime_anal_norm['범죄']
    ,columns=[crime_anal_norm.index,crime_anal_norm['범죄']]
    , key_on='feature.id'
).add_to(seoul_map)

seoul_map
```
![image](https://github.com/user-attachments/assets/b2bd1619-9393-4833-989d-aade2e89e32b)

```
#서울시 행정구역 데이터 및 범죄현황 데이터
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser


geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

seoul_map = fl.Map(
    location=[37.55002,126.982]                                #지도의 중심(서울 시청)
    ,zoom_start=11
)

fl.Choropleth(
    geo_data=geo_str
    , data= crime_anal_norm['검거']
    ,columns=[crime_anal_norm.index,crime_anal_norm['검거']]
    , key_on='feature.id'
).add_to(seoul_map)

seoul_map
```
![image](https://github.com/user-attachments/assets/78a79fe3-b782-4c08-b01d-7540bf823521)

---

## 경찰서별 검거현황과 구별 범죄발생 현황을 표현하기

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser

# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)
crime_anal_raw
```
![image](https://github.com/user-attachments/assets/5594d419-c511-4d63-b9d8-b8d338edce45)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle
# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

crime_anal_raw.head()
```
![image](https://github.com/user-attachments/assets/1e580463-7700-4942-9bfe-c280d4bd8831)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle
# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

print(col_list) 
```
![image](https://github.com/user-attachments/assets/c6b24776-ec2c-4c74-83da-1fd502d7eb83)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle
# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()
tmp_df
```
![image](https://github.com/user-attachments/assets/2f02d82d-b297-4be0-b9b3-d1e7388d402f)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle
# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)
crime_anal_raw
```
![image](https://github.com/user-attachments/assets/02ac74ce-4d7c-435a-aff8-a0b5583d2d97)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle
# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)

crime_anal_raw[col_list].max()

```
![image](https://github.com/user-attachments/assets/3d940811-ff38-4f94-9b57-da5d8dbf9723)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle

# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)

# 지도에 경찰서 위치 표시

map = fl.Map(
    location=[37.55002,126.982] 
    , zoom_start = 11
)

for idx in crime_anal_raw.index:
    fl.Marker(
        location=[crime_anal_raw['lat'][idx],crime_anal_raw['lng'][idx]]
    ).add_to(map)
map
```
![image](https://github.com/user-attachments/assets/ed525419-5f37-48b4-a3cf-ff26b86d045f)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle

# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)

# 전체 지도 생성

map1 = fl.Map(
    location=[37.55002,126.982] 
    , zoom_start = 11
)

# 지도에 경찰서 위치 표시

for idx in crime_anal_raw.index:
    fl.Marker(
        location=[crime_anal_raw['lat'][idx],crime_anal_raw['lng'][idx]]
    ).add_to(map1)

# 전체 지도 생성
map2= fl.Map(
    location=[37.55002,126.982] 
    , zoom_start = 11
)

# 행정 경계 생성
geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

fl.Choropleth(
    geo_data=geo_str    # 서울시 구별 데이터
    ,data=crime_anal_norm['범죄']   # 범죄 컬럼 : 범죄 발생
    ,columns=[crime_anal_norm.index,crime_anal_norm['범죄']]
    , key_on='feature.id'
).add_to(map2)

map2
```
![image](https://github.com/user-attachments/assets/6c97322c-db7a-4f48-bfcc-b6e6452fb0c4)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle

# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)

# 전체 지도 생성

map1 = fl.Map(
    location=[37.55002,126.982] 
    , zoom_start = 11
)


# 행정 경계 생성
geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

fl.Choropleth(
    geo_data=geo_str    # 서울시 구별 데이터
    ,data=crime_anal_norm['범죄']   # 범죄 컬럼 : 범죄 발생
    ,columns=[crime_anal_norm.index,crime_anal_norm['범죄']]
    , key_on='feature.id'
).add_to(map1)

# 지도에 경찰서 위치 표시

for idx in crime_anal_raw.index:
    fl.Marker(
        location=[crime_anal_raw['lat'][idx],crime_anal_raw['lng'][idx]]
    ).add_to(map1)

map1
```
![image](https://github.com/user-attachments/assets/9f989108-9cbf-4d9e-8c37-392269e3b6be)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle

# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)

# 전체 지도 생성

map1 = fl.Map(
    location=[37.55002,126.982] 
    , zoom_start = 11
)


# 행정 경계 생성
geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

fl.Choropleth(
    geo_data=geo_str    # 서울시 구별 데이터
    ,data=crime_anal_norm['범죄']   # 범죄 컬럼 : 범죄 발생
    ,columns=[crime_anal_norm.index,crime_anal_norm['범죄']]
    , key_on='feature.id'
).add_to(map1)

# 지도에 경찰서 위치 표시

for idx in crime_anal_raw.index:
    fl.CircleMarker(
        location=[crime_anal_raw['lat'][idx],crime_anal_raw['lng'][idx]]
        ,radius = crime_anal_raw['검거'][idx]*10
        ,color='#3186cc'
        ,fill_color='#3186cc'
        ,fill=True
    ).add_to(map1)

map1
```
![image](https://github.com/user-attachments/assets/ad2fd02c-0742-4cf6-bed9-ab0853816fdd)

```
import numpy as np
import pandas as pd    
import json
import folium as fl
import webbrowser
import pickle

# 경찰서의 구 연결 정보
crime_anal_raw=pd.read_csv(
    './data/02. crime_in_Seoul_include_gu_name.csv'
    , encoding='utf-8'
    , index_col=0
)

# 경찰서의 위치 정보 : station_lat, station_lag
station_lat=[]
station_lng=[]
with open('./data/station_lat.pickle','rb') as f:
    station_lat=pickle.load(f)

with open('./data/station_lng.pickle','rb') as f:
    station_lng=pickle.load(f)

# crime_anal_raw dataframe append
crime_anal_raw['lat']=station_lat
crime_anal_raw['lng']=station_lng

# 검거 컬럼을 추출 리스트

# col_list=[col for col in crime_anal_raw.columns if '검거' in col]
col_list = []  
for col in crime_anal_raw.columns:
    if '검거' in col:
        col_list.append(col)  

tmp_df = crime_anal_raw[col_list] / crime_anal_raw[col_list].max()

# 검거 컬럼 생성 : 정규화한 검거 합
crime_anal_raw['검거']=np.sum(tmp_df,axis=1)

# 전체 지도 생성

map1 = fl.Map(
    location=[37.55002,126.982] 
    , zoom_start = 11
)


# 행정 경계 생성
geo_path ='./data/02. skorea_municipalities_geo_simple.json'
geo_str=json.load(
    open(
        geo_path                                               # 서울시 행정구역 데이터
        ,encoding='utf-8'
    )
)

crime_anal_norm=pd.read_csv(
    './data/02. crime_in_Seoul_final.csv'
    ,encoding='utf-8'
    ,index_col=0
)

fl.Choropleth(
    geo_data=geo_str    # 서울시 구별 데이터
    ,data=crime_anal_norm['범죄']   # 범죄 컬럼 : 범죄 발생
    ,columns=[crime_anal_norm.index,crime_anal_norm['범죄']]
    , key_on='feature.id'
).add_to(map1)

# 지도에 경찰서 위치 표시

for idx in crime_anal_raw.index:
    fl.CircleMarker(
        location=[crime_anal_raw['lat'][idx],crime_anal_raw['lng'][idx]]
        ,radius = crime_anal_raw['검거'][idx]*10
        ,color='#3105cc'
        ,fill_color='#3105cc'
        ,fill=True
    ).add_to(map1)

map1
```
![image](https://github.com/user-attachments/assets/3f7556b3-4ae4-4c93-a2bd-1310a55dad8e)
