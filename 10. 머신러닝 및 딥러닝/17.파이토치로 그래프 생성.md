# 🔢 PyTorch 계산 그래프 (Computational Graph)

PyTorch는 **동적 계산 그래프 (Dynamic Computational Graph)** 방식을 사용하여 유연하고 직관적인 모델 개발을 가능하게 합니다. 계산이 수행되는 즉시 그래프가 생성되며, 자동으로 미분을 수행할 수 있습니다.

## 📘 개념 요약

- **계산 그래프**: 연산(operations)과 변수(tensors)를 노드로 구성한 구조.
- **동적 그래프**: 연산이 실행될 때 실시간으로 그래프를 생성.
- **자동 미분**: `requires_grad=True`인 텐서는 연산 기록을 저장하여 `.backward()` 호출 시 미분 계산 가능.
- **연산 추적**: `.grad_fn` 속성을 통해 각 텐서가 어떤 연산을 통해 만들어졌는지 확인할 수 있음.

## ⚖️ 동적 그래프 vs 정적 그래프

| 항목             | 동적 계산 그래프 (PyTorch) | 정적 계산 그래프 (TensorFlow 1.x 등) |
|------------------|-----------------------------|----------------------------------------|
| 그래프 생성 시점 | 실행 중 (runtime)           | 실행 전 (compile time)                 |
| 유연성           | 매우 높음                   | 낮음                                   |
| 디버깅           | 직관적                      | 복잡함                                 |
| 대표 프레임워크  | PyTorch, Chainer            | TensorFlow 1.x, MXNet                  |

---
```
# 간단한 그래프 생성
import torch

def compute_z(a, b, c):
    r1 = torch.sub(a, b)
    r2 = torch.mul(r1, 2)
    z = torch.add(r2, c)
    return z

print(f'스칼라(단일값) 입력 : {compute_z(torch.tensor(1), torch.tensor(2), torch.tensor(3))}')
print(f'랭크 1 입력 : {compute_z(torch.tensor([1]), torch.tensor([2]), torch.tensor([3]))}')
print(f'랭크 2 입력 : {compute_z(torch.tensor([[1]]), torch.tensor([[2]]), torch.tensor([[3]]))}')
```
![image](https://github.com/user-attachments/assets/bc623808-8c3b-4fba-8df3-4b8cdc86c5ef)
