# ğŸ”¢ PyTorch ê³„ì‚° ê·¸ë˜í”„ (Computational Graph)

PyTorchëŠ” **ë™ì  ê³„ì‚° ê·¸ë˜í”„ (Dynamic Computational Graph)** ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìœ ì—°í•˜ê³  ì§ê´€ì ì¸ ëª¨ë¸ ê°œë°œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ê³„ì‚°ì´ ìˆ˜í–‰ë˜ëŠ” ì¦‰ì‹œ ê·¸ë˜í”„ê°€ ìƒì„±ë˜ë©°, ìë™ìœ¼ë¡œ ë¯¸ë¶„ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“˜ ê°œë… ìš”ì•½

- **ê³„ì‚° ê·¸ë˜í”„**: ì—°ì‚°(operations)ê³¼ ë³€ìˆ˜(tensors)ë¥¼ ë…¸ë“œë¡œ êµ¬ì„±í•œ êµ¬ì¡°.
- **ë™ì  ê·¸ë˜í”„**: ì—°ì‚°ì´ ì‹¤í–‰ë  ë•Œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ìƒì„±.
- **ìë™ ë¯¸ë¶„**: `requires_grad=True`ì¸ í…ì„œëŠ” ì—°ì‚° ê¸°ë¡ì„ ì €ì¥í•˜ì—¬ `.backward()` í˜¸ì¶œ ì‹œ ë¯¸ë¶„ ê³„ì‚° ê°€ëŠ¥.
- **ì—°ì‚° ì¶”ì **: `.grad_fn` ì†ì„±ì„ í†µí•´ ê° í…ì„œê°€ ì–´ë–¤ ì—°ì‚°ì„ í†µí•´ ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŒ.

## âš–ï¸ ë™ì  ê·¸ë˜í”„ vs ì •ì  ê·¸ë˜í”„

| í•­ëª©             | ë™ì  ê³„ì‚° ê·¸ë˜í”„ (PyTorch) | ì •ì  ê³„ì‚° ê·¸ë˜í”„ (TensorFlow 1.x ë“±) |
|------------------|-----------------------------|----------------------------------------|
| ê·¸ë˜í”„ ìƒì„± ì‹œì  | ì‹¤í–‰ ì¤‘ (runtime)           | ì‹¤í–‰ ì „ (compile time)                 |
| ìœ ì—°ì„±           | ë§¤ìš° ë†’ìŒ                   | ë‚®ìŒ                                   |
| ë””ë²„ê¹…           | ì§ê´€ì                       | ë³µì¡í•¨                                 |
| ëŒ€í‘œ í”„ë ˆì„ì›Œí¬  | PyTorch, Chainer            | TensorFlow 1.x, MXNet                  |

---
```
# ê°„ë‹¨í•œ ê·¸ë˜í”„ ìƒì„±
import torch

def compute_z(a, b, c):
    r1 = torch.sub(a, b)
    r2 = torch.mul(r1, 2)
    z = torch.add(r2, c)
    return z

print(f'ìŠ¤ì¹¼ë¼(ë‹¨ì¼ê°’) ì…ë ¥ : {compute_z(torch.tensor(1), torch.tensor(2), torch.tensor(3))}')
print(f'ë­í¬ 1 ì…ë ¥ : {compute_z(torch.tensor([1]), torch.tensor([2]), torch.tensor([3]))}')
print(f'ë­í¬ 2 ì…ë ¥ : {compute_z(torch.tensor([[1]]), torch.tensor([[2]]), torch.tensor([[3]]))}')
```
![image](https://github.com/user-attachments/assets/bc623808-8c3b-4fba-8df3-4b8cdc86c5ef)

```
from IPython.display import Image
Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch13/figures/13_01.png', width=400)
```
![image](https://github.com/user-attachments/assets/a6947987-4f87-4eed-87fa-b8c544daaca8)

---
## ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•˜ê³  ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ íƒ ì„œ ê°ì²´

| **Layer**         | **Activation Function** | **Initialization**   |
|-------------------|-------------------------|----------------------|
| Linear            | Sigmoid                 | Xavier               |
| Linear            | ReLU                    | He                   |
| CNN               | ReLU                    | He                   |
| LSTM              | Sigmoid                 | Xavier               |

```
import torch
import torch.nn as nn

model=nn.Sequential(
    nn.Linear(4,16) # 4 : input_size, 16 : hidden_size
    , nn.ReLU()
    ,nn.Linear(16,32) # hidden_size :16, hidden_size=32
    ,nn.ReLU()
)
model
```
![image](https://github.com/user-attachments/assets/9340ffb8-9647-4454-b7d3-84485fe86b36)

```
import torch
import torch.nn as nn

class Model(nn.Module):
    def __init__(self, input_size,hidden_size):
        super().__init__()
        self.layer1=nn.Linear(input_size,hidden_size)
        self.layer2=nn.Linear(hidden_size,hidden_size)
    def forward(self,x):
        x=self.layer1(x)
        x=nn.ReLU(x)
        x=self.layer2(x)
        x=nn.ReLU()
        return x
        
        
model=nn.Sequential(
    nn.Linear(4,16) # 4 : input_size, 16 : hidden_size
    , nn.ReLU()
    ,nn.Linear(16,32) # hidden_size :16, hidden_size=32
    ,nn.ReLU()
)
model
```
![image](https://github.com/user-attachments/assets/55ed987b-07b4-4623-a43e-194c8e279fb2)

```
import torch
import torch.nn as nn

model=nn.Sequential(
    nn.Linear(4,16) # 4 : input_size, 16 : hidden_size
    , nn.ReLU()
    ,nn.Linear(16,32) # hidden_size :16, hidden_size=32
    ,nn.ReLU()
)

class Model(nn.Module):
    def __init__(self, input_size,hidden_size):
        super().__init__()
        self.layer1=nn.Linear(input_size,hidden_size)
        self.layer2=nn.Linear(hidden_size,hidden_size)
    def forward(self,x):
        x=self.layer1(x)
        x=nn.ReLU(x)
        x=self.layer2(x)
        x=nn.ReLU()
        x=model(x)
        return x
```
```
import torch
import torch.nn as nn

model=nn.Sequential(
    nn.Linear(4,16) # 4 : input_size, 16 : hidden_size
    , nn.ReLU()
    ,nn.Linear(16,32) # hidden_size :16, hidden_size=32
    ,nn.ReLU()
)

class Model(nn.Module):
    def __init__(self, input_size,hidden_size):
        super().__init__()
        self.layer1=nn.Linear(input_size,hidden_size)
        self.layer2=nn.Linear(hidden_size,hidden_size)
    def forward(self,x):
        x=self.layer1(x)
        x=nn.ReLU(x)
        x=self.layer2(x)
        x=nn.ReLU()
        x=model(x)
        return x

input_size=4
hidden_size=16
model1=Model(input_size=input_size,hidden_size=hidden_size)
model1
```
![image](https://github.com/user-attachments/assets/41f96ef9-84a5-45fe-8234-3590b3b433a2)
