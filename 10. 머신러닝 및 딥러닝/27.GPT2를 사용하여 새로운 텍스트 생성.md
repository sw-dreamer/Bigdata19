# GPT2를 사용하여 새로운 텍스트 생성

```
%pip install transformers
```
![image](https://github.com/user-attachments/assets/ea8ed49b-56c4-4068-985d-1f3694dce684)

```
from transformers import pipeline, set_seed

generator = pipeline( # 생성하는 오브젝트 생성
    'text-generation' # 머할것인지 지정
    ,model='gpt2' # 사용할 모델 지정
)

set_seed(123) # 실행할 때마다 데이터가 바뀌는것을 방지

# generator 실행
generator(
    'Hey reader, today is '
    , max_length=100
    , num_return_sequences=3 # 답변의 갯수
)
```
```
Device set to use cuda:0
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[{'generated_text': "Hey reader, today is the final day (no blogpost) of my\xa0 I'm working on an upcoming project with you guys. Today is the last day of school, so I'm taking part in a lecture about computer science today. The first of what will be a series of blog posts will focus on today's topic, the topic which will lead me through the development of the webkit.\nThis blogpost will focus mostly on the concepts and terminology which are important to most web"},
 {'generated_text': 'Hey reader, today is the 50th anniversary of the death of a single person who I thought would have been very unusual to write: Mike Cernovich. I am writing to offer my deepest condolences in advance to the family and friends of Mike, the man whom I wrote about at my very own blog last August and who is at our core a fan of all things video games, in his late teens for the first time with his family, and now for his friends. I knew from'},
 {'generated_text': 'Hey reader, today is Sunday.After my last post here on Aesop we are going down to the woods to get some quality woods. We are planning the day for our tour, but will be picking up lots of extra supplies if it runs out. We decided to make an initial hike and head back to our campground to help get ready for a big picnic lunch.\nAfter spending some time playing around in what is now called the Wild Horse State Forest, we came across'}]
```
```
from transformers import pipeline, set_seed

generator = pipeline( # 생성하는 오브젝트 생성
    'text-generation' # 머할것인지 지정
    ,model='gpt2' # 사용할 모델 지정
)

set_seed(123) # 실행할 때마다 데이터가 바뀌는것을 방지

# generator 실행
generator(
    '딥러닝 어떻게 배워야 하니?'
    , max_length=100
    , num_return_sequences=3 # 답변의 갯수
)
```
![image](https://github.com/user-attachments/assets/6b18f8ec-3184-4c05-8700-0615c35480d6)

```
from transformers import pipeline, set_seed
import torch

# 1. GPT-3 모델 사용 (실제로는 GPT-3 크기의 모델인 gpt-j-6B 사용)
#model_name = "EleutherAI/gpt-j-6B"  # OpenAI의 GPT-3는 Hugging Face에서 직접 사용할 수 없어 대체 모델 사용

# 리소스가 제한된 환경에서는 더 작은 모델을 사용할 수 있음
model_name = "EleutherAI/gpt-neo-1.3B"  # 더 작은 모델 옵션

# 2. 한글 처리를 위한 토크나이저 설정
generator = pipeline(
    'text-generation',
    model=model_name,
    tokenizer=model_name,
    device=0 if torch.cuda.is_available() else -1  # GPU 사용 가능시 활용
)

set_seed(42)

# 한글 프롬프트로 테스트
result = generator(
    "트랜스포머에 대해 자세한 설명 부탁해?",
    max_length=500,
    num_return_sequences=3,
    do_sample=True,
    top_k=50,
    top_p=0.95,
    temperature=0.8
)

for i, text in enumerate(result):
    print(f"결과 {i+1}: {text['generated_text']}")
```
