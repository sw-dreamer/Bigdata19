# 데이터 분리

---
## 데이터셋을 훈련 데이터셋과 테스트 데이터셋으로 나누기

```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

# UCI 머신러닝 저장소의 Wine 데이터셋에 접근되지 않을 때
# 다음 코드의 주석을 제거하고 로컬 경로에서 데이터셋을 읽으세요:

# df_wine = pd.read_csv('wine.data', header=None)


df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

print('Class labels', np.unique(df_wine['Class label']))
df_wine.head()
```
![image](https://github.com/user-attachments/assets/24c5beed-dfb8-43a4-91e4-ccc4f53d7129)

```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

df_wine.info()
```
![image](https://github.com/user-attachments/assets/fb9406ee-5539-4fdc-8c66-376035441246)

```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

df_wine.describe()
```
![image](https://github.com/user-attachments/assets/0ffab463-f4fa-4ec0-9b70-7892beef6b11)

```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

from sklearn.model_selection import train_test_split

# 데이터(X)와 답(y) 분리
X=df_wine.iloc[:,1:].values # 모든행, 1열부터 끝까지
y=df_wine.iloc[:,0].values # 레이블(답), 0열부터 끝까지

# 학습/테스트 데이터(답) 분리
X_train, X_test, y_train, y_test= train_test_split(
    X
    ,y
    ,test_size=0.3
    ,random_state=1
    ,stratify=y 
)
print(f'X_train.shape : {X_train.shape}')
print(f'X_test.shape : {X_test.shape}')
print(f'y_train.shape : {y_train.shape}')
print(f'y_test.shape : {y_test.shape}')
print('='*50)
print(f'np.bincount(y_train) : {np.bincount(y_train)}')
print(f'np.bincount(y_test) : {np.bincount(y_test)}')
```
![image](https://github.com/user-attachments/assets/7a09b08f-8b71-4b55-a668-8c171b12b69f)
---
## Scaler 종류

데이터 전처리에서 사용하는 다양한 스케일링 기법에 대해 설명합니다. 각 스케일러는 데이터를 특정 범위나 분포로 변환하는 방식이 다릅니다.

### 1. StandardScaler
- **목적**: 데이터를 평균이 0이고 표준편차가 1인 정규분포로 변환합니다.
- **사용법**: 데이터에서 평균을 빼고, 표준편차로 나눕니다.
- **공식**:
  
  ![StandardScaler](https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Bscaled%7D%7D%20%3D%20%5Cfrac%7BX%20-%20%5Cmu%7D%7B%5Csigma%7D)

  여기서, $\mu$는 평균, $\sigma$는 표준편차입니다.
- **특징**:
  - 이상치에 민감합니다.
  - 데이터가 정규분포를 따를 때 가장 효과적입니다.

### 2. MinMaxScaler
- **목적**: 데이터를 지정된 범위로 변환합니다. 보통 0과 1 사이로 변환됩니다.
- **사용법**: 데이터의 최소값과 최대값을 이용하여 데이터를 변환합니다.
- **공식**:
  
  ![MinMaxScaler](https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Bscaled%7D%7D%20%3D%20%5Cfrac%7BX%20-%20X_%7B%5Ctext%7Bmin%7D%7D%7D%7BX_%7B%5Ctext%7Bmax%7D%7D%20-%20X_%7B%5Ctext%7Bmin%7D%7D%7D)

  여기서, $X_{\text{min}}$과 $X_{\text{max}}$는 데이터의 최소값과 최대값입니다.
- **특징**:
  - 이상치가 있을 경우, 이상치가 다른 데이터의 스케일에 큰 영향을 미칩니다.
  - 모든 데이터가 같은 범위(보통 0~1)로 변환되기 때문에 다른 모델링에서 더 유용할 수 있습니다.

## 3. RobustScaler
- **목적**: 데이터를 중앙값(median)과 사분위수 범위(IQR)를 기준으로 변환합니다. 이상치에 덜 민감하게 변환됩니다.
- **사용법**: 중앙값을 빼고, IQR(75th percentile - 25th percentile)로 나눕니다.
- **공식**
  
  ![RobustScaler](https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Bscaled%7D%7D%20%3D%20%5Cfrac%7BX%20-%20%5Ctext%7BMedian%7D%28X%29%7D%7B%5Ctext%7BIQR%7D%28X%29%7D)

  여기서, $\text{Median}(X)$은 중앙값, $\text{IQR}(X)$는 사분위수 범위입니다.
- **특징**:
  - 이상치에 강인합니다.
  - 데이터가 이상치에 민감할 때 유용합니다.

## 4. MaxAbsScaler
- **목적**: 데이터를 절대값의 최대값으로 나누어, 데이터를 -1과 1 사이로 변환합니다.
- **사용법**: 각 데이터 포인트를 절대값의 최대값으로 나눕니다.
- **공식**
  
  ![image](https://github.com/user-attachments/assets/b142beca-6f2c-43cf-a99d-6023290fbf87)

  여기서, $|X_{\text{max}}|$는 절대값이 가장 큰 데이터 값입니다.
- **특징**:
  - 데이터가 양수와 음수를 포함하는 경우에도 데이터를 0과 ±1 사이로 변환합니다.
  - 이상치에 강인하며, 데이터가 스케일을 유지하면서 변화합니다.
  - 주로 희소 행렬(sparse matrix)에서 유용하게 사용됩니다.

## 요약
- **StandardScaler**: 평균이 0, 표준편차가 1인 정규분포로 변환 (정규분포 데이터에 적합)
- **MinMaxScaler**: 데이터를 특정 범위(보통 0과 1)로 변환 (이상치에 민감)
- **RobustScaler**: 중앙값과 IQR을 기준으로 변환 (이상치에 강인)
- **MaxAbsScaler**: 절대값 최대값으로 나누어 -1과 1 사이로 변환 (희소 행렬에 적합)

각 스케일러는 데이터의 특성에 따라 선택해야 하므로, 이상치의 유무나 데이터의 분포를 고려하여 적절한 스케일러를 선택하는 것이 중요합니다.


---
```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

from sklearn.model_selection import train_test_split

# 데이터(X)와 답(y) 분리
X=df_wine.iloc[:,1:].values # 모든행, 1열부터 끝까지
y=df_wine.iloc[:,0].values # 레이블(답), 0열부터 끝까지

# 학습/테스트 데이터(답) 분리
X_train, X_test, y_train, y_test= train_test_split(
    X
    ,y
    ,test_size=0.3
    ,random_state=1
    ,stratify=y 
)

from sklearn.preprocessing import MinMaxScaler

mms=MinMaxScaler()

mms.fit(X_train) # 13개의 feature의 min/max 구해진다

X_train_norm=mms.transform(X_train)
X_test_norm=mms.transform(X_test)

X_train_norm.shape
```
![image](https://github.com/user-attachments/assets/fadc9b06-743e-41fe-9954-466428916af1)

```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

from sklearn.model_selection import train_test_split

# 데이터(X)와 답(y) 분리
X=df_wine.iloc[:,1:].values # 모든행, 1열부터 끝까지
y=df_wine.iloc[:,0].values # 레이블(답), 0열부터 끝까지

# 학습/테스트 데이터(답) 분리
X_train, X_test, y_train, y_test= train_test_split(
    X
    ,y
    ,test_size=0.3
    ,random_state=1
    ,stratify=y 
)

from sklearn.preprocessing import MinMaxScaler

mms=MinMaxScaler()

mms.fit(X_train) # 13개의 feature의 min/max 구해진다

X_train_norm=mms.transform(X_train)
X_test_norm=mms.transform(X_test)

print(f'X_train_norm.max() : {X_train_norm.max()}')
print(f'X_train_norm.min() : {X_train_norm.min()}')
```
![image](https://github.com/user-attachments/assets/c339efaf-ab46-44ab-84cf-49baa4e43af9)

```
import numpy as np
ex = np.array(
    [0,1,2,3,4,5]
)
print(f'표준화 : {(ex-ex.mean())/ex.std()}')
print(f'정규화 : {(ex-ex.min())/ex.max()-ex.min()}')
```
![image](https://github.com/user-attachments/assets/64b6cb25-a1af-4eaf-a9d7-81426e0a703e)

---
## 유용한 특성 선택
```
import pandas as pd
import numpy as np

df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

from sklearn.model_selection import train_test_split

# 데이터(X)와 답(y) 분리
X=df_wine.iloc[:,1:].values # 모든행, 1열부터 끝까지
y=df_wine.iloc[:,0].values # 레이블(답), 0열부터 끝까지

# 학습/테스트 데이터(답) 분리
X_train, X_test, y_train, y_test= train_test_split(
    X
    ,y
    ,test_size=0.3
    ,random_state=1
    ,stratify=y 
)

from sklearn.preprocessing import MinMaxScaler

mms=MinMaxScaler()

mms.fit(X_train) # 13개의 feature의 min/max 구해진다

X_train_norm=mms.transform(X_train)
X_test_norm=mms.transform(X_test)

# 3중 분류
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(
    penalty='l1'
    ,C=1.0
    ,solver='liblinear'
    ,multi_class='ovr'
)

lr.fit(X_train_norm,y_train)
print(f'훈련 정확도 : {lr.score(X_train_norm,y_train)}')
print(f'테스트 정확도 : {lr.score(X_test_norm,y_test)}')
```
![image](https://github.com/user-attachments/assets/a34b7ec6-02f8-4eae-b576-bb0bb4a72d0c)
