# Stacking Ensemble

**스태킹 앙상블(Stacks Ensemble)**은 여러 머신 러닝 모델을 결합하여 더 높은 예측 성능을 얻는 기법 중 하나입니다. 각 모델의 예측 결과를 결합하여 최종 예측을 수행합니다. 스태킹은 다양한 유형의 모델을 결합할 수 있으며, 일반적으로 다른 기본 모델들(Base Learners)의 예측을 새로운 모델(Meta Learner)을 통해 결합합니다.

## 개념

스태킹 앙상블은 크게 두 가지 주요 단계로 구성됩니다:

1. **1단계 (Base Learners)**:
   - 다양한 모델(예: 결정 트리, 랜덤 포레스트, SVM 등)을 훈련시킵니다.
   - 각 모델은 주어진 데이터에 대해 예측을 생성합니다.
   
2. **2단계 (Meta Learner)**:
   - 1단계에서 나온 예측 결과를 입력으로 받습니다.
   - Meta Learner는 이 예측들을 바탕으로 최종 예측을 생성합니다.
   
**스태킹 앙상블**은 기본적으로 `다양한 모델의 예측을 결합`하여 하나의 최종 모델을 만드는 방식으로, 각 모델의 예측을 취합하여 개별 모델이 놓칠 수 있는 패턴을 보완합니다.

## Stacking 앙상블의 장점

- **성능 향상**: 다양한 모델의 장점을 결합하여 더 높은 성능을 기대할 수 있습니다.
- **다양성 활용**: 서로 다른 모델들은 각기 다른 방식으로 데이터를 해석하므로, 서로 보완적인 특성을 가집니다.
- **유연성**: 기본 모델(Base Learner)으로 다양한 알고리즘을 사용할 수 있습니다.

## Stacking 앙상블의 단점

- **훈련 시간**: 여러 모델을 훈련시키고, 메타 모델을 학습시키는 데 시간이 많이 소요될 수 있습니다.
- **복잡성**: 여러 모델을 사용하기 때문에 모델이 복잡해지고, 결과 해석이 어려울 수 있습니다.

## 결론

스태킹 앙상블은 여러 모델의 예측을 결합하여 더 강력한 예측 성능을 얻는 기법으로, 머신 러닝 모델의 성능을 극대화할 수 있는 유용한 방법입니다. 다양한 기본 모델을 사용하고, 메타 모델을 통해 최종 예측을 개선하는 방식으로 작동하며, 실용적인 경우가 많습니다.


---
```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

cancer_data=load_breast_cancer()

X_data=cancer_data.data
y_label=cancer_data.target

X_train,X_test,y_train,y_test=train_test_split(
    X_data
    ,y_label
    ,test_size=0.2
    ,random_state=0
)

# 개별 ML 모델 생성
knn_clf=KNeighborsClassifier(n_neighbors=4)
rf_clf=RandomForestClassifier(n_estimators=100,random_state=0)
dt_clf=DecisionTreeClassifier()
ada_clf=AdaBoostClassifier(n_estimators=100)

# 스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델
lr_final=LogisticRegression()

knn_clf.fit(X_train,y_train)
rf_clf.fit(X_train,y_train)
dt_clf.fit(X_train,y_train)
ada_clf.fit(X_train,y_train)

# 학습된 개별 모델들이 각자 반환하는 예측 데이터 세트를 생성하고 개별 모델의 정확도 측정
knn_pred=knn_clf.predict(X_test)
rf_pred=rf_clf.predict(X_test)
dt_pred=dt_clf.predict(X_test)
ada_pred=ada_clf.predict(X_test)

print(f'KNN 정확도 : {accuracy_score(y_test,knn_pred)}')
print(f'랜덤 포레스트 정확도 : {accuracy_score(y_test,rf_pred)}')
print(f'결정 트리 정확도 : {accuracy_score(y_test,dt_pred)}')
print(f'에이다 부스트 정확도 : {accuracy_score(y_test,ada_pred)}')

pred=np.array([knn_pred,rf_pred,dt_pred,ada_pred])

print(f'pred.shape : {pred.shape}')

# transpose를 이용한 행과 열의 위치 교환, 칼럼 레벨로 각 알고리즘의 예측 결과를 피쳐로 만듬
pred=np.transpose(pred)
print(f'pred.shape : {pred.shape}')

lr_final.fit(pred,y_test)
final=lr_final.predict(pred)
print(f'최종 메타 모델의 예측 정확도 {accuracy_score(y_test,final)}')

print('='*100)

from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error

# 개발 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수
def get_statcking_base_datasets(model,X_train_n,y_train_n,X_test_n,n_folds):
    # 지정된 n_folds 값으로 KFold 생성
    kf=KFold(
        n_splits=n_folds
        ,shuffle=False
    )
    # 추후에 메타 모델이 사용할 학습 데이터 반환을 위한 numpy 배열 초기화
    train_fold_pred=np.zeros(
        (X_train_n.shape[0],1)
    )
    test_pred=np.zeros(
        (X_test_n.shape[0],n_folds)
    )
    print(model.__class__.__name__,' model 시작')
    
    for folder_counter, (train_index,valid_index) in enumerate(kf.split(X_train_n)):
        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출
        print(f'\t 폴드 세트 : {folder_counter} 시작')
        X_tr=X_train_n[train_index]
        y_tr=y_train_n[train_index]
        X_te=X_train_n[valid_index]
        
        # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행
        model.fit(X_tr,y_tr)
        
        # 폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장
        train_fold_pred[valid_index,:]=model.predict(X_te).reshape(-1,1)
        # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장
        test_pred[:,folder_counter]=model.predict(X_test_n)
    
    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성
    test_pred_mean=np.mean(
        test_pred
        ,axis=1
    ).reshape(-1,1)
    
    # train_fold_pred는 최종 메타 모델이 사용하는 학습데이터, test_pred_mean은 테스트 데이터
    return train_fold_pred,test_pred_mean

knn_train,knn_test=get_statcking_base_datasets(knn_clf,X_train,y_train,X_test,7)
rf_train,rf_test=get_statcking_base_datasets(rf_clf,X_train,y_train,X_test,7)
dt_train,dt_test=get_statcking_base_datasets(dt_clf,X_train,y_train,X_test,7)
ada_train,ada_test=get_statcking_base_datasets(ada_clf,X_train,y_train,X_test,7)

print('='*100)

Stack_final_X_train=np.concatenate(
    (knn_train,rf_train,dt_train,ada_train)
    ,axis=1
)

Stack_final_X_test=np.concatenate(
    (knn_test,rf_test,dt_test,ada_test)
    ,axis=1
)

print(
    f'\
    원본 학습 피쳐 데이터 Shape : {X_train.shape}, \
    원본 테스트 피쳐 Shape : {X_test.shape}, \
    스태킹 학습 피쳐 데이터 Shape : {Stack_final_X_train.shape},\
    스태킹 테스트 피쳐 데이터 Shape : {Stack_final_X_test.shape}'
)

print('='*100)

lr_final.fit(Stack_final_X_train,y_train)
stack_final=lr_final.predict(Stack_final_X_test)

print(f'최종 메타 모델의 예측 정확도 : {accuracy_score(y_test,stack_final)}')
```
```
KNN 정확도 : 0.9210526315789473
랜덤 포레스트 정확도 : 0.9649122807017544
결정 트리 정확도 : 0.9035087719298246
에이다 부스트 정확도 : 0.9736842105263158
pred.shape : (4, 114)
pred.shape : (114, 4)
최종 메타 모델의 예측 정확도 0.9736842105263158
====================================================================================================
KNeighborsClassifier  model 시작
	 폴드 세트 : 0 시작
	 폴드 세트 : 1 시작
	 폴드 세트 : 2 시작
	 폴드 세트 : 3 시작
	 폴드 세트 : 4 시작
	 폴드 세트 : 5 시작
	 폴드 세트 : 6 시작
RandomForestClassifier  model 시작
	 폴드 세트 : 0 시작
	 폴드 세트 : 1 시작
	 폴드 세트 : 2 시작
	 폴드 세트 : 3 시작
	 폴드 세트 : 4 시작
	 폴드 세트 : 5 시작
	 폴드 세트 : 6 시작
DecisionTreeClassifier  model 시작
	 폴드 세트 : 0 시작
	 폴드 세트 : 1 시작
	 폴드 세트 : 2 시작
	 폴드 세트 : 3 시작
	 폴드 세트 : 4 시작
	 폴드 세트 : 5 시작
	 폴드 세트 : 6 시작
AdaBoostClassifier  model 시작
	 폴드 세트 : 0 시작
	 폴드 세트 : 1 시작
	 폴드 세트 : 2 시작
	 폴드 세트 : 3 시작
	 폴드 세트 : 4 시작
	 폴드 세트 : 5 시작
	 폴드 세트 : 6 시작
====================================================================================================
    원본 학습 피쳐 데이터 Shape : (455, 30),     원본 테스트 피쳐 Shape : (114, 30),     스태킹 학습 피쳐 데이터 Shape : (455, 4),    스태킹 테스트 피쳐 데이터 Shape : (114, 4)
====================================================================================================
최종 메타 모델의 예측 정확도 : 0.9649122807017544
```
