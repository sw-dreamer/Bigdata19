pytorch 설정 
nvidia 버전이 1660이어서 cuda 11.8으로 다운을 하여 설정을 완료 해줍니다. 그 후 아래 명령어로 설치를 합니다.

```
pip install --no-cache-dir torch==2.1.1+cu118 torchvision==0.16.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html
```
```
pip install numpy==1.23.5
```
아래 명령어로 확인을 합니다.
```
import torch


# CUDA(GPU) 사용 가능한지 확인 (True: GPU 사용 가능, False: 사용 불가)
gpu_available = torch.cuda.is_available()
print(f'GPU 사용 가능 여부: {gpu_available}')


if gpu_available:
    # 사용 가능한 GPU 개수 확인
    gpu_count = torch.cuda.device_count()
    print(f'사용 가능한 GPU 개수: {gpu_count}')


    # GPU 이름과 사양 확인
    for gpu_idx in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(gpu_idx)
        print(f'GPU {gpu_idx}: {gpu_name}')


    # 현재 사용 중인 GPU 번호 확인
    current_gpu = torch.cuda.current_device()
    print(f'현재 사용 중인 GPU 번호: {current_gpu}')


else:
    print("GPU가 감지되지 않았습니다. CPU를 사용 중입니다.")
```
![image](https://github.com/user-attachments/assets/0b3f9352-b37d-4156-a1f7-ca100c93b7e7)

---
## 파이토치 탠서 생성
```
import torch
import numpy as np

# 넘파이 환경 설정 : 소수점 3자리까지 표시
np.set_printoptions(precision=3)

# 리스트 생성
a=[1,2,3]

# array 생성
b=np.array(
    [4,5,6]
    ,dtype=np.int32
)

# 리스트로 탠서 생성
t_a=torch.tensor(a)
print(t_a)

# array -> tensor
t_b=torch.from_numpy(b)
print(t_b)
```
![image](https://github.com/user-attachments/assets/0f2a378d-78a4-4d57-a771-b4f915760828)

```
# tensor create : one

import torch

t_ones=torch.ones(2,3) # 2,3은 2 rox x 3 col 로 하겠다는 의미

t_ones
```
![image](https://github.com/user-attachments/assets/6cee664a-285c-4c6a-9252-fea53041a70e)

```
t_ones=torch.zeros(2,3) # 2,3은 2 rox x 3 col 로 하겠다는 의미

t_ones
```
![image](https://github.com/user-attachments/assets/1e4c7a8a-5ecc-4e85-8254-f10f5204e7f6)

---
## 탠서 데이터 타입과 크기 조작

```
import torch

# 텐서는 기본적으로 다차원 배열을 의미하는데, 벡터나 행렬을 포함하는 더 일반적인 개념이라고 볼 수 있습니다. 
# torch.to() : 탠서를 다른 장치나 데이터 타입으로 이동할때 사용
tensor_ = torch.tensor([1, 2, 3])

print(f'tensor_ : {tensor_}')  # 저장되 있는 위치가 dram

# tensor 객체에서 'to' 메서드를 호출하여 GPU로 이동
tensor_gpu = tensor_.to('cuda')

print(f'tensor_gpu : {tensor_gpu}')
```
![image](https://github.com/user-attachments/assets/97e4dad2-1ac0-4d9e-bf43-7eea4388c13a)

```
import torch


# 텐서 전치하기
t=torch.rand(3,5)
t_tr=torch.transpose(t,0,1)
print(f't shape : {t.shape}, t_tr shape : {t_tr.shape}')
print(f't : {t}')
print(f't_tr : {t_tr}')
```
![image](https://github.com/user-attachments/assets/d732f154-53a0-4aac-898b-a7ec8a9a46e0)

```
# 텐서 크기 변경 : reshape
t=torch.zeros(30)
print(t)
t_reshape=t.reshape(5,6)
print(t_reshape)
```
![image](https://github.com/user-attachments/assets/4ead4551-81f4-4950-b92e-a3a6a8ba73fe)

```
# 불필요한 차원 삭제 : squeeze
t=torch.zeros(1,2,1,4,1) # 5차원이다
print(t)

print(f't shape : {t.shape}')
t_squeeze=t.squeeze(
    2
)
print(t_squeeze)
print(f't_squeeze shape : {t_squeeze.shape}')
```
![image](https://github.com/user-attachments/assets/97ff492d-edd1-4a45-9d2a-6fa23a12f571)

```
import numpy as np
import torch
# 차원 추가 : unsqueeze
t=torch.tensor(
    [1,2,3]
)
print(f't shape : {t.shape}')
print(t)

t_n=np.array(
    [1,2,3]
)
print(f't_n shape : {t_n.shape}')

# 텐서 차원 추가
u_t=t.unsqueeze(0) # 0 번째 차원 추가

print(f'u_t shape : {u_t.shape}')
print(u_t)
```
![image](https://github.com/user-attachments/assets/fdb43aa6-e925-4f73-aa8a-cd1e2c5dacd4)

```
# element-wise : 원소별 연산
# 원소별 곱셈
torch.manual_seed(1)
t1=2*torch.rand(5,2)-1
print(t1)
```
![image](https://github.com/user-attachments/assets/8142a826-0183-4378-8081-0133a4486200)

```
# element-wise : 원소별 연산
# 원소별 곱셈
torch.manual_seed(1)
t1=2*torch.rand(5,2)-1
print(t1)
t2=torch.normal(mean=0,std=1,size=(5,2))
print(t2)
t3=torch.multiply(t1,t2)
print(t3)
```
![image](https://github.com/user-attachments/assets/84d2c77b-ef38-46a7-895c-fc12a42f76c8)

```
# 행렬 곱 : dot product (내적)
t1=2*torch.rand(5,2)-1
print(t1.shape)
t2=torch.normal(mean=0,std=1,size=(5,2))
print(t2.shape)
print(torch.transpose(t2,0,1))
t5= torch.matmul(t1,torch.transpose(t2,0,1))
print(t5)
print(t5.shape)
```
![image](https://github.com/user-attachments/assets/85629cf0-f892-4e75-8093-7e93b68d26e8)

---
## 파이토치 입력 파이프라인 구축

```
import torch
from torch.utils.data import DataLoader
t=torch.arange(6,dtype=torch.float32)
data_loader=DataLoader(t)

for item in data_loader:
    print(item)     
print('='*100)
data_loader=DataLoader(t,batch_size=3,drop_last=False)
for batch in data_loader:
    print(f'batch : {batch}')  
print('='*100)
data_loader=DataLoader(t,batch_size=3,drop_last=True)
for batch in data_loader:
    print(f'batch : {batch}')
```
![image](https://github.com/user-attachments/assets/6b443984-40d4-426f-aa8d-b48c7ae63f22)

```
import torch
from torch.utils.data import DataLoader
t=torch.arange(7,dtype=torch.float32)
data_loader=DataLoader(t)

for item in data_loader:
    print(item)     
print('='*100)
data_loader=DataLoader(t,batch_size=3,drop_last=False)
for batch in data_loader:
    print(f'batch : {batch}')  
print('='*100)
data_loader=DataLoader(t,batch_size=3,drop_last=True)
for batch in data_loader:
    print(f'batch : {batch}')
```
![image](https://github.com/user-attachments/assets/42300249-a7f5-4170-8865-f6770f4b0489)

```
from torch.utils.data import DataLoader,TensorDataset

# 텐서 데이터 준비
f=torch.randn(100,3)
print(f'텐서 구조 : {f.shape}')
for idx in range(len(f)):
    print(f[idx])
print('='*100)
labels=torch.randint(0,2,(100,))
print(f'labels shape: {labels.shape}')
print(f'lables :\n{labels}')
print('='*100)
# 텐서를 이용한 데이터셋을 생성
dataset=TensorDataset(f,labels)
print(dataset[0])
for idx in range(len(dataset)):
    print(f'{idx}번째 datset : {dataset[idx]}')
```
```
텐서 구조 : torch.Size([100, 3])
tensor([ 0.5965, -0.2248, -1.3013])
tensor([-0.1356,  1.3967, -0.2600])
tensor([-0.7876, -0.4009, -0.0892])
tensor([-0.1714,  1.3057,  0.0668])
tensor([ 0.6350, -2.1654,  1.3780])
tensor([-1.5427,  0.8177,  0.7472])
tensor([ 0.3395, -1.5277, -0.9528])
tensor([-0.1002, -0.6491,  0.0774])
tensor([ 0.9316,  1.1905, -0.0228])
tensor([ 0.9538, -1.4761, -1.5200])
tensor([-1.3992,  0.2526, -1.0721])
tensor([ 0.5617, -0.1813,  0.6479])
tensor([-1.3754, -1.0257, -1.9801])
tensor([ 0.2045, -0.7652,  2.1713])
tensor([-0.0788, -0.1179, -0.7340])
tensor([-0.3688, -0.2374, -2.5091])
tensor([1.2371, 0.2285, 0.0802])
tensor([-1.4025, -0.3743,  1.2562])
tensor([-0.4114, -1.1657, -0.3619])
tensor([ 0.0813, -0.2030,  1.7867])
tensor([-1.8098, -0.4974, -0.3413])
tensor([ 0.0882, -1.4530,  1.7697])
tensor([ 0.8969,  0.0173, -1.7575])
tensor([ 0.4261, -0.5796,  0.0505])
tensor([-0.1233, -0.4801, -0.1846])
tensor([-0.7148, -0.5029,  0.1585])
tensor([ 0.0535, -0.1655,  0.1797])
tensor([ 0.0186, -0.7067, -0.0158])
tensor([ 1.4318,  2.8418, -0.9929])
tensor([ 1.4532, -0.7069, -0.5511])
tensor([-0.3846,  2.2370,  1.1127])
tensor([-0.1012, -0.1209,  1.4870])
tensor([ 1.5411, -1.8538,  0.3008])
tensor([ 1.6506,  0.0892, -1.1751])
tensor([-1.2228, -0.7439,  1.8599])
tensor([1.1933, 1.0049, 2.3180])
tensor([-0.3098, -0.4866, -1.2543])
tensor([0.0805, 0.2112, 1.6861])
tensor([-0.9734,  0.7408, -0.7772])
tensor([-1.6399, -1.0774, -0.6151])
tensor([-0.3536,  1.4637, -1.0469])
tensor([-1.4068,  0.5273,  1.1568])
tensor([-0.8616,  0.5580,  0.6418])
tensor([-0.9873, -1.2825, -0.7874])
tensor([ 2.5974,  1.0973, -0.1721])
tensor([-0.7066, -0.5636,  0.7665])
tensor([ 2.6821,  0.1160, -0.8742])
tensor([ 0.2659, -1.9265, -0.3953])
tensor([-0.6433, -1.0689,  0.1209])
tensor([1.2312, 0.5676, 0.4610])
tensor([-1.1579, -1.8862, -0.2570])
tensor([0.7474, 1.0907, 0.0654])
tensor([-3.0565e-01,  1.0469e-03,  1.4465e+00])
tensor([0.0050, 1.6177, 0.4709])
tensor([ 1.2555, -0.3513,  0.0651])
tensor([1.2227, 0.5333, 0.5360])
tensor([ 0.8766,  0.6157, -1.9573])
tensor([-0.1894, -0.1300,  1.2484])
tensor([ 1.0727, -0.6915,  0.2683])
tensor([ 0.0778,  0.1452, -0.7557])
tensor([-2.1238,  0.4668,  0.0973])
tensor([0.9798, 0.3907, 0.4044])
tensor([-0.3112,  0.0349, -0.4879])
tensor([-0.3432,  0.0858, -0.2718])
tensor([ 1.5555, -1.0168,  1.3520])
tensor([1.2340, 1.2053, 1.0867])
tensor([ 1.2288, -0.3632, -2.0115])
tensor([ 0.5870,  1.5174, -1.0761])
tensor([-0.1530,  0.4114, -0.1329])
tensor([-1.3254,  0.7425,  1.6147])
tensor([0.6477, 0.5770, 0.6615])
tensor([-0.0672,  0.0892,  0.6578])
tensor([1.8993, 1.1570, 1.8926])
tensor([-0.6104, -0.9517,  0.4295])
tensor([ 0.3012, -0.6417,  0.4153])
tensor([ 1.0272, -0.0930,  0.7601])
tensor([ 0.7303,  0.3738, -1.0710])
tensor([-0.4233, -0.3168, -0.7196])
tensor([1.4817, 0.7792, 0.8348])
tensor([ 0.3894, -2.4872, -1.3875])
tensor([-0.1046, -0.3272, -0.3847])
tensor([-0.1513, -0.7124, -0.2907])
tensor([ 1.2453, -0.4189, -0.4971])
tensor([1.6850, 1.0114, 1.5273])
tensor([-0.7367,  0.2655, -0.0789])
tensor([-0.2676,  0.6184, -0.9178])
tensor([ 0.6649, -1.1846,  0.4253])
tensor([ 0.2321, -0.6932,  1.5286])
tensor([-1.1558,  1.0350,  0.6300])
tensor([-1.1531, -0.4977, -0.1588])
tensor([ 1.1468, -0.1172, -1.4771])
tensor([0.1248, 1.0104, 0.8202])
tensor([ 1.8008, -0.0524,  0.1364])
tensor([-1.2214, -0.5140, -0.4434])
tensor([-1.5338,  0.5087,  0.4622])
tensor([-1.2767, -2.5545, -0.3935])
tensor([0.2856, 1.1013, 0.0768])
tensor([-1.6010, -0.5405, -0.4149])
tensor([-0.3963, -0.4048,  0.5114])
tensor([-0.1092,  1.1605,  0.6342])
====================================================================================================
labels shape: torch.Size([100])
lables :
tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,
        1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,
        1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
        1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,
        0, 1, 1, 0])
====================================================================================================
(tensor([ 0.5965, -0.2248, -1.3013]), tensor(0))
0번째 datset : (tensor([ 0.5965, -0.2248, -1.3013]), tensor(0))
1번째 datset : (tensor([-0.1356,  1.3967, -0.2600]), tensor(0))
2번째 datset : (tensor([-0.7876, -0.4009, -0.0892]), tensor(0))
3번째 datset : (tensor([-0.1714,  1.3057,  0.0668]), tensor(0))
4번째 datset : (tensor([ 0.6350, -2.1654,  1.3780]), tensor(1))
5번째 datset : (tensor([-1.5427,  0.8177,  0.7472]), tensor(1))
6번째 datset : (tensor([ 0.3395, -1.5277, -0.9528]), tensor(1))
7번째 datset : (tensor([-0.1002, -0.6491,  0.0774]), tensor(1))
8번째 datset : (tensor([ 0.9316,  1.1905, -0.0228]), tensor(0))
9번째 datset : (tensor([ 0.9538, -1.4761, -1.5200]), tensor(0))
10번째 datset : (tensor([-1.3992,  0.2526, -1.0721]), tensor(0))
11번째 datset : (tensor([ 0.5617, -0.1813,  0.6479]), tensor(1))
12번째 datset : (tensor([-1.3754, -1.0257, -1.9801]), tensor(1))
13번째 datset : (tensor([ 0.2045, -0.7652,  2.1713]), tensor(0))
14번째 datset : (tensor([-0.0788, -0.1179, -0.7340]), tensor(0))
15번째 datset : (tensor([-0.3688, -0.2374, -2.5091]), tensor(0))
16번째 datset : (tensor([1.2371, 0.2285, 0.0802]), tensor(1))
17번째 datset : (tensor([-1.4025, -0.3743,  1.2562]), tensor(1))
18번째 datset : (tensor([-0.4114, -1.1657, -0.3619]), tensor(1))
19번째 datset : (tensor([ 0.0813, -0.2030,  1.7867]), tensor(1))
20번째 datset : (tensor([-1.8098, -0.4974, -0.3413]), tensor(0))
21번째 datset : (tensor([ 0.0882, -1.4530,  1.7697]), tensor(0))
22번째 datset : (tensor([ 0.8969,  0.0173, -1.7575]), tensor(1))
23번째 datset : (tensor([ 0.4261, -0.5796,  0.0505]), tensor(1))
24번째 datset : (tensor([-0.1233, -0.4801, -0.1846]), tensor(1))
25번째 datset : (tensor([-0.7148, -0.5029,  0.1585]), tensor(0))
26번째 datset : (tensor([ 0.0535, -0.1655,  0.1797]), tensor(1))
27번째 datset : (tensor([ 0.0186, -0.7067, -0.0158]), tensor(0))
28번째 datset : (tensor([ 1.4318,  2.8418, -0.9929]), tensor(1))
29번째 datset : (tensor([ 1.4532, -0.7069, -0.5511]), tensor(0))
30번째 datset : (tensor([-0.3846,  2.2370,  1.1127]), tensor(0))
31번째 datset : (tensor([-0.1012, -0.1209,  1.4870]), tensor(1))
32번째 datset : (tensor([ 1.5411, -1.8538,  0.3008]), tensor(1))
33번째 datset : (tensor([ 1.6506,  0.0892, -1.1751]), tensor(1))
34번째 datset : (tensor([-1.2228, -0.7439,  1.8599]), tensor(1))
35번째 datset : (tensor([1.1933, 1.0049, 2.3180]), tensor(1))
36번째 datset : (tensor([-0.3098, -0.4866, -1.2543]), tensor(1))
37번째 datset : (tensor([0.0805, 0.2112, 1.6861]), tensor(0))
38번째 datset : (tensor([-0.9734,  0.7408, -0.7772]), tensor(1))
39번째 datset : (tensor([-1.6399, -1.0774, -0.6151]), tensor(0))
40번째 datset : (tensor([-0.3536,  1.4637, -1.0469]), tensor(1))
41번째 datset : (tensor([-1.4068,  0.5273,  1.1568]), tensor(1))
42번째 datset : (tensor([-0.8616,  0.5580,  0.6418]), tensor(0))
43번째 datset : (tensor([-0.9873, -1.2825, -0.7874]), tensor(0))
44번째 datset : (tensor([ 2.5974,  1.0973, -0.1721]), tensor(1))
45번째 datset : (tensor([-0.7066, -0.5636,  0.7665]), tensor(0))
46번째 datset : (tensor([ 2.6821,  0.1160, -0.8742]), tensor(0))
47번째 datset : (tensor([ 0.2659, -1.9265, -0.3953]), tensor(1))
48번째 datset : (tensor([-0.6433, -1.0689,  0.1209]), tensor(1))
49번째 datset : (tensor([1.2312, 0.5676, 0.4610]), tensor(1))
50번째 datset : (tensor([-1.1579, -1.8862, -0.2570]), tensor(1))
51번째 datset : (tensor([0.7474, 1.0907, 0.0654]), tensor(1))
52번째 datset : (tensor([-3.0565e-01,  1.0469e-03,  1.4465e+00]), tensor(0))
53번째 datset : (tensor([0.0050, 1.6177, 0.4709]), tensor(1))
54번째 datset : (tensor([ 1.2555, -0.3513,  0.0651]), tensor(1))
55번째 datset : (tensor([1.2227, 0.5333, 0.5360]), tensor(0))
56번째 datset : (tensor([ 0.8766,  0.6157, -1.9573]), tensor(1))
57번째 datset : (tensor([-0.1894, -0.1300,  1.2484]), tensor(1))
58번째 datset : (tensor([ 1.0727, -0.6915,  0.2683]), tensor(0))
59번째 datset : (tensor([ 0.0778,  0.1452, -0.7557]), tensor(1))
60번째 datset : (tensor([-2.1238,  0.4668,  0.0973]), tensor(0))
61번째 datset : (tensor([0.9798, 0.3907, 0.4044]), tensor(0))
62번째 datset : (tensor([-0.3112,  0.0349, -0.4879]), tensor(0))
63번째 datset : (tensor([-0.3432,  0.0858, -0.2718]), tensor(0))
64번째 datset : (tensor([ 1.5555, -1.0168,  1.3520]), tensor(1))
65번째 datset : (tensor([1.2340, 1.2053, 1.0867]), tensor(0))
66번째 datset : (tensor([ 1.2288, -0.3632, -2.0115]), tensor(1))
67번째 datset : (tensor([ 0.5870,  1.5174, -1.0761]), tensor(1))
68번째 datset : (tensor([-0.1530,  0.4114, -0.1329]), tensor(0))
69번째 datset : (tensor([-1.3254,  0.7425,  1.6147]), tensor(0))
70번째 datset : (tensor([0.6477, 0.5770, 0.6615]), tensor(1))
71번째 datset : (tensor([-0.0672,  0.0892,  0.6578]), tensor(1))
72번째 datset : (tensor([1.8993, 1.1570, 1.8926]), tensor(1))
73번째 datset : (tensor([-0.6104, -0.9517,  0.4295]), tensor(0))
74번째 datset : (tensor([ 0.3012, -0.6417,  0.4153]), tensor(0))
75번째 datset : (tensor([ 1.0272, -0.0930,  0.7601]), tensor(0))
76번째 datset : (tensor([ 0.7303,  0.3738, -1.0710]), tensor(1))
77번째 datset : (tensor([-0.4233, -0.3168, -0.7196]), tensor(1))
78번째 datset : (tensor([1.4817, 0.7792, 0.8348]), tensor(1))
79번째 datset : (tensor([ 0.3894, -2.4872, -1.3875]), tensor(0))
80번째 datset : (tensor([-0.1046, -0.3272, -0.3847]), tensor(1))
81번째 datset : (tensor([-0.1513, -0.7124, -0.2907]), tensor(1))
82번째 datset : (tensor([ 1.2453, -0.4189, -0.4971]), tensor(0))
83번째 datset : (tensor([1.6850, 1.0114, 1.5273]), tensor(0))
84번째 datset : (tensor([-0.7367,  0.2655, -0.0789]), tensor(0))
85번째 datset : (tensor([-0.2676,  0.6184, -0.9178]), tensor(0))
86번째 datset : (tensor([ 0.6649, -1.1846,  0.4253]), tensor(1))
87번째 datset : (tensor([ 0.2321, -0.6932,  1.5286]), tensor(1))
88번째 datset : (tensor([-1.1558,  1.0350,  0.6300]), tensor(0))
89번째 datset : (tensor([-1.1531, -0.4977, -0.1588]), tensor(0))
90번째 datset : (tensor([ 1.1468, -0.1172, -1.4771]), tensor(0))
91번째 datset : (tensor([0.1248, 1.0104, 0.8202]), tensor(1))
92번째 datset : (tensor([ 1.8008, -0.0524,  0.1364]), tensor(1))
93번째 datset : (tensor([-1.2214, -0.5140, -0.4434]), tensor(0))
94번째 datset : (tensor([-1.5338,  0.5087,  0.4622]), tensor(1))
95번째 datset : (tensor([-1.2767, -2.5545, -0.3935]), tensor(1))
96번째 datset : (tensor([0.2856, 1.1013, 0.0768]), tensor(0))
97번째 datset : (tensor([-1.6010, -0.5405, -0.4149]), tensor(1))
98번째 datset : (tensor([-0.3963, -0.4048,  0.5114]), tensor(1))
99번째 datset : (tensor([-0.1092,  1.1605,  0.6342]), tensor(0))
```
```
from torch.utils.data import DataLoader,TensorDataset

# 텐서 데이터 준비
f=torch.randn(100,3)
# print(f'텐서 구조 : {f.shape}')
# for idx in range(len(f)):
    # print(f[idx])
# print('='*100)
labels=torch.randint(0,2,(100,))
# print(f'labels shape: {labels.shape}')
# print(f'lables :\n{labels}')
# print('='*100)
# 텐서를 이용한 데이터셋을 생성
dataset=TensorDataset(f,labels)
# print(dataset[0])
# for idx in range(len(dataset)):
    # print(f'{idx}번째 datset : {dataset[idx]}')
# 데이터로더 생성
data_loader=DataLoader(dataset=dataset,batch_size=16,shuffle=True)
for batch_features, batch_labels in data_loader:
    print(f'배치 사이즈 : {batch_features.size()}, 배치 라벨 사이즈 : {batch_labels.size()}')
```
![image](https://github.com/user-attachments/assets/95ce3db0-2cec-4a4d-9b9f-4e740cf3a361)

---

---

## 🧠 임베딩(Embedding)이란?

### 📌 개요

**임베딩(Embedding)** 은 인간의 언어를 기계가 이해할 수 있도록 수치화하는 과정입니다. 구체적으로는 단어나 문장, 문서를 고차원 벡터 공간의 점(숫자 배열)으로 변환하여, 그 의미나 관계성을 수학적으로 분석할 수 있게 합니다.


### 🔍 임베딩의 목적

임베딩을 사용하는 이유는 다음과 같습니다:

- ✅ 텍스트 간 **의미 유사도** 비교 가능  
- 🔍 의미 기반의 **검색 및 추천** 시스템 구현  
- 🧩 텍스트를 수치로 변환하여 **머신러닝 모델에 입력** 가능  
- 📊 차원 축소나 군집화 등 **데이터 분석**에 활용 가능


### 🧭 예: 단어를 벡터로

예를 들어 `"openai"`와 `"upstate"`라는 두 단어가 있을 때, 각각을 임베딩하면 아래처럼 고차원 벡터로 표현됩니다:

- `"openai"` → `[0.123, -0.045, ..., 0.889]`
- `"upstate"` → `[0.321, 0.776, ..., -0.214]`

이 두 벡터의 방향이나 거리를 통해 두 단어가 얼마나 **의미적으로 가까운지** 계산할 수 있습니다.


### 📐 벡터 공간의 특징

- 단어 간의 **의미적 유사성**은 벡터 간의 **거리** 또는 **각도**로 측정합니다.  
- 자주 같이 쓰이거나 비슷한 맥락에서 등장하는 단어들은 **비슷한 벡터**를 가집니다.  
- 반대로 의미가 전혀 다른 단어는 **멀리 떨어진 위치**에 존재합니다.


### 🧠 임베딩의 활용 분야

| 분야 | 설명 |
|------|------|
| 의미 기반 검색 | 키워드가 아닌 의미로 유사 문서를 찾음 |
| 챗봇 및 질문 응답 | 질문과 관련된 답변을 의미 벡터로 찾아냄 |
| 추천 시스템 | 사용자의 행동 또는 관심사와 유사한 항목 추천 |
| 감정 분석 | 문장의 벡터를 분석하여 긍정/부정 감정 분류 |


### 🛠 임베딩 모델 예시

- **OpenAI**: `text-embedding-ada-002` 모델은 대표적인 고성능 텍스트 임베딩 모델입니다.
- **출력 벡터 크기**: 1536차원
- **입력**: 단어, 문장, 문단 모두 가능
- **적용 사례**: 벡터 검색, 유사도 측정, 분류, 클러스터링 등


### ✅ 요약

- 임베딩은 텍스트를 **수치 벡터로 변환**하는 기술입니다.
- 벡터를 통해 기계는 **의미적 유사성**을 이해하고 활용할 수 있습니다.
- 자연어처리(NLP)에서 가장 핵심적인 기술 중 하나입니다.


### 🔗 참고 링크

- [OpenAI Embedding 문서](https://platform.openai.com/docs/guides/embeddings)
- [Word Embedding 개념 설명 (Wikipedia)](https://en.wikipedia.org/wiki/Word_embedding)

---
## 로컬 디스크에 있는 파일에서 데이터셋 만들기 

```
import pathlib
imgdir_path=pathlib.Path('cat_dog_images')
file_list=sorted(
    [str(path) for path in imgdir_path.glob('*.jpg')]
)
print(file_list)
```
![image](https://github.com/user-attachments/assets/2043b840-712e-4376-bba0-88ea42887b9c)

```
import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
import pathlib
imgdir_path=pathlib.Path('cat_dog_images')
file_list=sorted(
    [str(path) for path in imgdir_path.glob('*.jpg')]
)
fig=plt.figure(figsize=(10,5))
for i, file in enumerate(file_list):
    img=Image.open(file)
    print(f'Image shape : {np.array(img).shape}')
    ax = fig.add_subplot(2,3,i+1)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.imshow(img)
    ax.set_title(os.path.basename(file),size=15)
plt.tight_layout()
plt.show()
```
![image](https://github.com/user-attachments/assets/d5aae431-07d2-4af2-b030-8142fb93bd7d)

```
# 파일명에서 레이블 추출 : 강아지(dog)=>1, 고양이(cat)=>0
labels=[1 if 'dog' in os.path.basename(files) else 0 for files in file_list]
print(labels)
```
![image](https://github.com/user-attachments/assets/5b598618-9204-473d-97a4-488196ec858c)
