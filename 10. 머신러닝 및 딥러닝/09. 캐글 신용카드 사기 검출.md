# 캐글 신용카드 사기 검출기 검출

데이터 : [캐글 신용카드 사기 검출기 검출](https://www.kaggle.com/competitions/credit-card-fraud-prediction)


```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

card_df.head()
```
![image](https://github.com/user-attachments/assets/8bb53d08-b998-4bc2-b97d-e3d8ae03f23a)

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

from sklearn.model_selection import train_test_split

def get_preprocessed_df(df=None):
    df_copy = df.copy()
    df_copy.drop('Time',axis=1,inplace=True)
    return df_copy

def get_train_test_dataset(df=None):
    if df is None: 
        return '데이터베이스가 존재하지 않습니다'
    else:
        df_copy = get_preprocessed_df(df)
        X_features = df_copy.iloc[:, :-1]
        y_target = df_copy.iloc[:, -1]
        X_train, X_test, y_train, y_test = train_test_split(
            X_features,
            y_target,
            test_size=0.3,
            random_state=0,
            stratify=y_target
        )
        return X_train, X_test, y_train, y_test


X_train,X_test,y_train,y_test=get_train_test_dataset(card_df)

print('='*50)
print(f'학습 데이터 레이블 값 비율\n{y_train.value_counts()/y_train.shape[0]*100}')
print('='*50)
print(f'테스트 데이터 레이블 값 비율\n{y_test.value_counts()/y_test.shape[0]*100}')
```
![image](https://github.com/user-attachments/assets/328661f9-668d-4d1e-87de-b61dc8347596)

---
## 원본 데이터 가공 없이 모델 학습, 일반화 성능 확인

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

from sklearn.model_selection import train_test_split

def get_preprocessed_df(df=None):
    df_copy = df.copy()
    df_copy.drop('Time',axis=1,inplace=True)
    return df_copy

def get_train_test_dataset(df=None):
    if df is None:  
        return '데이터베이스가 존재하지 않습니다'
    else:
        df_copy = get_preprocessed_df(df)
        X_features = df_copy.iloc[:, :-1]
        y_target = df_copy.iloc[:, -1]
        X_train, X_test, y_train, y_test = train_test_split(
            X_features,
            y_target,
            test_size=0.3,
            random_state=0,
            stratify=y_target
        )
        return X_train, X_test, y_train, y_test

X_train,X_test,y_train,y_test=get_train_test_dataset(card_df)

# print('='*50)
# print(f'학습 데이터 레이블 값 비율\n{y_train.value_counts()/y_train.shape[0]*100}')
# print('='*50)
# print(f'테스트 데이터 레이블 값 비율\n{y_test.value_counts()/y_test.shape[0]*100}')


# 모델 생성 성능 평가 : get_clf_eval(원래답, 예측값, 예측확률)
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, roc_auc_score


def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred) # 정확도 점수
    precision = precision_score(y_test , pred) # 정밀도 점수
    recall = recall_score(y_test , pred) # 재현율 점수
    f1 = f1_score(y_test,pred) # 정밀도, 재현율 조화평균 값
    # ROC-AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba) # AUC 점수 : 불균형 데이터 셋에서 필요
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))

from sklearn.linear_model import LogisticRegression

lr_clf =LogisticRegression(max_iter=1000)
lr_clf.fit(X_train,y_train)
lr_pred=lr_clf.predict(X_test)
lr_pred_proba=lr_clf.predict_proba(X_test)[:,1]

get_clf_eval(y_test,lr_pred,lr_pred_proba)

```
![image](https://github.com/user-attachments/assets/8977c25e-5025-4751-8a22-1c4ce2a3ef3d)

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

from sklearn.model_selection import train_test_split

def get_preprocessed_df(df=None):
    df_copy = df.copy()
    df_copy.drop('Time',axis=1,inplace=True)
    return df_copy

def get_train_test_dataset(df=None):
    if df is None:  
        return '데이터베이스가 존재하지 않습니다'
    else:
        df_copy = get_preprocessed_df(df)
        X_features = df_copy.iloc[:, :-1]
        y_target = df_copy.iloc[:, -1]
        X_train, X_test, y_train, y_test = train_test_split(
            X_features,
            y_target,
            test_size=0.3,
            random_state=0,
            stratify=y_target
        )
        return X_train, X_test, y_train, y_test

X_train,X_test,y_train,y_test=get_train_test_dataset(card_df)

# print('='*50)
# print(f'학습 데이터 레이블 값 비율\n{y_train.value_counts()/y_train.shape[0]*100}')
# print('='*50)
# print(f'테스트 데이터 레이블 값 비율\n{y_test.value_counts()/y_test.shape[0]*100}')

from sklearn.linear_model import LogisticRegression

lr_clf =LogisticRegression(max_iter=1000)
lr_clf.fit(X_train,y_train)
lr_pred=lr_clf.predict(X_test)
lr_pred_proba=lr_clf.predict_proba(X_test)[:,1]


# 모델 생성 성능 평가 : get_clf_eval(원래답, 예측값, 예측확률)
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, roc_auc_score


def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred) # 정확도 점수
    precision = precision_score(y_test , pred) # 정밀도 점수
    recall = recall_score(y_test , pred) # 재현율 점수
    f1 = f1_score(y_test,pred) # 정밀도, 재현율 조화평균 값
    # ROC-AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba) # AUC 점수 : 불균형 데이터 셋에서 필요
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))

def get_model_train_eval(
    model                   # 분류 알고리즘
    ,ftr_train=None         # 학습 데이터
    ,ftr_test=None          # 테스트 데이터
    ,tgt_train=None         # 학습 데이터 레이블
    ,tgt_test=None          # 테스트 데이터 레이블
    ):
    model.fit(ftr_train,tgt_train)
    pred = model.predict(ftr_test)
    pred_proba=model.predict_proba(ftr_test)[:,1] # 예측 확률
    get_clf_eval(tgt_test,pred,pred_proba)

from lightgbm import LGBMClassifier

lgbm_clf = LGBMClassifier(
    n_estimators=1000
    ,num_leaves=64
    #, n_jobs=-1 # cpu 일때만 사용
    ,device='gpu' # gpu 일때만 사용
    ,boosting_from_average=False # 극도로 불균형한 레이블일 경우 False를 줘야 함
)

get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)
```

![image](https://github.com/user-attachments/assets/bb4b5e60-f3bb-4bd1-9f6c-72c5f373acd5)

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

from sklearn.model_selection import train_test_split

def get_preprocessed_df(df=None):
    df_copy = df.copy()
    df_copy.drop('Time',axis=1,inplace=True)
    return df_copy

def get_train_test_dataset(df=None):
    if df is None:  
        return '데이터베이스가 존재하지 않습니다'
    else:
        df_copy = get_preprocessed_df(df)
        X_features = df_copy.iloc[:, :-1]
        y_target = df_copy.iloc[:, -1]
        X_train, X_test, y_train, y_test = train_test_split(
            X_features,
            y_target,
            test_size=0.3,
            random_state=0,
            stratify=y_target
        )
        return X_train, X_test, y_train, y_test

X_train,X_test,y_train,y_test=get_train_test_dataset(card_df)

# print('='*50)
# print(f'학습 데이터 레이블 값 비율\n{y_train.value_counts()/y_train.shape[0]*100}')
# print('='*50)
# print(f'테스트 데이터 레이블 값 비율\n{y_test.value_counts()/y_test.shape[0]*100}')

from sklearn.linear_model import LogisticRegression

lr_clf =LogisticRegression(max_iter=1000)
lr_clf.fit(X_train,y_train)
lr_pred=lr_clf.predict(X_test)
lr_pred_proba=lr_clf.predict_proba(X_test)[:,1]


# 모델 생성 성능 평가 : get_clf_eval(원래답, 예측값, 예측확률)
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, roc_auc_score


def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred) # 정확도 점수
    precision = precision_score(y_test , pred) # 정밀도 점수
    recall = recall_score(y_test , pred) # 재현율 점수
    f1 = f1_score(y_test,pred) # 정밀도, 재현율 조화평균 값
    # ROC-AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba) # AUC 점수 : 불균형 데이터 셋에서 필요
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))

def get_model_train_eval(
    model                   # 분류 알고리즘
    ,ftr_train=None         # 학습 데이터
    ,ftr_test=None          # 테스트 데이터
    ,tgt_train=None         # 학습 데이터 레이블
    ,tgt_test=None          # 테스트 데이터 레이블
    ):
    model.fit(ftr_train,tgt_train)
    pred = model.predict(ftr_test)
    pred_proba=model.predict_proba(ftr_test)[:,1] # 예측 확률
    get_clf_eval(tgt_test,pred,pred_proba)


from lightgbm import LGBMClassifier

lgbm_clf = LGBMClassifier(
    n_estimators=1000
    ,num_leaves=64
    #, n_jobs=-1 # cpu 일때만 사용
    ,device='gpu' # gpu 일때만 사용
    ,boosting_from_average=False # 극도로 불균형한 레이블일 경우 False를 줘야 함
)

# lightGBM
get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)

# LogisticRegression
get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)
```
![image](https://github.com/user-attachments/assets/ac09dbe7-edea-40e5-8c34-0d8363bd1d5c)

---
## 데이터 분포 확인, 변환후 모델 학습/예측/평가

```
# 특정 피쳐(금액)의 데이터 분포 확인
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

import seaborn as sns

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

plt.figure(figsize=(8,4))
plt.xticks(
    range(0,30000,1000)
    ,rotation=60
)
sns.histplot(card_df['Amount'],bins=100,kde=True)
plt.show()
```
![image](https://github.com/user-attachments/assets/b32af0f7-1e8b-4743-bd6b-f3629af769b7)

---

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline  

import warnings
warnings.filterwarnings('ignore')  

import seaborn as sns

# CSV 파일을 읽어와 DataFrame으로 저장
card_df = pd.read_csv(
    './creditcard.csv',  # 신용카드 거래 데이터 파일 경로
    encoding='utf-8'  # UTF-8 인코딩으로 파일을 읽음
)

# 외도(Skewness) 값 확인: 데이터의 비대칭성을 확인하기 위함
# 비대칭 데이터의 경우 로그 변환 등으로 정규성을 확보할 필요가 있음

# 첨도(Kurtosis) 값 확인: 극단값(outlier)의 존재 여부를 판단하기 위함
# 양의 첨도: 분포의 꼬리가 두껍고, 중앙이 뾰족 -> 극단값이 자주 발생
#           -> 극단값 처리가 필요하며, 적절한 모델 선택이 중요
# 음의 첨도: 분포의 꼬리가 얇고, 중앙이 평평 -> 극단값이 적게 발생
# 중간 첨도: 정규분포에 가까움 (외도와 첨도가 0에 가까움)

from scipy.stats import skew  # 외도 계산 함수
from scipy.stats import kurtosis  # 첨도 계산 함수

# 'Amount' 열의 외도(Skewness) 값 출력
print(f"외도 : {skew(card_df['Amount'])}")
print(f"첨도 : {kurtosis(card_df['Amount'])}")
```
![image](https://github.com/user-attachments/assets/9fc70ec9-5e36-4415-800c-3abcccc2cccc)

---
## 📊 모수적 vs 비모수적 검정 방법 정리

### 1. t-test (독립표본 t-검정, 대응표본 t-검정)
#### 🔹 특징
- 두 그룹의 **평균 차이**를 비교하는 **모수적 검정**  
- 데이터가 **정규성을 만족해야** 함  
- **대응표본 t-검정**: 같은 집단의 사전-사후 데이터를 비교  
- **독립표본 t-검정**: 서로 다른 두 집단을 비교  

#### ✅ 장점
- 해석이 직관적이며 널리 사용됨  
- 검정력이 강하여 비교적 적은 표본에서도 신뢰성 확보 가능  

#### ❌ 단점
- 정규성을 만족하지 않으면 사용하기 어려움  
- 등분산성을 가정해야 함 (등분산이 다르면 Welch’s t-test 사용)  

---

### 2. Mann-Whitney U test (윌콕슨 순위합 검정)
#### 🔹 특징
- 두 그룹의 **중위수 차이**를 비교하는 **비모수 검정**  
- 데이터의 크기 순서(순위)를 이용하여 비교  
- 정규성을 만족하지 않아도 사용 가능  

#### ✅ 장점
- 정규성 가정이 필요 없음 → 소규모 샘플에서도 활용 가능  
- 이상치(outlier)에 덜 민감함  

#### ❌ 단점
- 평균이 아닌 **중위수 비교**이므로 평균 차이를 확인하는 데 한계가 있음  
- 표본 크기가 클 경우 검정력이 낮아질 수 있음  

---

### 3. ANOVA (분산 분석, Analysis of Variance)
#### 🔹 특징
- 세 그룹 이상의 **평균 차이**를 비교하는 **모수적 검정**  
- 정규성과 등분산성을 만족해야 함  
- 집단 간 분산과 집단 내 분산을 이용하여 차이를 분석  

#### ✅ 장점
- 세 그룹 이상을 동시에 비교할 수 있어 **다중 비교 문제 방지**  
- 그룹 간 차이를 분석하는 데 효과적  

#### ❌ 단점
- 정규성과 등분산성을 만족하지 않으면 부적절함  
- 차이가 있다고만 알려주며, **어느 그룹 간 차이가 있는지 추가 분석(Tukey HSD 등)이 필요**  

---

### 4. Kruskal-Wallis test (크루스칼-왈리스 검정)
#### 🔹 특징
- 세 그룹 이상의 **중위수 차이**를 비교하는 **비모수 검정**  
- 정규성을 만족하지 않아도 사용 가능  
- 데이터의 순위를 이용하여 비교  

#### ✅ 장점
- 정규성을 가정할 필요 없음  
- 이상치에 덜 민감하여 다양한 데이터에 적용 가능  

#### ❌ 단점
- 평균이 아닌 **중위수를 비교**하므로 모수적 방법보다 덜 강력함  
- 그룹 간 어느 부분에서 차이가 나는지 추가 분석 필요  

---

### 📌 요약 정리

| 비교 대상 | 모수적 방법 | 비모수적 방법 |
|-----------|------------|--------------|
| **두 그룹 비교 (평균)** | t-test | Mann-Whitney U test (Wilcoxon rank-sum test) |
| **세 그룹 이상 비교 (평균)** | ANOVA | Kruskal-Wallis test |


| 검정 방법 | 특징 | 장점 | 단점 |
|----------|------|------|------|
| **t-test** | 두 그룹의 평균 비교 (모수) | 검정력이 강함, 직관적 해석 가능 | 정규성 필요, 등분산 가정 필요 |
| **Mann-Whitney U test** | 두 그룹의 중위수 비교 (비모수) | 정규성 필요 없음, 이상치에 강함 | 평균 비교 불가, 큰 표본에서 검정력 낮음 |
| **ANOVA** | 세 그룹 이상의 평균 비교 (모수) | 다중 비교 가능, 효과적인 그룹 차이 분석 | 정규성·등분산 필요, 추가 분석 필요 |
| **Kruskal-Wallis test** | 세 그룹 이상의 중위수 비교 (비모수) | 정규성 필요 없음, 이상치에 강함 | 평균 비교 불가, 추가 분석 필요 |

---
## 📊 정규성 판단 방법 정리

### **1. 통계적 검정 방법**
정규성을 확인하기 위한 다양한 **유의확률 기반 검정 방법**입니다.

#### 📌 **1) Shapiro-Wilk Test**
- **특징**: 가장 널리 사용되는 정규성 검정 방법  
- **사용 조건**: 샘플 크기가 작을 때(50 이하) 적합  

✅ **장점**  
- 소규모 샘플(≤50개)에 대해 높은 검정력 제공  
- 비교적 정확한 정규성 검정 가능  

❌ **단점**  
- 샘플 크기가 커지면 검정력이 너무 강해져 정규성을 쉽게 기각할 수 있음  
- 이상치(outlier)에 민감  

---

#### 📌 **2) Kolmogorov-Smirnov Test (K-S Test)**
- **특징**: 정규분포와 데이터 분포를 비교하여 정규성 검정  
- **사용 조건**: 대규모 샘플에서 사용 가능하지만, 정확성이 낮음  

✅ **장점**  
- 샘플 크기에 상관없이 적용 가능  
- 분포의 차이를 직접 비교하는 방식  

❌ **단점**  
- 검정력이 낮아 정규성을 정확히 판별하지 못할 수 있음  
- 샘플 크기가 크면 정규성을 기각할 가능성이 커짐  

---

#### 📌 **3) Anderson-Darling Test**
- **특징**: Kolmogorov-Smirnov Test보다 정밀한 정규성 검정 방법  
- **사용 조건**: 샘플 크기에 상관없이 활용 가능  

✅ **장점**  
- 샘플 크기에 크게 영향을 받지 않음  
- 분포의 꼬리 부분까지 고려하여 정규성을 판단  

❌ **단점**  
- Shapiro-Wilk Test보다 덜 직관적  
- 특정한 상황에서 p-value 해석이 어려울 수 있음  

---

#### 📌 **4) Jarque-Bera Test**
- **특징**: 데이터의 **왜도(skewness)와 첨도(kurtosis)** 를 이용한 정규성 검정  
- **사용 조건**: 대규모 샘플에서 사용  

✅ **장점**  
- 큰 샘플에서도 신뢰할 수 있는 결과 제공  
- 왜도와 첨도를 함께 고려하여 정규성 검정 가능  

❌ **단점**  
- 소규모 샘플에서는 검정력이 낮아 비효율적  
- 왜도와 첨도가 극단적인 경우 정규성을 정확히 판단하기 어려움  

---

### **2. 시각적 분석 방법**
정규성을 **직관적으로 확인**하는 방법입니다.

#### 📌 **1) 히스토그램 (Histogram)**
- **특징**: 데이터의 분포가 종모양(정규분포)인지 확인  

✅ **장점**  
- 정규성을 빠르게 시각적으로 확인 가능  
- 직관적인 해석 가능  

❌ **단점**  
- 샘플 크기가 작으면 부정확할 수 있음  
- 육안 판단이므로 주관적일 수 있음  

---

#### 📌 **2) Q-Q Plot (Quantile-Quantile Plot)**
- **특징**: 데이터의 분위수를 정규분포의 분위수와 비교  

✅ **장점**  
- 정규성을 시각적으로 쉽게 판단 가능  
- 정규성 여부뿐만 아니라 데이터 분포의 특성(왜도, 이상치)도 확인 가능  

❌ **단점**  
- 해석이 다소 어려울 수 있음  
- 육안 판단이므로 정확한 검정 방법은 아님  

---

#### 📌 **3) P-P Plot (Probability-Probability Plot)**
- **특징**: 표본 데이터의 누적분포와 정규분포의 누적분포를 비교  

✅ **장점**  
- Q-Q Plot과 유사하지만 누적분포를 기반으로 하기 때문에 정규성 검정에 더 유리  

❌ **단점**  
- 데이터 수가 많아질수록 해석이 어려워질 수 있음  

---

#### 📌 **4) Box Plot (상자 그림)**
- **특징**: 데이터의 대칭성과 이상치(outlier)를 확인  

✅ **장점**  
- 데이터의 분포를 직관적으로 볼 수 있음  
- 이상치가 있는지 쉽게 확인 가능  

❌ **단점**  
- 정규성을 직접적으로 검정할 수 없음  
- 샘플 크기가 작으면 왜곡될 가능성이 있음  

---

### **📌 정규성 판단 방법 비교표**

| 방법 | 특징 | 장점 | 단점 |
|------|------|------|------|
| **Shapiro-Wilk Test** | 가장 널리 사용되는 정규성 검정 | 소규모 샘플(≤50)에서 높은 검정력 | 대규모 샘플에서 과도하게 정규성을 기각할 가능성 있음 |
| **Kolmogorov-Smirnov Test** | 정규분포와 데이터 분포를 비교 | 샘플 크기에 관계없이 적용 가능 | 검정력이 낮아 정규성을 정확히 판별하기 어려움 |
| **Anderson-Darling Test** | K-S Test보다 정밀한 정규성 검정 | 샘플 크기 영향을 덜 받음 | 해석이 다소 어려울 수 있음 |
| **Jarque-Bera Test** | 왜도와 첨도를 이용한 정규성 검정 | 대규모 샘플에서 신뢰성 높음 | 소규모 샘플에서는 검정력이 낮음 |
| **히스토그램** | 데이터 분포가 정규성을 따르는지 확인 | 직관적인 해석 가능 | 샘플 크기가 작으면 부정확할 수 있음 |
| **Q-Q Plot** | 데이터 분위수와 정규분포 분위수를 비교 | 왜도, 이상치 등을 한눈에 파악 가능 | 해석이 다소 어려울 수 있음 |
| **P-P Plot** | 누적분포를 비교하여 정규성 검정 | Q-Q Plot보다 정규성 검정에 유리 | 데이터 수가 많아지면 해석 어려움 |
| **Box Plot** | 데이터의 대칭성과 이상치 확인 | 이상치를 쉽게 발견 가능 | 정규성을 직접 검정할 수 없음 |

---

### **✅ 정규성 판단 흐름**
1️⃣ **시각적 방법(Q-Q Plot, 히스토그램 등)으로 대략적인 정규성 확인**  
2️⃣ **통계적 검정(Shapiro-Wilk Test, K-S Test 등) 수행**  
3️⃣ **p-value ≥ 0.05** → 정규성 만족 (모수 검정 가능)  
4️⃣ **p-value < 0.05** → 정규성 불만족 (비모수 검정 필요)  

📌 **정규성 검정은 데이터 특성에 따라 적절한 방법을 선택하는 것이 중요합니다!** 🚀

