# 캐글 신용카드 사기 검출기 검출

데이터 : [캐글 신용카드 사기 검출기 검출](https://www.kaggle.com/competitions/credit-card-fraud-prediction)

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

card_df.head()
```
![image](https://github.com/user-attachments/assets/8bb53d08-b998-4bc2-b97d-e3d8ae03f23a)

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

from sklearn.model_selection import train_test_split

def get_preprocessed_df(df=None):
    df_copy = df.copy()
    df_copy.drop('Time',axis=1,inplace=True)
    return df_copy

def get_train_test_dataset(df=None):
    if df is None: 
        return '데이터베이스가 존재하지 않습니다'
    else:
        df_copy = get_preprocessed_df(df)
        X_features = df_copy.iloc[:, :-1]
        y_target = df_copy.iloc[:, -1]
        X_train, X_test, y_train, y_test = train_test_split(
            X_features,
            y_target,
            test_size=0.3,
            random_state=0,
            stratify=y_target
        )
        return X_train, X_test, y_train, y_test


X_train,X_test,y_train,y_test=get_train_test_dataset(card_df)

print('='*50)
print(f'학습 데이터 레이블 값 비율\n{y_train.value_counts()/y_train.shape[0]*100}')
print('='*50)
print(f'테스트 데이터 레이블 값 비율\n{y_test.value_counts()/y_test.shape[0]*100}')
```
![image](https://github.com/user-attachments/assets/328661f9-668d-4d1e-87de-b61dc8347596)

---
## 로지스틱
```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

card_df=pd.read_csv(
    './creditcard.csv'
    ,encoding='utf-8'
)

from sklearn.model_selection import train_test_split

def get_preprocessed_df(df=None):
    df_copy = df.copy()
    df_copy.drop('Time',axis=1,inplace=True)
    return df_copy

def get_train_test_dataset(df=None):
    if df is None:  
        return '데이터베이스가 존재하지 않습니다'
    else:
        df_copy = get_preprocessed_df(df)
        X_features = df_copy.iloc[:, :-1]
        y_target = df_copy.iloc[:, -1]
        X_train, X_test, y_train, y_test = train_test_split(
            X_features,
            y_target,
            test_size=0.3,
            random_state=0,
            stratify=y_target
        )
        return X_train, X_test, y_train, y_test

X_train,X_test,y_train,y_test=get_train_test_dataset(card_df)

# print('='*50)
# print(f'학습 데이터 레이블 값 비율\n{y_train.value_counts()/y_train.shape[0]*100}')
# print('='*50)
# print(f'테스트 데이터 레이블 값 비율\n{y_test.value_counts()/y_test.shape[0]*100}')


# 모델 생성 성능 평가 : get_clf_eval(원래답, 예측값, 예측확률)
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, roc_auc_score


def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred) # 정확도 점수
    precision = precision_score(y_test , pred) # 정밀도 점수
    recall = recall_score(y_test , pred) # 재현율 점수
    f1 = f1_score(y_test,pred) # 정밀도, 재현율 조화평균 값
    # ROC-AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba) # AUC 점수 : 불균형 데이터 셋에서 필요
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))

from sklearn.linear_model import LogisticRegression

lr_clf =LogisticRegression(max_iter=1000)
lr_clf.fit(X_train,y_train)
lr_pred=lr_clf.predict(X_test)
lr_pred_proba=lr_clf.predict_proba(X_test)[:,1]

get_clf_eval(y_test,lr_pred,lr_pred_proba)

```
![image](https://github.com/user-attachments/assets/8977c25e-5025-4751-8a22-1c4ce2a3ef3d)
