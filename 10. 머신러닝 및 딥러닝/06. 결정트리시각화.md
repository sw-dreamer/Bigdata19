## 결정트리시각화

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# DecisionTree Classifier 생성
dt_clf = DecisionTreeClassifier(random_state=156, max_depth=3)

# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리
iris_data = load_iris()
X_train , X_test , y_train , y_test = train_test_split(
    iris_data.data
    , iris_data.target
    , test_size=0.2
    , random_state=11)

# DecisionTreeClassifer 학습. 
dt_clf.fit(X_train , y_train)
print(f'DecisionTreeClassifer 학습\n {dt_clf.fit(X_train , y_train)}')
```
![image](https://github.com/user-attachments/assets/9fe0d92b-e50c-4be0-aa38-98a5fc7b565f)

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# DecisionTree Classifier 생성
dt_clf = DecisionTreeClassifier(random_state=156, max_depth=3)

# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리
iris_data = load_iris()
X_train , X_test , y_train , y_test = train_test_split(
    iris_data.data
    , iris_data.target
    , test_size=0.2
    , random_state=11)

# DecisionTreeClassifer 학습. 
dt_clf.fit(X_train , y_train)
# print(f'DecisionTreeClassifer 학습\n{dt_clf.fit(X_train , y_train)}')

from sklearn.tree import export_graphviz

# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함.
export_graphviz(
    dt_clf, out_file="./tree.dot"
    , class_names=iris_data.target_names
    ,feature_names = iris_data.feature_names
    , impurity=True
    , filled=True
)
```
![image](https://github.com/user-attachments/assets/134a596c-bbcb-4531-bb6c-8fdbda03608f)

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# DecisionTree Classifier 생성
dt_clf = DecisionTreeClassifier(random_state=156, max_depth=3)

# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리
iris_data = load_iris()
X_train , X_test , y_train , y_test = train_test_split(
    iris_data.data
    , iris_data.target
    , test_size=0.2
    , random_state=11)

# DecisionTreeClassifer 학습. 
dt_clf.fit(X_train , y_train)
# print(f'DecisionTreeClassifer 학습\n{dt_clf.fit(X_train , y_train)}')

from sklearn.tree import export_graphviz

# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함.
export_graphviz(
    dt_clf, out_file="./tree.dot"
    , class_names=iris_data.target_names
    ,feature_names = iris_data.feature_names
    , impurity=True
    , filled=True
)

# 피처 중요도 시각화
# 피처 중요도 파악
import seaborn as sns
import numpy as np
# %matplotlib inline


# feature importance 추출
print("Feature importances:\n{0}".format(np.round(dt_clf.feature_importances_, 3)))


# feature별 importance 매핑
for name, value in zip(iris_data.feature_names , dt_clf.feature_importances_):
    print('{0} : {1:.3f}'.format(name, value))


# feature importance를 column 별로 시각화 하기
sns.barplot(x=dt_clf.feature_importances_ , y=iris_data.feature_names)
```
![image](https://github.com/user-attachments/assets/f030ae6a-c5f1-4233-a0cf-6c1f61306135)

![image](https://github.com/user-attachments/assets/e7e43d0a-5cf5-4323-8002-6104a5ac4f66)

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# DecisionTree Classifier 생성
dt_clf = DecisionTreeClassifier(random_state=156, max_depth=3)

# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리
iris_data = load_iris()
X_train , X_test , y_train , y_test = train_test_split(
    iris_data.data
    , iris_data.target
    , test_size=0.2
    , random_state=11)

# DecisionTreeClassifer 학습. 
dt_clf.fit(X_train , y_train)
# print(f'DecisionTreeClassifer 학습\n{dt_clf.fit(X_train , y_train)}')

from sklearn.tree import export_graphviz

# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함.
export_graphviz(
    dt_clf, out_file="./tree.dot"
    , class_names=iris_data.target_names
    ,feature_names = iris_data.feature_names
    , impurity=True
    , filled=True
)

# 피처 중요도 시각화
# 피처 중요도 파악
import seaborn as sns
import numpy as np
# %matplotlib inline


# feature importance 추출
print("Feature importances:\n{0}".format(np.round(dt_clf.feature_importances_, 3)))


# feature별 importance 매핑
for name, value in zip(iris_data.feature_names , dt_clf.feature_importances_):
    print('{0} : {1:.3f}'.format(name, value))


# feature importance를 column 별로 시각화 하기
sns.barplot(x=dt_clf.feature_importances_ , y=iris_data.feature_names)

# 과적합 처리
# 데이터 생성
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
%matplotlib inline


plt.title("3 Class values with 2 Features Sample data creation")


# 2차원 시각화를 위해서 feature는 2개, 결정값 클래스는 3가지 유형의 classification 샘플 데이터 생성.
X_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,
                             n_classes=3, n_clusters_per_class=1,random_state=0)


# plot 형태로 2개의 feature로 2차원 좌표 시각화, 각 클래스값은 다른 색깔로 표시됨.
plt.scatter(X_features[:, 0], X_features[:, 1], marker='o', c=y_labels, s=25, cmap='rainbow', edgecolor='k')
plt.show()
```
![image](https://github.com/user-attachments/assets/35f72173-6a25-4ed6-bdd7-eeb5f8b05677)

![image](https://github.com/user-attachments/assets/975b5d7c-b2eb-4c02-a064-4a519fbd9bff)

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# DecisionTree Classifier 생성
dt_clf = DecisionTreeClassifier(random_state=156, max_depth=3)

# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리
iris_data = load_iris()
X_train , X_test , y_train , y_test = train_test_split(
    iris_data.data
    , iris_data.target
    , test_size=0.2
    , random_state=11)

# DecisionTreeClassifer 학습. 
dt_clf.fit(X_train , y_train)
# print(f'DecisionTreeClassifer 학습\n{dt_clf.fit(X_train , y_train)}')

from sklearn.tree import export_graphviz

# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함.
export_graphviz(
    dt_clf, out_file="./tree.dot"
    , class_names=iris_data.target_names
    ,feature_names = iris_data.feature_names
    , impurity=True
    , filled=True
)

# 피처 중요도 시각화
# 피처 중요도 파악
import seaborn as sns
import numpy as np
# %matplotlib inline


# feature importance 추출
# print("Feature importances:\n{0}".format(np.round(dt_clf.feature_importances_, 3)))


# feature별 importance 매핑
# for name, value in zip(iris_data.feature_names , dt_clf.feature_importances_):
    # print('{0} : {1:.3f}'.format(name, value))


# feature importance를 column 별로 시각화 하기
# sns.barplot(x=dt_clf.feature_importances_ , y=iris_data.feature_names)

# # 과적합 처리
# # 데이터 생성
# from sklearn.datasets import make_classification
# import matplotlib.pyplot as plt
# %matplotlib inline

# plt.title("3 Class values with 2 Features Sample data creation")


# # 2차원 시각화를 위해서 feature는 2개, 결정값 클래스는 3가지 유형의 classification 샘플 데이터 생성.
# X_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,
#                              n_classes=3, n_clusters_per_class=1,random_state=0)


# # plot 형태로 2개의 feature로 2차원 좌표 시각화, 각 클래스값은 다른 색깔로 표시됨.
# plt.scatter(X_features[:, 0], X_features[:, 1], marker='o', c=y_labels, s=25, cmap='rainbow', edgecolor='k')

# Classifier의 Decision Boundary를 시각화 하는 함수
def visualize_boundary(model, X, y):
    fig,ax = plt.subplots()
   
    # 학습 데이타 scatter plot으로 나타내기
    ax.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='rainbow', edgecolor='k',
               clim=(y.min(), y.max()), zorder=3)
    ax.axis('tight')
    ax.axis('off')
    xlim_start , xlim_end = ax.get_xlim()
    ylim_start , ylim_end = ax.get_ylim()
   
    # 호출 파라미터로 들어온 training 데이타로 model 학습 .
    model.fit(X, y)
    # meshgrid 형태인 모든 좌표값으로 예측 수행.
    xx, yy = np.meshgrid(np.linspace(xlim_start,xlim_end, num=200),np.linspace(ylim_start,ylim_end, num=200))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)
   
    # contourf() 를 이용하여 class boundary 를 visualization 수행.
    n_classes = len(np.unique(y))
    contours = ax.contourf(xx, yy, Z, alpha=0.3,
                           levels=np.arange(n_classes + 1) - 0.5,
                           cmap='rainbow', clim=(y.min(), y.max()),
                           zorder=1)


from sklearn.tree import DecisionTreeClassifier

# 학습이 종료된 모델 나왔다
dt_clf=DecisionTreeClassifier(random_state=156).fit(X_features, y_labels)
visualize_boundary(dt_clf, X_features, y_labels)
plt.show()
```
![image](https://github.com/user-attachments/assets/5f27907b-7c36-411a-b235-e8bad86ba63f)

![image](https://github.com/user-attachments/assets/ab6ee2b0-24ef-4c14-971a-628dfdf5bb21)

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# DecisionTree Classifier 생성
dt_clf = DecisionTreeClassifier(random_state=156, max_depth=3)

# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리
iris_data = load_iris()
X_train , X_test , y_train , y_test = train_test_split(
    iris_data.data
    , iris_data.target
    , test_size=0.2
    , random_state=11)

# DecisionTreeClassifer 학습. 
dt_clf.fit(X_train , y_train)
# print(f'DecisionTreeClassifer 학습\n{dt_clf.fit(X_train , y_train)}')

from sklearn.tree import export_graphviz

# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함.
export_graphviz(
    dt_clf, out_file="./tree.dot"
    , class_names=iris_data.target_names
    ,feature_names = iris_data.feature_names
    , impurity=True
    , filled=True
)

# 피처 중요도 시각화
# 피처 중요도 파악
import seaborn as sns
import numpy as np
# %matplotlib inline


# feature importance 추출
# print("Feature importances:\n{0}".format(np.round(dt_clf.feature_importances_, 3)))


# feature별 importance 매핑
# for name, value in zip(iris_data.feature_names , dt_clf.feature_importances_):
    # print('{0} : {1:.3f}'.format(name, value))


# feature importance를 column 별로 시각화 하기
# sns.barplot(x=dt_clf.feature_importances_ , y=iris_data.feature_names)

# # 과적합 처리
# # 데이터 생성
# from sklearn.datasets import make_classification
# import matplotlib.pyplot as plt
# %matplotlib inline

# plt.title("3 Class values with 2 Features Sample data creation")


# # 2차원 시각화를 위해서 feature는 2개, 결정값 클래스는 3가지 유형의 classification 샘플 데이터 생성.
# X_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,
#                              n_classes=3, n_clusters_per_class=1,random_state=0)


# # plot 형태로 2개의 feature로 2차원 좌표 시각화, 각 클래스값은 다른 색깔로 표시됨.
# plt.scatter(X_features[:, 0], X_features[:, 1], marker='o', c=y_labels, s=25, cmap='rainbow', edgecolor='k')

# Classifier의 Decision Boundary를 시각화 하는 함수
def visualize_boundary(model, X, y):
    fig,ax = plt.subplots()
   
    # 학습 데이타 scatter plot으로 나타내기
    ax.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='rainbow', edgecolor='k',
               clim=(y.min(), y.max()), zorder=3)
    ax.axis('tight')
    ax.axis('off')
    xlim_start , xlim_end = ax.get_xlim()
    ylim_start , ylim_end = ax.get_ylim()
   
    # 호출 파라미터로 들어온 training 데이타로 model 학습 .
    model.fit(X, y)
    # meshgrid 형태인 모든 좌표값으로 예측 수행.
    xx, yy = np.meshgrid(np.linspace(xlim_start,xlim_end, num=200),np.linspace(ylim_start,ylim_end, num=200))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)
   
    # contourf() 를 이용하여 class boundary 를 visualization 수행.
    n_classes = len(np.unique(y))
    contours = ax.contourf(xx, yy, Z, alpha=0.3,
                           levels=np.arange(n_classes + 1) - 0.5,
                           cmap='rainbow', clim=(y.min(), y.max()),
                           zorder=1)


from sklearn.tree import DecisionTreeClassifier

# 학습이 종료된 모델 나왔다
# dt_clf=DecisionTreeClassifier(random_state=156).fit(X_features, y_labels)
# visualize_boundary(dt_clf, X_features, y_labels)

# min_samples_leaf=6 으로 트리 생성 조건을 제약한 Decision Boundary 시각화
dt_clf = DecisionTreeClassifier(min_samples_leaf=6, random_state=156).fit(X_features, y_labels)
visualize_boundary(dt_clf, X_features, y_labels)


plt.show()
```
![image](https://github.com/user-attachments/assets/d7e64871-f4e8-4a90-b95f-4f12a567aa7d)

---
## 결정 트리 실습

https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones 에서 데이터 다운로드

```
import pandas as pd
import numpy as np
import matplotlib as plt

# 피처명 읽기
# features.txt 파일에는 피쳐 이름 index와 피쳐명이 공백으로 분리되어 있음
# 이름 DataFrame 롣,
# \s+ => \s : white space (공백,\n,\r,\) 한자
# + : 한개 이상
feature_name_dir=pd.read_csv(
    './UCI HAR Dataset/data/features.txt'
    ,sep='\s+'
    ,header=None
    ,names=['column_index','column_name']
)
feature_name_dir.head()
```
![image](https://github.com/user-attachments/assets/704f531b-2e37-4cb4-b0f8-b25654039f71)

```
import pandas as pd
import numpy as np
import matplotlib as plt

# 피처명 읽기
# features.txt 파일에는 피쳐 이름 index와 피쳐명이 공백으로 분리되어 있음
# 이름 DataFrame 롣,
# \s+ => \s : white space (공백,\n,\r,\) 한자
# + : 한개 이상
feature_name_dir=pd.read_csv(
    './UCI HAR Dataset/data/features.txt'
    ,sep='\s+'
    ,header=None
    ,names=['column_index','column_name']
)

# 중복된 피쳐명 확인

feature_dup_df = feature_name_dir.groupby(
    'column_name'
).count()

print(f"중복된 개수 확인 : {feature_dup_df[feature_dup_df['column_index']>1].count()}")
```
![image](https://github.com/user-attachments/assets/c49c2387-52b7-4208-843e-f052e7cf6bef)

```
import pandas as pd
import numpy as np
import matplotlib as plt

# 피처명 읽기
# features.txt 파일에는 피쳐 이름 index와 피쳐명이 공백으로 분리되어 있음
# 이름 DataFrame 롣,
# \s+ => \s : white space (공백,\n,\r,\) 한자
# + : 한개 이상
feature_name_dir=pd.read_csv(
    './UCI HAR Dataset/data/features.txt'
    ,sep='\s+'
    ,header=None
    ,names=['column_index','column_name']
)

# 중복된 피쳐명 확인

feature_dup_df = feature_name_dir.groupby(
    'column_name'
).count()

def get_new_feature_name_df(old_feature_name_df):
    feature_dup_df = pd.DataFrame(
        data=old_feature_name_df.groupby('column_name').cumcount()
        ,columns=['dup_cnt']
    )
    feature_dup_df = feature_dup_df.reset_index()
    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')
    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(
        lambda x : x[0]+'_'+str(x[1]) if x[1] >0 else x[0]
        ,axis=1
    )
    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)
    return new_feature_name_df

def get_human_dataset( ):
   
    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.
    feature_name_df = pd.read_csv('./UCI HAR Dataset/data/features.txt',sep='\s+',
                        header=None,names=['column_index','column_name'])
   
    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성.
    new_feature_name_df = get_new_feature_name_df(feature_name_df)
   
    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환
    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()
   
    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용
    X_train = pd.read_csv('./UCI HAR Dataset/data/train/X_train.txt',sep='\s+', names=feature_name )
    X_test = pd.read_csv('./UCI HAR Dataset/data//test/X_test.txt',sep='\s+', names=feature_name)
   
    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여
    y_train = pd.read_csv('./UCI HAR Dataset/data/train/y_train.txt',sep='\s+',header=None,names=['action'])
    y_test = pd.read_csv('./UCI HAR Dataset/data/test/y_test.txt',sep='\s+',header=None,names=['action'])
   
    # 로드된 학습/테스트용 DataFrame을 모두 반환
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = get_human_dataset()

print('학습 데이터 구조')
print(f'X_train shape : {X_train.shape}')
print(f'X_test shape : {X_test.shape}')
print(f'y_train shape : {y_train.shape}')
print(f'y_test shape : {y_test.shape}')

# 행동-답 확인
print(f"행동-답 확인\n{y_train['action']}")
```
![image](https://github.com/user-attachments/assets/4a87c1ab-b431-4455-8ac4-a528ab0aaab5)

```
import pandas as pd
import numpy as np
import matplotlib as plt

# 피처명 읽기
# features.txt 파일에는 피쳐 이름 index와 피쳐명이 공백으로 분리되어 있음
# 이름 DataFrame 롣,
# \s+ => \s : white space (공백,\n,\r,\) 한자
# + : 한개 이상
feature_name_dir=pd.read_csv(
    './UCI HAR Dataset/data/features.txt'
    ,sep='\s+'
    ,header=None
    ,names=['column_index','column_name']
)

# 중복된 피쳐명 확인

feature_dup_df = feature_name_dir.groupby(
    'column_name'
).count()

def get_new_feature_name_df(old_feature_name_df):
    feature_dup_df = pd.DataFrame(
        data=old_feature_name_df.groupby('column_name').cumcount()
        ,columns=['dup_cnt']
    )
    feature_dup_df = feature_dup_df.reset_index()
    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')
    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(
        lambda x : x[0]+'_'+str(x[1]) if x[1] >0 else x[0]
        ,axis=1
    )
    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)
    return new_feature_name_df

def get_human_dataset( ):
   
    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.
    feature_name_df = pd.read_csv('./UCI HAR Dataset/data/features.txt',sep='\s+',
                        header=None,names=['column_index','column_name'])
   
    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성.
    new_feature_name_df = get_new_feature_name_df(feature_name_df)
   
    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환
    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()
   
    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용
    X_train = pd.read_csv('./UCI HAR Dataset/data/train/X_train.txt',sep='\s+', names=feature_name )
    X_test = pd.read_csv('./UCI HAR Dataset/data//test/X_test.txt',sep='\s+', names=feature_name)
   
    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여
    y_train = pd.read_csv('./UCI HAR Dataset/data/train/y_train.txt',sep='\s+',header=None,names=['action'])
    y_test = pd.read_csv('./UCI HAR Dataset/data/test/y_test.txt',sep='\s+',header=None,names=['action'])
   
    # 로드된 학습/테스트용 DataFrame을 모두 반환
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = get_human_dataset()

# 데이터 불균형 확인
# Series -> value_counts()
y_train['action'].value_counts() # 확인결과 불균형 하지 않음
```
![image](https://github.com/user-attachments/assets/edcf82a4-feaa-4ea5-971e-5eb54b0810d2)
