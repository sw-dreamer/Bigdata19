# CelebA 데이터셋

```
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'Not available'}")
```
```
CUDA available: True
PyTorch version: 2.7.0+cu118
CUDA version: 11.8
```
```
import torch
import torchvision
import numpy as np
import os

image_path = './celeba'

celeba_train_dataset = torchvision.datasets.CelebA(
    image_path,
    split='train',
    target_type='attr',
    download=True
)

celeba_valid_dataset = torchvision.datasets.CelebA(
    image_path,
    split='valid',
    target_type='attr',
    download=True
)

celeba_test_dataset = torchvision.datasets.CelebA(
    image_path,
    split='test',
    target_type='attr',
    download=True
)

print(f'훈련세트 : {len(celeba_train_dataset)}')
print(f'검증세트 : {len(celeba_valid_dataset)}')
print(f'테스트세트 : {len(celeba_test_dataset)}')
```
![image](https://github.com/user-attachments/assets/4ca601af-7d22-4397-9fbe-64dc1a3b39d3)

```
from torchvision import transforms
import matplotlib.pyplot as plt


## 다섯 개 샘플


fig = plt.figure(figsize=(16, 8.5))


## 1열: 바운딩 박스로 자르기
ax = fig.add_subplot(2, 5, 1)
img, attr = celeba_train_dataset[0]
ax.set_title('Crop to a \nbounding-box', size=15)
ax.imshow(img)
ax = fig.add_subplot(2, 5, 6)
img_cropped = transforms.functional.crop(img, 50, 20, 128, 128)
ax.imshow(img_cropped)


plt.show()
```
![image](https://github.com/user-attachments/assets/3db31936-8641-47fa-bacc-e9ef8d6c8bad)

```
import matplotlib.pyplot as plt
import torchvision.transforms as transforms

# 데이터셋에서 이미지를 불러옵니다.
img, attr = celeba_train_dataset[1]

# 새로운 figure 객체를 생성합니다.
fig = plt.figure(figsize=(10, 6))

# 첫 번째 서브플롯: 원본 이미지
ax = fig.add_subplot(2, 5, 2)
ax.set_title('Original Image', size=15)
ax.imshow(img)

# 두 번째 서브플롯: 수평 뒤집기한 이미지
ax = fig.add_subplot(2, 5, 7)
img_flipped = transforms.functional.hflip(img)
ax.set_title('Flip (horizontal)', size=15)
ax.imshow(img_flipped)

plt.show()
```
![image](https://github.com/user-attachments/assets/782d5f6e-f6bd-4bbe-b660-afbd14ef1ce2)

```
import matplotlib.pyplot as plt
import torchvision.transforms as transforms

# fig 객체 생성 (그래프를 2x5의 그리드로 설정)
fig = plt.figure(figsize=(15, 6))

## 3열: 대비 조정
ax = fig.add_subplot(2, 5, 3)
img, attr = celeba_train_dataset[2]
ax.set_title('Adjust constrast', size=15)
ax.imshow(img)
ax = fig.add_subplot(2, 5, 8)
img_adj_contrast = transforms.functional.adjust_contrast(img, contrast_factor=2)
ax.imshow(img_adj_contrast)


## 4열: 명도 조정
ax = fig.add_subplot(2, 5, 4)
img, attr = celeba_train_dataset[3]
ax.set_title('Adjust brightness', size=15)
ax.imshow(img)
ax = fig.add_subplot(2, 5, 9)
img_adj_brightness = transforms.functional.adjust_brightness(img, brightness_factor=1.3)
ax.imshow(img_adj_brightness)


## 5열: 이미지 중앙 자르기
ax = fig.add_subplot(2, 5, 5)
img, attr = celeba_train_dataset[4]
ax.set_title('Center crop\nand resize', size=15)
ax.imshow(img)
ax = fig.add_subplot(2, 5, 10)
img_center_crop = transforms.functional.center_crop(img, [0.7*218, 0.7*178])
img_resized = transforms.functional.resize(img_center_crop, size=(218, 178))
ax.imshow(img_resized)

plt.show()
```
![image](https://github.com/user-attachments/assets/341aa3da-9ac3-4253-a60e-e42b752caf27)

```
import torch
torch.manual_seed(1)

fig = plt.figure(figsize=(14, 12))

for i, (img, attr) in enumerate(celeba_train_dataset):
    ax = fig.add_subplot(3, 4, i*4+1)
    ax.imshow(img)
    if i == 0:
        ax.set_title('Orig.', size=15)


    ax = fig.add_subplot(3, 4, i*4+2)
    img_transform = transforms.Compose([transforms.RandomCrop([178, 178])])
    img_cropped = img_transform(img)
    ax.imshow(img_cropped)
    if i == 0:
        ax.set_title('Step 1: Random crop', size=15)


    ax = fig.add_subplot(3, 4, i*4+3)
    img_transform = transforms.Compose([transforms.RandomHorizontalFlip()])
    img_flip = img_transform(img_cropped)
    ax.imshow(img_flip)
    if i == 0:
        ax.set_title('Step 2: Random flip', size=15)


    ax = fig.add_subplot(3, 4, i*4+4)
    img_resized = transforms.functional.resize(img_flip, size=(128, 128))
    ax.imshow(img_resized)
    if i == 0:
        ax.set_title('Step 3: Resize', size=15)


    if i == 2:
        break


# plt.savefig('figures/14_15.png', dpi=300)
plt.show()
```
![image](https://github.com/user-attachments/assets/008fbb69-8502-4edc-ac2e-d789c78239bf)

```
get_smile = lambda attr: attr[31]


transform_train = transforms.Compose([
    transforms.RandomCrop([178, 178]),
    transforms.RandomHorizontalFlip(),
    transforms.Resize([64, 64]),
    transforms.ToTensor(),
])


transform = transforms.Compose([
    transforms.CenterCrop([178, 178]),
    transforms.Resize([64, 64]),
    transforms.ToTensor()
,])

from torch.utils.data import DataLoader


celeba_train_dataset = torchvision.datasets.CelebA(image_path,
                                                   split='train',
                                                   target_type='attr',
                                                   download=False,
                                                   transform=transform_train,
                                                   target_transform=get_smile)


torch.manual_seed(1)
data_loader = DataLoader(celeba_train_dataset, batch_size=2)


fig = plt.figure(figsize=(15, 6))


num_epochs = 5
for j in range(num_epochs):
    img_batch, label_batch = next(iter(data_loader))
    img = img_batch[0]
    ax = fig.add_subplot(2, 5, j + 1)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_title(f'Epoch {j}:', size=15)
    ax.imshow(img.permute(1, 2, 0))


    img = img_batch[1]
    ax = fig.add_subplot(2, 5, j + 6)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.imshow(img.permute(1, 2, 0))




#plt.savefig('figures/14_16.png', dpi=300)
plt.show()
```
![image](https://github.com/user-attachments/assets/05db7920-8ad8-4e9f-9850-12476ae5c6ee)

```
# valid, test DataLoader
celeba_valid_dataset = torchvision.datasets.CelebA(image_path,
                                                   split='valid',
                                                   target_type='attr',
                                                   download=False,
                                                   transform=transform,
                                                   target_transform=get_smile)


celeba_test_dataset = torchvision.datasets.CelebA(image_path,
                                                   split='test',
                                                   target_type='attr',
                                                   download=False,
                                                   transform=transform,
                                                   target_transform=get_smile)


from torch.utils.data import Subset
celeba_train_dataset = Subset(celeba_train_dataset, torch.arange(16000))
celeba_valid_dataset = Subset(celeba_valid_dataset, torch.arange(1000))


print('훈련 세트:', len(celeba_train_dataset))
print('검증 세트:', len(celeba_valid_dataset))
```
![image](https://github.com/user-attachments/assets/7bcf9e80-602b-420c-82f9-4e658fc70ce7)

```
batch_size = 32

torch.manual_seed(1)
train_dl = DataLoader(celeba_train_dataset, batch_size, shuffle=True)
valid_dl = DataLoader(celeba_valid_dataset, batch_size, shuffle=False)
test_dl = DataLoader(celeba_test_dataset, batch_size, shuffle=False)
```
```
# 웃는 얼굴 분류 CNN 신경망 구성
import torch.nn as nn


model = nn.Sequential()


model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1))
model.add_module('relu1', nn.ReLU())
model.add_module('pool1', nn.MaxPool2d(kernel_size=2))
model.add_module('dropout1', nn.Dropout(p=0.5))


model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))
model.add_module('relu2', nn.ReLU())
model.add_module('pool2', nn.MaxPool2d(kernel_size=2))
model.add_module('dropout2', nn.Dropout(p=0.5))


model.add_module('conv3', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1))
model.add_module('relu3', nn.ReLU())
model.add_module('pool3', nn.MaxPool2d(kernel_size=2))


model.add_module('conv4', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1))
model.add_module('relu4', nn.ReLU())

model
```
![image](https://github.com/user-attachments/assets/14544298-ea02-4d05-99df-2bdc624fd1c7)

```
x = torch.ones((4, 3, 64, 64))
model(x).shape
```
![image](https://github.com/user-attachments/assets/da953103-da64-45d6-8b8c-85a7188cfc95)

```
model.add_module('pool4', nn.AvgPool2d(kernel_size=8))
model.add_module('flatten', nn.Flatten())
x = torch.ones((4, 3, 64, 64))
model(x).shape
```
![image](https://github.com/user-attachments/assets/1e1e9ed3-5231-418c-ba90-098fb964d5a5)

```
model.add_module('fc', nn.Linear(256, 1))
model.add_module('sigmoid', nn.Sigmoid())
x = torch.ones((4, 3, 64, 64))
model(x).shape
```
![image](https://github.com/user-attachments/assets/3691a174-fead-4ded-9d01-f293500bfbc4)

```
model
```
![image](https://github.com/user-attachments/assets/99711495-3698-46f4-9a24-7d0b8cc62c71)

```
# GPU 처리
# GPU 사용 가능 확인
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# model => gpu 보내기
model=model.to(device=device)
model
```
![image](https://github.com/user-attachments/assets/e43561a5-abac-4e51-a40f-b3af2cabff4f)

```
# 함수 정의 : model, loss_fn, train_dl, vaild_dl, num_epochs, optimizer
def train(model, num_epochs, train_dl, valid_dl, loss_fn, optimizer):
    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    loss_hist_train=[0]*num_epochs # cpu
    acc_hist_train=[0]*num_epochs # cpu
    loss_hist_valid=[0]*num_epochs # cpu
    acc_hist_valid=[0]*num_epochs # cpu
    
    for epoch in range(num_epochs):
        # 모델을 학습 모드로 설정
        model.train()
        for x_batch, y_batch in train_dl: 
            # model은 gpu에 있다. data는 cpu에 있다
            # cpu에 있는 data -> gpu 보내기
            x_batch=x_batch.to(device) # gpu로 보내기
            y_batch=y_batch.to(device) # gpu로 보내기
            
            pred_batch=model(x_batch)[:,0] # 예측값 추출 (배치만큼)
            loss=loss_fn(pred_batch, y_batch.float())        
            loss.backward() # 가중치 w로 미분, 오차가 최소화 되는
            optimizer.step() # 배치만큼 가중치 수정(update)
            # 위 for문 코드 까지가 1 batch 학습 
            
            optimizer.zero_grad() # 가중치 초기화
            # 초기화 후 반복 (batch 수 만큼)
            
            # 시각화 데이터
            # loss.item = 평균값으로 나온다, 나중에 평균을 따로 구해야 하기 때문에
            # 우리가 필요한 값은 원래 값이다. y_batch.size(0)를 곱해서 원래값을 나오게 한다
            # 전체 누적 오차 저장
            loss_hist_train[epoch]+=loss.item()*y_batch.size(0) 
            # 누적 정확도 : 배치 사이즈 만큼 나온다
            is_correct=((pred_batch >= 0.5).float()==y_batch).float()
            acc_hist_train[epoch]+=is_correct.sum().cpu()
            
        # 1 epoch 마다 평균 오차, 평균 정확도
        # len(train_dl) = 전체 데이터 / batch_size
        # len(train_dl.dataset) = 전체데이터        
        loss_hist_train[epoch] /= len(train_dl.dataset)
        acc_hist_train[epoch] /= len(train_dl.dataset)
        
        # 모델을 평가 모드로 설정, 결과 위 리스트에 대입
        model.eval() # 예측만 해야 한다, backward 하면 안된다
        with torch.no_grad(): # backward 안하기 때문에 미분 할 필요가 없다. no_grad() 필수다
            for x_batch, y_batch in valid_dl: # x_batch, y_batch, valid_dl가 cpu, gpu 둘 중 어디에 있는지 알고 있어야 한다
                x_batch=x_batch.to(device) # GPU로 보내기
                y_batch=y_batch.to(device) # GPU로 보내기
                
                pred_batch=model(x_batch)[:,0] # 예측값 - 원래값
                loss=loss_fn(pred_batch,y_batch.float())
                
                loss_hist_valid[epoch]+=loss.item()*y_batch.size(0)
                is_correct=((pred_batch >= 0.5).float()==y_batch).float()       
                acc_hist_valid[epoch]+=is_correct.sum().cpu()
                # 위 코드까지는 1배치만큼씩 처리
                
        loss_hist_valid[epoch] /= len(valid_dl.dataset)
        acc_hist_valid[epoch] /= len(valid_dl.dataset)
                
        # 학습데이터 정확도와 검증데이터의 정확도 출력
        print(f'에포크 : {epoch+1}, 학습정확도 : {acc_hist_train[epoch]:.4f}, 검증 정확도 : {acc_hist_valid[epoch]:.4f}')                
                
    return loss_hist_train, loss_hist_valid, acc_hist_train, acc_hist_valid
```
```
# loss_fn, optimizer
# torch.manual_seed(1)
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

num_epochs=50
loss_fn=nn.BCELoss()
optimizer=torch.optim.Adam(model.parameters(),lr=0.001) # default : 0.001 학습률

hist=train(model, num_epochs, train_dl, valid_dl, loss_fn, optimizer)
```
```
에포크 : 1, 학습정확도 : 0.5088, 검증 정확도 : 0.5140
에포크 : 2, 학습정확도 : 0.5379, 검증 정확도 : 0.5620
에포크 : 3, 학습정확도 : 0.5474, 검증 정확도 : 0.5480
에포크 : 4, 학습정확도 : 0.5968, 검증 정확도 : 0.5950
에포크 : 5, 학습정확도 : 0.6199, 검증 정확도 : 0.6330
에포크 : 6, 학습정확도 : 0.6346, 검증 정확도 : 0.6490
에포크 : 7, 학습정확도 : 0.6448, 검증 정확도 : 0.6240
에포크 : 8, 학습정확도 : 0.6540, 검증 정확도 : 0.6550
에포크 : 9, 학습정확도 : 0.6668, 검증 정확도 : 0.6450
에포크 : 10, 학습정확도 : 0.6706, 검증 정확도 : 0.6710
에포크 : 11, 학습정확도 : 0.6740, 검증 정확도 : 0.6500
에포크 : 12, 학습정확도 : 0.6915, 검증 정확도 : 0.6810
에포크 : 13, 학습정확도 : 0.7015, 검증 정확도 : 0.7290
에포크 : 14, 학습정확도 : 0.7263, 검증 정확도 : 0.7060
에포크 : 15, 학습정확도 : 0.7499, 검증 정확도 : 0.7760
에포크 : 16, 학습정확도 : 0.7846, 검증 정확도 : 0.8010
에포크 : 17, 학습정확도 : 0.8033, 검증 정확도 : 0.8310
에포크 : 18, 학습정확도 : 0.8183, 검증 정확도 : 0.8510
에포크 : 19, 학습정확도 : 0.8363, 검증 정확도 : 0.8470
에포크 : 20, 학습정확도 : 0.8430, 검증 정확도 : 0.8370
에포크 : 21, 학습정확도 : 0.8489, 검증 정확도 : 0.8730
에포크 : 22, 학습정확도 : 0.8546, 검증 정확도 : 0.8630
에포크 : 23, 학습정확도 : 0.8597, 검증 정확도 : 0.8210
에포크 : 24, 학습정확도 : 0.8651, 검증 정확도 : 0.8360
에포크 : 25, 학습정확도 : 0.8702, 검증 정확도 : 0.8720
에포크 : 26, 학습정확도 : 0.8716, 검증 정확도 : 0.8630
에포크 : 27, 학습정확도 : 0.8754, 검증 정확도 : 0.8840
에포크 : 28, 학습정확도 : 0.8729, 검증 정확도 : 0.8760
에포크 : 29, 학습정확도 : 0.8756, 검증 정확도 : 0.8920
에포크 : 30, 학습정확도 : 0.8804, 검증 정확도 : 0.9020
에포크 : 31, 학습정확도 : 0.8844, 검증 정확도 : 0.8970
에포크 : 32, 학습정확도 : 0.8817, 검증 정확도 : 0.8740
에포크 : 33, 학습정확도 : 0.8808, 검증 정확도 : 0.8840
에포크 : 34, 학습정확도 : 0.8829, 검증 정확도 : 0.8890
에포크 : 35, 학습정확도 : 0.8879, 검증 정확도 : 0.8760
에포크 : 36, 학습정확도 : 0.8886, 검증 정확도 : 0.8960
에포크 : 37, 학습정확도 : 0.8867, 검증 정확도 : 0.8980
에포크 : 38, 학습정확도 : 0.8858, 검증 정확도 : 0.8830
에포크 : 39, 학습정확도 : 0.8934, 검증 정확도 : 0.9060
에포크 : 40, 학습정확도 : 0.8924, 검증 정확도 : 0.9030
에포크 : 41, 학습정확도 : 0.8959, 검증 정확도 : 0.9000
에포크 : 42, 학습정확도 : 0.8935, 검증 정확도 : 0.8760
에포크 : 43, 학습정확도 : 0.8936, 검증 정확도 : 0.8950
에포크 : 44, 학습정확도 : 0.8967, 검증 정확도 : 0.8960
에포크 : 45, 학습정확도 : 0.8959, 검증 정확도 : 0.8860
에포크 : 46, 학습정확도 : 0.8920, 검증 정확도 : 0.9040
에포크 : 47, 학습정확도 : 0.8974, 검증 정확도 : 0.8880
에포크 : 48, 학습정확도 : 0.8974, 검증 정확도 : 0.8770
에포크 : 49, 학습정확도 : 0.8991, 검증 정확도 : 0.8900
에포크 : 50, 학습정확도 : 0.9016, 검증 정확도 : 0.9000
```
```
import numpy as np
x_arr = np.arange(len(hist[0])) + 1
fig = plt.figure(figsize=(12, 4))
ax = fig.add_subplot(1, 2, 1)
ax.plot(x_arr, hist[0], '-o', label='Train loss')
ax.plot(x_arr, hist[1], '--<', label='Validation loss')
ax.legend(fontsize=15)
ax.set_xlabel('Epoch', size=15)
ax.set_ylabel('Loss', size=15)
ax = fig.add_subplot(1, 2, 2)
ax.plot(x_arr, hist[2], '-o', label='Train acc.')
ax.plot(x_arr, hist[3], '--<', label='Validation acc.')
ax.legend(fontsize=15)
ax.set_xlabel('Epoch', size=15)
ax.set_ylabel('Accuracy', size=15)
#plt.savefig('figures/14_17.png', dpi=300)
plt.show()
```
![image](https://github.com/user-attachments/assets/e825ed71-95bc-49f1-9127-ac54623816ce)

```
# test data 테스트
accuracy_test = 0

model.eval()
with torch.no_grad():
    for x_batch, y_batch in test_dl:
        x_batch = x_batch.to(device)
        y_batch = y_batch.to(device)
        pred = model(x_batch)[:, 0]
        is_correct = ((pred>=0.5).float() == y_batch).float()
        accuracy_test += is_correct.sum().cpu()


accuracy_test /= len(test_dl.dataset)


print(f'테스트 정확도: {accuracy_test:.4f}')
```
![image](https://github.com/user-attachments/assets/b0476b64-cf20-4cfd-956c-6feeff7b1919)

```
pred = model(x_batch)[:, 0] * 100


fig = plt.figure(figsize=(15, 7))
for j in range(10, 20):
    ax = fig.add_subplot(2, 5, j-10+1)
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(x_batch[j].cpu().permute(1, 2, 0))
    if y_batch[j] == 1:
        label = 'Smile'
    else:
        label = 'Not Smile'
    ax.text(
        0.5, -0.15,
        f'GT: {label:s}\nPr(Smile)={pred[j]:.0f}%',
        size=16,
        horizontalalignment='center',
        verticalalignment='center',
        transform=ax.transAxes)

#plt.savefig('figures/figures-14_18.png', dpi=300)
plt.show()
```
![image](https://github.com/user-attachments/assets/b230c6ca-4459-41f0-b4d3-702ff70763b9)

```
import os

if not os.path.exists('models'):
    os.mkdir('models')

path='models/celeba-con_20250424.ph'
torch.save(model,path)
```
