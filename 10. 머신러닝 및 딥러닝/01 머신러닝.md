# 머신러닝
---
## 환경설정

### 기싱환경
```
conda create -n pyml python=3.10
```
![image](https://github.com/user-attachments/assets/ce192c6e-cc99-49da-9f83-2b12191633c3)

![image](https://github.com/user-attachments/assets/19e305ab-8dbb-44cb-80f5-9f548f5c97b7)

```
conda activate pyml
```
![image](https://github.com/user-attachments/assets/5f9bb3db-97f7-49cd-acc2-7cfdb1697474)

```
conda install numpy==1.21.2 scipy==1.7.0 scikit-learn==1.2 matplotlib==3.4.3  pandas==1.3.2 ipykernel
```
![image](https://github.com/user-attachments/assets/97b82766-7bce-4f7c-9f21-746a2ce5d83f)

```
conda install numpy==1.21.2 scipy scikit-learn==1.2 matplotlib==3.4.3  pandas ipykernel
```
![image](https://github.com/user-attachments/assets/f68a8e55-83ca-4b9f-8867-233291d73b7c)

```
conda install numpy==1.21.2 scipy scikit-learn==1.2 matplotlib  pandas ipykernel
```
![image](https://github.com/user-attachments/assets/196d51fd-8b61-47f3-a14c-460ce582e681)

```
conda install numpy==1.23.3 scipy scikit-learn==1.2 matplotlib  pandas ipykernel
```
![image](https://github.com/user-attachments/assets/617195b8-a561-4108-bbf4-2ddeb16f5ef1)

```
pip freeze > requirements.txt
```
![image](https://github.com/user-attachments/assets/1677c9b1-0562-4e2b-b867-9523cc200f8c)

만약에 requirements.txt를 설치하고 싶으면 아래 명령어를 실행하면 된다.
```
pip install -r requirements.txt
```

---

## numpy

1. 넘파이란
   - 파이썬에서 수치 계산을 효율적으로 할 수 있도록 지원하는 라이브러리
   - 다차원 배열 객체(ndarray)를 제공
   - 벡터, 행렬 연산과 같은 고속으로 수행할 수 있도록 최적화되어 있음
   - 과학 계산, 머신러닝, 딥러닝, 데이터 분석등 다양한 분야에 사용
    
2. 특징
   - 고속 연산 지원 : c언어로 구현되어 내부 연산이 빠르다
   - 다차원 배열 지원
   - 브로드캐스팅 지원 : 서로 다른 크기의 배열 간 연산을 가능
   - 다양한 수학 함수 지원 : 선형대수, 통계, 랜덤 샘플링 등의 다양한 함수 지원
   - python 리스트보다 메모리를 효율적으로 사용

3. numpy 기본 사용법
   - 설치 : pip(conda) install numpy
   - import numpy as np

```
import numpy as np

# 주요 기능 및 예제

# 배열 생성 (np.array())
# 1차원 배열 생성
arr1 = np.array([1,2,3,4,5])

print(f'arr1 : {arr1}')

# 2차원 배열 생성
arr2 = np.array([
    [1,2,3]
    ,[4,5,6]
])
print(f'arr2 : {arr2}')

# 3차원 배열 생성

arr3 =np.array(
    [
        [
            [1,2]
            ,[3,4]
            ,[5,6]
            ,[7,8]
        ]
    ]
)
print(f'arr3 : {arr3}')
```
![image](https://github.com/user-attachments/assets/81aa6f7b-7aed-4f5c-b595-35936db79445)

```
import numpy as np

# 주요 기능 및 예제

# 배열 생성 (np.array())
# 1차원 배열 생성
arr1 = np.array([1,2,3,4,5])

# 2차원 배열 생성
arr2 = np.array([
    [1,2,3]
    ,[4,5,6]
])


# 3차원 배열 생성

arr3 =np.array(
    [
        [
            [1,2]
            ,[3,4]
            ,[5,6]
            ,[7,8]
        ]
    ]
)
print('='*50)

print(f'arr1 배열의 차원 : {arr1.ndim}')
print(f'arr2 배열의 차원 : {arr2.ndim}')
print(f'arr3 배열의 차원 : {arr3.ndim}')
print('='*50)
print(f'arr1 배열의 크기 : {arr1.shape}')
print(f'arr2 배열의 크기 : {arr2.shape}')
print(f'arr3 배열의 크기 : {arr3.shape}')

print('='*50)

print(f'arr1 배열의 원소 개수 : {arr1.size}')
print(f'arr2 배열의 원소 개수 : {arr2.size}')
print(f'arr3 배열의 원소 개수 : {arr3.size}')

print('='*50)

print(f'arr1 배열의 데이터 타입 : {arr1.dtype}')
print(f'arr2 배열의 데이터 타입 : {arr2.dtype}')
print(f'arr3 배열의 데이터 타입 : {arr3.dtype}') # ndarray는 동일타입만 저장 할 수 있다
```
![image](https://github.com/user-attachments/assets/a2760dec-fd88-4c21-8157-1a0e43b706e2)

```
import numpy as np
# 특정값을 갖는 배열 생성
# 0값을 갖는 배열 : np.zeros((행,열))
zeroes =np.zeros(
    (3,3)
)
zeroes
```
![image](https://github.com/user-attachments/assets/2613dd34-7f86-4229-a437-574730734353)

```
import numpy as np
# 특정값을 갖는 배열 생성
# 0값을 갖는 배열 : np.zeros((행,열))
zeroes_ =np.zeros(
    (3,3)
)
print(zeroes_)
print('='*50)
# 1값을 갖는 배열 : np.ones((행,열))
ones_ =np.ones(
    (3,3)
)
print(ones_)
print('='*50)
# 특정값으로 채운 배열 : np.full((행,열),특정값)

full=np.full((2,2),5)
print(full)

print('='*50)
# 연속된 숫자로 채운 배열 생성 : np.arange(start,end, stop)
arr4=np.arange(1,10,2)
print(arr4)
print('='*50)

# np.linspace(start,end,count)
lin_arr=np.linspace(0,100,5) # 0~100 사이에서 5개 값으로 생성
print(lin_arr)
```
![image](https://github.com/user-attachments/assets/dc3c08d7-c94a-49f2-a615-04af3b193942)

```
import numpy as np

# 난수 배열 생성

# numpy의 random모듈을 사용하면 다양한 난수 배열을 생성 할 수 있다.

# np.random.rand(행,열) : 0~1사이의 난수를 가진 배열 생성
np.random.seed(42) # seed에 의해 rand 값이 바뀔수도 있고 안 바뀔수도 있다

rand_arr = np.random.rand(2,3)
print(rand_arr)
```
![image](https://github.com/user-attachments/assets/947023bd-f155-4a66-94c2-24b4c223db30)

```
import numpy as np

# 난수 배열 생성

# numpy의 random모듈을 사용하면 다양한 난수 배열을 생성 할 수 있다.

# np.random.rand(행,열) : 0~1사이의 난수를 가진 배열 생성
np.random.seed(42) # seed에 의해 rand 값이 바뀔수도 있고 안 바뀔수도 있다

rand_arr = np.random.rand(2,3)
print(rand_arr)

# 정규분포를 따르는 난수 배열 생성 : np.random.randn(행,열)
randn_arr=np.random.randn(2,2)
print(randn_arr)

# 특정 범위의 정수 난수 배열 생성 : np.random.randint(start,ent,[(행,열)])
randint_arr= np.random.randint(1,10,[3,4])
print(randint_arr)
```
![image](https://github.com/user-attachments/assets/4023bd24-a25d-43ba-aec1-448a0525d54c)

```
import numpy as np

# 배열 연산(더하기, 빼기, 곱셈, 나눗셈, 제곱)
a_vector =np.array([1,2,3])
b_vector =np.array([4,5,6])
print(f'덧셈 : {a_vector+b_vector}')
print(f'뺄셈 : {a_vector-b_vector}')
print(f'곱셈 : {a_vector*b_vector}')
print(f'제곱 : {a_vector**b_vector}')
```
![image](https://github.com/user-attachments/assets/f22eca3b-8e9f-434e-a1e9-ad9237c49ba3)

```
import numpy as np

# 배열 인덱싱 및 슬라이싱
arr=np.array([
    [1,2,3]
    ,[4,5,6]
    ,[7,8,9]
])

print(f'arr : {arr}')
print(f'첫번째 행, 두번째 열 : {arr[0][1]}') # arr[행][열]
print(f'첫번째 행, 두번째 열 : {arr[0,1]}') # arr[행,열]

# 특정 행 슬라이싱
print(f'첫번째 행 : {arr[0]}')
print(f'첫번째 행 : {arr[0,]}')
print(f'첫번째 행 : {arr[0,:]}')

# 특정 열 슬라이싱
print(f'두번째 열 : {arr[:,1]}')

# 부분 배열 가져오기
print(f'2x2 부분 배열 : {arr[1:3,1:3]}')
```
![image](https://github.com/user-attachments/assets/2c63edbe-ad55-418a-9c69-91304e275994)

```
import numpy as np

# 선형대수 연산
# 선형 변환(Linear Transformation)은 벡터나 행렬을 다른 벡터나 행렬로 변환하는 수학적 과정
# 특정 방향으로 확장/축소하는 역할
A = np.array([
    [1,2]
    ,[3,4]
])
B = np.array([
    [1,1]
    ,[2,2]
])

# 점 곱 
# 주어진 데이터(A)를 가중치(B)로 선형 변환한 것이다.
dot_prod=np.dot(A,B)
print(f'행 열 곱 : {dot_prod}')
```
![image](https://github.com/user-attachments/assets/58069830-1c49-4a17-a646-3ff64da28bfe)

```
import numpy as np

# 전체 행렬 : transpose
A = np.array([
    [1,2]
    ,[3,4]
])
B = np.array([
    [1,1]
    ,[2,2]
])

A,A.T,A.transpose()
```
![image](https://github.com/user-attachments/assets/5281654f-1165-429e-804f-e53f6174cdb5)

```
import numpy as np

a=np.array([1,2,3])
print(f'a shape : {a.shape}')
b=np.array([1,2,3])
print(f'b shape : {b.shape}')
print(np.dot(a,b))
print(np.dot(a.T,b))
```
![image](https://github.com/user-attachments/assets/b1029566-640d-4b8c-ba45-49df18d822a2)

```
import numpy as np

a = np.array([[1, 2, 3], [4, 5, 6]])
print(f'a shape : {a.shape}')

b = np.array([1, 2, 3])
print(f'b shape : {b.shape}')

print(np.dot(a, b))

try:
    print(np.dot(a.T, b))
except Exception as e:
    print('오류: ' + str(e))
```
![image](https://github.com/user-attachments/assets/b25cf09e-fbf0-493f-9f67-4fcb8f5795f9)

```
import numpy as np

# 역행렬
# 역행렬 존재하는 조건
# 1. 정사각 행렬(Square Matrix) (nxn)
# 2. 행렬식이 0이 아니어야한다. 행렬식이 0 이면 역행렬이 존재하지 않고 이러한 행렬을 특이행렬(Singular Matrix)라고 한다.
#    AxA-1 = A-1
#    단위 행렬(Identity Matrix), 행렬 곱셈의 항등원 역할



# 행렬식 : 정사각 행렬의 스칼라(단일값) 값을 의미한다.
# 특정 행렬(데이터)이 선형변환에서 공간을 얼마나 변환시키는지를 나타나는 값

# 행렬식이 0이면 해당 행렬이 역행렬을 가질 수 없다(det(A)=0)
# 해당 행렬이 선형 종속(Linear Dependent)이 된다

# 행렬식이 0이 아니면
# 행렬이 가역(invertible)하며, 역행렬이 존재한다.

# 역행렬과 행렬식 계산
# 1. 역행렬 구하기(np.linalg.inv())

# 행렬 A : 2X2 정사각행렬
A = np.array([
    [4,7]
    ,[2,6]
]
)

# 역행렬 구하기
A_inv = np.linalg.inv(A)

print(A_inv)

# 단위 행렬 구하기
I = np.dot(A,A_inv)
print(I)

```
![image](https://github.com/user-attachments/assets/2cea4b7d-3551-4b2a-9523-e76ff2ce5764)

```
import numpy as np
# 역행렬 존재하지 않는 행렬
B = np.array([
    [4,12]
    ,[2,6]
]
)


B_inv = np.linalg.inv(B)

print(B_inv)

B_I = np.dot(B,B_inv)
print(B_I)
```
![image](https://github.com/user-attachments/assets/daa078ff-70a9-4178-a56c-558d5be38794)

```
import numpy as np

# 행렬식 구하기 (np.linalg.det())

# 3x3 정사각 행렬
B = np.array(
    [
        [1,2,3]
        ,[4,5,6]
        ,[7,8,9]
    ]
)
print(B)

# 역행렬 구하기
B_inv = np.linalg.inv(B)
print(B_inv)

# 행렬식 구하기
B_det = np.linalg.det(B) # 행렬식 결과값은 스칼라값(단일값)이 나온다

print(B_det)
```
![image](https://github.com/user-attachments/assets/9c66ba69-f873-4048-bae0-da03d31aa9bd)

```
import numpy as np

# 행렬식 구하기 (np.linalg.det())

# 3x3 정사각 행렬
B = np.array(
    [
        [1,2,3]
        ,[4,5,6]
        ,[7,8,10]
    ]
)
print(B)

# 역행렬 구하기
B_inv = np.linalg.inv(B)
print(B_inv)

# 행렬식 구하기
B_det = np.linalg.det(B)

print(B_det)
```
![image](https://github.com/user-attachments/assets/59187ccc-4df2-480b-b304-c67ef2bfc3c4)

```
import numpy as np

# 특이 행렬(Singular Matrix)

C = np.array(
    [
        [1,2]
        ,[2,4]
    ]
)

print(C)

# 행렬식 확인
print(f'행렬식 값 : {np.linalg.det(C)}')
```
![image](https://github.com/user-attachments/assets/a2d686a9-43ea-4de7-8ece-7dcf989ac1dc)

```
import numpy as np

# 특이 행렬(Singular Matrix)

C = np.array(
    [
        [1,2]
        ,[2,4]
    ]
)

print(C)

# 행렬식 확인
print(f'행렬식 값 : {np.linalg.det(C)}')

try:
    c_inv = np.linalg.inv(C)
    print(f'역행렬 : {c_inv}')
except np.linalg.LinAlgError:
    print('역행렬을 가질 수 없는 특이 행렬이다.')

```
![image](https://github.com/user-attachments/assets/e6b68221-b6fd-4689-b3d7-84eae7dbb137)

### 역행렬의 해석과 의미

1. 역행렬의 존재 조건
- 행렬  A가 정사각 행렬이어야 한다.
- 행렬식이 0이 아니어야한다.
- 선행독립(Linear Independent)인 열벡터를 가져야 한다.
    - 즉, 행렬의 열벡터들이 서로 독립적이면 역행렬이 존재하게 된다.

2. 해석
2.1 선형변환 관점
- 행렬 A는 공간을 변형시키는 선형 변환으로 볼 수 있다.
- 역행렬은 이 변환을 되돌리는 역할을 한다.(공간을 복원하는 역할)

2.2 기하학적 관점
- 역행렬이 존재 : 변환이 가역적이라면, 좌표 공간을 다시 원래대로 복원
- 역행렬이 존재 x : 변환이 공간을 축소시키거나, 특정 차원으로 줄여 되둘리 수 없는 변환(Singular Transformation)이 된다.

### Singular Tranformation
- 역행렬이 존재하지 않는 경우는 공간을 완전히 축소시키는 변환을 의미한다.
- 2D 공간에서 1D 공간으로 압축되거나, 3D 공간에서 2D 평면으로 축소되는 등의 변환을 수행
---
## 퍼셉트론

- 퍼셉트론(Perceptron)은 인공 신경망에서 가장 기본적인 형태로, 이진 분류(binary classification)를 위한 알고리즘입니다. 주로 머신러닝의 기초로 다루어지며, "단층 퍼셉트론"이 가장 간단한 형태입니다.

### 동작 원리
- 퍼셉트론은 주어진 입력 데이터에 대해 출력을 예측하는 과정에서 **가중치(weights)**와 **편향(bias)**을 학습하여 분류 작업을 수행합니다. 퍼셉트론의 핵심은 **선형 결정 경계(linear decision boundary)**를 만들어서 데이터를 분류하는 것입니다.

퍼셉트론의 동작 과정은 다음과 같습니다:

#### 1. 입력 데이터와 가중치 초기화
- 입력값 **X**와 이를 조정하는 **가중치(w)**가 있습니다.
- 가중치는 일반적으로 **난수**로 초기화되며, 훈련을 통해 조정됩니다.
- 편향 **b** 역시 초기화됩니다.

#### 2. 선형 결합 계산
- 각 입력 값에 대해 가중치를 곱하고, 그 값을 모두 더한 후 편향을 더하여 **선형 결합**을 계산합니다.
- 이 계산은 `net_input(X)` 메소드에서 `np.dot(X, w) + b`와 같이 수행됩니다.

#### 3. 활성화 함수 (Activation Function)
- 퍼셉트론은 선형 결합된 값을 활성화 함수에 통과시켜 출력을 만듭니다.
- 퍼셉트론에서 사용하는 활성화 함수는 **단위 계단 함수(unit step function)**입니다.
    - 이 함수는 출력이 0 이상이면 1을 반환하고, 0 미만이면 0을 반환합니다.
    - 이 과정은 `predict(X)` 메소드에서 `np.where(self.net_input(X) >= 0.0, 1, 0)`로 수행됩니다.

#### 4. 오차 계산 및 가중치 업데이트
- 예측값과 실제 목표값(타겟값) 사이의 차이를 **오차(error)**라고 합니다.
- 퍼셉트론은 이 오차를 기반으로 **가중치(weight)**와 **편향(bias)**을 업데이트합니다.
- 업데이트 공식은 `w = w + eta * error * X`로, 여기서 **eta**는 학습률(learning rate)을 의미합니다. 학습률은 가중치 업데이트의 크기를 조절합니다.
- 이 과정을 반복하여 가중치가 점차적으로 학습됩니다.

#### 5. 훈련 반복
- 이 과정은 주어진 **에포크(epoch)** 수만큼 반복됩니다. 각 에포크마다 데이터셋을 한번씩 학습하며, 가중치를 업데이트합니다.

### 퍼셉트론의 특징
- **단층 퍼셉트론**은 선형적으로 구분 가능한 데이터만 처리할 수 있습니다. 즉, 입력 데이터가 선형 결정 경계로 나눠질 수 있을 때만 잘 동작합니다.
- XOR 문제와 같은 비선형적으로 구분되는 문제를 해결할 수 없습니다. 이 문제를 해결하려면 **다층 퍼셉트론(Multi-layer Perceptron, MLP)**을 사용해야 합니다.
- 퍼셉트론은 매우 간단하고, 학습 속도가 빠르며, 구현이 쉽다는 장점이 있습니다. 그러나 실제 복잡한 문제를 해결하기에는 한계가 있습니다.

### 퍼셉트론의 수학적 표현
퍼셉트론의 핵심은 다음의 수식으로 표현됩니다:

$$
y = 
\begin{cases} 
1 & \text{if } w \cdot x + b \geq 0 \\
0 & \text{if } w \cdot x + b < 0 
\end{cases}
$$


여기서:
- \( x \)는 입력 벡터,
- \( w \)는 가중치 벡터,
- \( b \)는 편향,
- \( y \)는 예측된 클래스(0 또는 1)입니다.
  
```
import numpy as np

class Perceptron:
    '''퍼셉트론 분류기
    
    매개변수
    -------------
    eta : float
        학습률(0.0과 1.0 사이)
    n-iter L int
    훈련데이터셋 반복 회수 : 에포크
    
    random_state : int
    난수 생성 시드(난수값을 고정)
    
    속성(클래스 내부에서 사용할 변수)
    w_ : 1d array
        학습할 가중치
    b_ : 스칼라
        학습할 가중치
    
    error : list
    에포크마다 누적된 분류 오류(오차)
    
    '''
    
    def __init__(self,eta=0.01,n_iter=50,random_state=1):
        self.eta=eta
        self.n_iter=n_iter
        self.random_state=random_state
        
    def fit(self,X,y): # 학습 메소드
        '''
        훈련 데이터 학습
        
        매개변수
        --------------------------------------------------
        X : {array-like}, shape=[n_samples,n_features]
        n_samples 개의 샘플데이터, n_feautres개의 특성(컬럼)으로 이뤄진 훈련데이터
        
        y : array-like, shape=[n_samples]
        원래 답(타깃 값)
        
        반환 값(return value)
        ----------------------------
        self : object
        '''
        rgen=np.random.RandomState(self.random_state) # 시드 적용
        self.w_=rgen.normal(
            loc=0.0
            ,scale=0.01
            ,size=X.shape[1] # X 2차원 행렬 -> (행,열)
        )
        
        self.b_= np.float_(0.)
        self_errors_=[] # 빈리스트 : 오차 저장할 리스트
        
        #학습
        for _ in range(self.n_iter): # 순수하게 반복만 진행
            errors = 0 # 1회 학습시 나오는 오차를 저장하는 변수
            for xi, target in zip(X,y):
                update = self.eta *(target-self.predict(xi)) # 오차를 구한다
                self.w_ += update*xi
                self.b_ += update
                errors += int(update!=0.0)
            
            self_errors_.append(errors) # 1에포크 마다  오차를 저장하는 함수
        return self # java의 this와 같음 : 오브젝트를 접근 할 수 있는 변수
    
    def net_input(self,X):
        '''
        입력 계산 : Z
        '''
        return np.dot(X,self.w_) + self.b_
    
    def predict(self, X): # 입력 데이터를 받아서 예측값을 반환 : 0,1
        # np.where(w조건, 참일경우, 거짓일 경우)
        return np.where(self.net_input(X)>=0.0,1,0)
```

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
print('url : ',s)

df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

df.tail()
```
![image](https://github.com/user-attachments/assets/718b6a86-fac6-449a-b889-a59fc7cce1a4)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

df[4].unique()
```
![image](https://github.com/user-attachments/assets/cbfb8f74-cc5c-4780-8ba8-07439622885d)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

# 시각화
import matplotlib.pyplot as plt

# setosa랑 versicolor를 선택
df.iloc[0:100,4].values #품정 추출
```
![image](https://github.com/user-attachments/assets/ff98857b-9245-4c28-893d-f77a76ddd811)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

# 시각화
import matplotlib.pyplot as plt

# setosa랑 versicolor를 선택
y=df.iloc[0:100,4].values #품정 추출

# setosa이면 0, versicolor이면 1로 출력

np.where(y=='Iris-setosa',0,1)
```
![image](https://github.com/user-attachments/assets/03a1cd79-035a-4d48-aac2-2464dbf0f1c9)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

# 시각화
import matplotlib.pyplot as plt

# setosa랑 versicolor를 선택
y=df.iloc[0:100,4].values #품정 추출

# setosa이면 0, versicolor이면 1로 출력

y=np.where(y=='Iris-setosa',0,1)

# 꽃의 길이 df[0],df[2], 꽃의 넓이 : df[1], df[3]
# data 추출 : 꽃받침, 꽃잎의 길이 데이터를 추출
X=df.iloc[0:100,[0,2]].values
X

```
![image](https://github.com/user-attachments/assets/318240b2-e263-4e43-80be-f288485ce9ba)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

# 시각화
import matplotlib.pyplot as plt

# setosa랑 versicolor를 선택
y=df.iloc[0:100,4].values #품정 추출

# setosa이면 0, versicolor이면 1로 출력

y=np.where(y=='Iris-setosa',0,1)

# 꽃의 길이 df[0],df[2], 꽃의 넓이 : df[1], df[3]
# data 추출 : 꽃받침, 꽃잎의 길이 데이터를 추출
X=df.iloc[0:100,[0,2]].values

# setosa와 versicolor 데이터 분포 확인

# 산점도 setosa
plt.figure(figsize=(10,8))
plt.scatter(
    x=X[:50,0]
    ,y=X[:50,1]
    ,color='red'
    ,marker='o'
    ,label='setosa'
)
plt.show()

```
![image](https://github.com/user-attachments/assets/dab8d629-09c8-487e-8fb9-f32a2a86f432)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

# 시각화
import matplotlib.pyplot as plt

# setosa랑 versicolor를 선택
y=df.iloc[0:100,4].values #품정 추출

# setosa이면 0, versicolor이면 1로 출력

y=np.where(y=='Iris-setosa',0,1)

# 꽃의 길이 df[0],df[2], 꽃의 넓이 : df[1], df[3]
# data 추출 : 꽃받침, 꽃잎의 길이 데이터를 추출
X=df.iloc[0:100,[0,2]].values

# setosa와 versicolor 데이터 분포 확인

# 산점도 setosa
plt.figure(figsize=(10,8))
plt.scatter(
    x=X[:50,0]
    ,y=X[:50,1]
    ,color='red'
    ,marker='o'
    ,label='setosa'
)

plt.scatter(
    x=X[50:100,0]
    ,y=X[50:100,1]
    ,color='blue'
    ,marker='o'
    ,label='versicolor'

)


plt.show()

```
![image](https://github.com/user-attachments/assets/8e05a556-c413-4087-b8e9-cb6387398cde)

```
# 붓꽃 데이터셋에서 퍼셉트론 훈련
import os
import pandas as pd
s= 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'


df = pd.read_csv(
    s
    , header = None
    , encoding='utf-8'
)

# 시각화
import matplotlib.pyplot as plt

# setosa랑 versicolor를 선택
y=df.iloc[0:100,4].values #품정 추출

# setosa이면 0, versicolor이면 1로 출력

y=np.where(y=='Iris-setosa',0,1)

# 꽃의 길이 df[0],df[2], 꽃의 넓이 : df[1], df[3]
# data 추출 : 꽃받침, 꽃잎의 길이 데이터를 추출
X=df.iloc[0:100,[0,2]].values

# setosa와 versicolor 데이터 분포 확인

# 산점도 setosa
plt.figure(figsize=(10,8))
plt.scatter(
    x=X[:50,0]
    ,y=X[:50,1]
    ,color='red'
    ,marker='o'
    ,label='setosa'
)

plt.scatter(
    x=X[50:100,0]
    ,y=X[50:100,1]
    ,color='blue'
    ,marker='o'
    ,label='versicolor'

)

plt.xlabel('Sepal length [cm]')
plt.ylabel('Petal length [cm]')
plt.legend(loc='upper left')

plt.show()
```
![image](https://github.com/user-attachments/assets/3477269c-9447-4e9d-a593-30cfb6b1a3a2)

### 시그모이드 함수(Sigmoid Function)

시그모이드 함수는 실수 값을 입력받아 그 출력을 0과 1 사이로 제한하는 특성을 가진 함수입니다. 이 함수는 주로 인공 신경망에서 활성화 함수로 사용됩니다. 시그모이드 함수는 다음과 같은 수식으로 정의됩니다.

세개 이상의 품종을 예측 하기 위해서는 **softmax**를 사용하는게 좋다

이진 분류 문제에서는 **시그모이드 함수**가 적합합니다.

#### 시그모이드 함수의 수식

$$
f(x) = \frac{1}{1 + e^{-x}}
$$


여기서 \( e \)는 자연 상수(약 2.718), \( x \)는 입력 값입니다.

#### 시그모이드 함수의 특징

1. **출력 범위**: 시그모이드 함수의 출력값은 항상 0과 1 사이에 있습니다. 즉, \( 0 < f(x) < 1 \)입니다.
2. **비선형성**: 시그모이드 함수는 비선형 함수로, 입력값의 변화에 비례하여 출력을 부드럽게 변화시킵니다. 이는 신경망에서 비선형적인 학습을 가능하게 합니다.
3. **미분 가능**: 시그모이드 함수는 미분이 가능하며, 이는 역전파 알고리즘을 사용할 때 유용합니다. 시그모이드 함수의 미분은 다음과 같습니다:

$$
f'(x) = f(x) \cdot (1 - f(x))
$$

4. **대칭성**: 시그모이드 함수는 원점에 대해 대칭적이지 않지만, 매우 작은 음수 입력에 대해 출력값이 0에 가까워지고, 양수 입력에 대해 1에 가까워지는 특성을 가집니다.

#### 시그모이드 함수의 그래프

시그모이드 함수는 S자 형태의 곡선을 그리며, 매우 작은 값에서 0에 가까워지고, 매우 큰 값에서는 1에 가까워집니다.

![image](https://github.com/user-attachments/assets/c6860750-4f70-4613-b12e-08429a26bd74)


#### 시그모이드 함수의 장점과 단점

##### 장점:
- **출력 범위 제한**: 출력값이 0과 1 사이로 제한되어, 확률을 다룰 때 유용합니다.
- **미분 가능성**: 신경망에서 학습을 위해 필요한 미분이 가능합니다.

##### 단점:
- **기울기 소실 문제**: 입력값이 너무 크거나 작을 경우, 함수의 기울기가 거의 0에 가까워져 학습이 느려질 수 있습니다.
- **비대칭성**: 출력 값이 0과 1 사이로 제한되어 있기 때문에, 0을 기준으로 대칭적인 출력을 제공하는 다른 함수들이 더 적합한 경우도 있습니다.

#### 시그모이드 함수의 활용

- **신경망**: 시그모이드 함수는 초기 신경망에서 활성화 함수로 사용되었지만, 현재는 ReLU와 같은 다른 함수들이 더 널리 사용됩니다.
- **로지스틱 회귀**: 이진 분류 문제에서 출력 값을 확률로 해석하기 위해 시그모이드 함수가 사용됩니다.

---
## Adaline (Adaptive Linear Neuron) 설명

### 개요

Adaline (Adaptive Linear Neuron)은 선형 회귀와 비슷한 개념을 가진 인공 신경망 모델입니다. Adaline은 주로 **Gradient Descent** 알고리즘을 사용하여 모델을 훈련시킵니다. 이 모델은 **활성화 함수**로 **항등 함수 (Identity Function)**를 사용하며, 출력은 입력의 가중치와 바이어스의 선형 조합입니다.

Adaline은 **퍼셉트론**과 비슷하지만, 퍼셉트론은 이진 분류에서 **단계 함수 (Step Function)**를 사용하여 출력을 이진값(0 또는 1)으로 결정하는 반면, Adaline은 **연속적인 값을 출력**합니다. 또한, Adaline은 평균 제곱 오차(MSE)를 손실 함수로 사용하며, 이를 최소화하기 위해 경사 하강법(Gradient Descent)을 적용합니다.

### 수학적 모델

Adaline은 다음과 같은 수식으로 정의됩니다:

- **순 입력 (Net Input)**:  
  $
  \[
  z = w_1x_1 + w_2x_2 + \dots + w_nx_n + b
  \]
  $
  여기서 \(x_1, x_2, \dots, x_n\)은 입력 값, \(w_1, w_2, \dots, w_n\)은 가중치, \(b\)는 바이어스입니다.

- **출력 (Output)**:  
  Adaline은 활성화 함수로 항등 함수를 사용합니다. 즉, 출력 \(y\)는 순 입력 \(z\)와 동일합니다.  
  $
  \[
  y = z
  \]
  $
  
- **오차 (Error)**:  
  실제 값 \(t\)와 모델의 예측값 \(y\) 사이의 오차는 다음과 같이 계산됩니다:
  $
  \[
  e = t - y
  \]
  $
  
- **가중치 업데이트 (Weight Update)**:  
  가중치는 다음과 같은 규칙에 따라 업데이트됩니다:
  $
  \[
  w_i = w_i + \eta \cdot e \cdot x_i
  \]
  $
  여기서 \(\eta\)는 학습률(learning rate), \(e\)는 오차, \(x_i\)는 입력값입니다.

## 모델 훈련

Adaline은 **경사 하강법 (Gradient Descent)**을 이용하여 가중치와 바이어스를 업데이트합니다. 경사 하강법은 손실 함수(평균 제곱 오차, MSE)를 최소화하기 위해 가중치와 바이어스의 기울기를 계산하고 이를 따라 업데이트합니다.

### 학습 과정:
1. **초기화**: 가중치와 바이어스를 작은 임의의 값으로 초기화합니다.
2. **예측**: 훈련 데이터에 대해 예측값을 계산합니다.
3. **오차 계산**: 실제 값과 예측값의 차이를 구합니다.
4. **가중치 업데이트**: 경사 하강법을 사용하여 가중치와 바이어스를 업데이트합니다.
5. **손실 계산**: 오차의 제곱 평균을 계산하여 손실값을 추적합니다.
6. **반복**: 주어진 반복 횟수만큼 2-5단계를 반복합니다.

## 장점

- **단순성**: Adaline은 퍼셉트론보다 구현이 간단하고, 선형 회귀 모델에 기반하여 수학적으로 이해하기 쉬운 모델입니다.
- **연속적인 출력을 제공**: Adaline은 퍼셉트론처럼 0 또는 1로 분류하는 대신, 연속적인 값을 출력하므로 회귀 문제에도 유용하게 사용될 수 있습니다.

## 단점

- **선형 모델**: Adaline은 선형 모델이기 때문에, 비선형적인 데이터에 대해서는 성능이 좋지 않습니다.
- **오류 민감도**: 경사 하강법을 사용하기 때문에, 학습률(\(\eta\))이 너무 크면 발산할 수 있으며, 너무 작으면 수렴이 매우 느려질 수 있습니다.

## 결론

Adaline은 간단하고 직관적인 선형 모델로, 특히 선형적으로 분리 가능한 데이터를 다룰 때 유용합니다. 그러나 비선형 문제에 대해서는 퍼셉트론이나 다른 비선형 모델들이 더 적합합니다.

```
# 필요한 라이브러리 임포트
import numpy as np
import matplotlib.pyplot as plt 


# Adaline (Adaptive Linear Neuron) 모델 클래스 정의
class AdalineGD:
    # 모델 초기화
    def __init__(self, eta=0.01, n_iter=50, random_state=1):
        self.eta = eta  # 학습률 (step size)
        self.n_iter = n_iter  # 훈련할 반복 횟수
        self.random_state = random_state  # 랜덤 시드를 설정하여 재현 가능하도록 설정
    
    # 훈련 데이터를 기반으로 모델 학습
    # method self를 주는 이유 : 맴버 변수 생성하거나 접근하게 하려고 준다
    def fit(self, X, y): # X : 학습 데이터, y : 원래 답
        rgen = np.random.RandomState(self.random_state)  # 주어진 시드로 랜덤 넘버 생성기 초기화
        # 가중치(w_)를 작은 랜덤 값으로 초기화
        self.w_ = rgen.normal(
            loc=0.0 # 평균
            , scale=0.01 # 표준편차
            , size=X.shape[1] # 개수 지정 : X의 피처 개수만큼
        )  # 작은 값으로 초기화
        self.b_ = np.float_(0.)  # 바이어스(bias)는 0으로 초기화

        # 오차 저장 : 시각화
        self.losses_ = []  # 각 반복에서의 손실값을 저장할 리스트
        
        # 주어진 반복 횟수만큼 Gradient Descent 수행
        for i in range(self.n_iter):
            # 입력값 X와 가중치 w_의 내적 + 바이어스를 계산하여 순 입력 값 구하기
            net_input = self.net_input(X)
            # 순 입력 값에 활성화 함수 적용 (Adaline은 선형 활성화 함수)
            output = self.activation(net_input)
            # 실제 값(y)와 예측 값(output)의 오차 계산
            errors = (y - output)
            # 가중치 업데이트 (오차에 대한 기울기)
            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]
            # 바이어스 업데이트 (오차 평균에 대한 기울기)
            self.b_ += self.eta * 2.0 * errors.mean()
            # 손실값 계산 (평균 제곱 오차)
            loss = (errors ** 2).mean()
            self.losses_.append(loss)  # 손실값을 리스트에 저장
        
        return self  # 훈련된 모델 반환
    
    # 순 입력 계산 (X * 가중치 + 바이어스)
    def net_input(self, X):
        return np.dot(X, self.w_) + self.b_
    
    # 활성화 함수 (Adaline에서는 항등 함수, 즉 입력 그대로 반환)
    def activation(self, X):
        return X
    
    # 모델을 이용한 예측 함수
    def predict(self, X):
        # 예측값이 0 이상이면 1, 아니면 -1로 반환
        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)
```
