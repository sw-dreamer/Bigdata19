# 자전거 대여 수요 예측

[자전거 대여 수요 예측](https://www.kaggle.com/competitions/bike-sharing-demand)

```
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline


import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)


bike_df = pd.read_csv('./train.csv')
print(bike_df.shape)
bike_df.head(3)
```
![image](https://github.com/user-attachments/assets/d1222015-451f-428d-8416-e93c4e14bdd7)

```
bike_df.info()
```
![image](https://github.com/user-attachments/assets/b21552db-034d-44d2-99c3-fbb042e120cd)

```
# 문자열로 되어 있는 dataetime 피쳐 값을 datetime 타입으로 변환
# bike_df['datetime']=bike_df.datetime.apply(pd.to_datetime)
bike_df['datetime']=bike_df.datetime.apply(pd.to_datetime)

bike_df.info()
```
![image](https://github.com/user-attachments/assets/92bf13fc-cea4-43c0-b848-14c8b0e68386)

```
# year feature 새로 생성
bike_df['year']=bike_df.datetime.apply(lambda x:x.year)
bike_df.info()
```
![image](https://github.com/user-attachments/assets/0ec6f98f-94bc-4922-9373-71c965df66b4)

```
bike_df['year']
```
![image](https://github.com/user-attachments/assets/33251b7b-4cfd-4394-b5a2-4b21533aa945)

```
# month feature 새로 생성
bike_df['month']=bike_df.datetime.apply(lambda x:x.month)
# day feature 새로 생성
bike_df['day']=bike_df.datetime.apply(lambda x:x.day)
# hour feature 새로 생성
bike_df['hour']=bike_df.datetime.apply(lambda x:x.hour)
# minute feature 새로 생성
bike_df['minute']=bike_df.datetime.apply(lambda x:x.minute)
```

```
bike_df.head(20)
```
![image](https://github.com/user-attachments/assets/3f927b99-fd7f-48de-ac58-2d70cb64b85d)

```
# count = casual + registered 이므로 필요한 데이터가 아니다
drop_columns=['datetime','casual','registered','minute']
bike_df.drop(
    drop_columns
    ,axis=1
    ,inplace=True
)

bike_df.columns
```
![image](https://github.com/user-attachments/assets/2fdaa6ce-5add-41d6-980e-5be0e5562c5a)

```
# 피쳐의 분포 확인
cat_features=[
    'year'
    ,'month'
    ,'season'
    ,'weather'
    ,'day'
    ,'hour'
    ,'workingday'
    ,'holiday'
]

# 막대 그래프로 분포 확인
fig,axs=plt.subplots(
    figsize=(15,8)
    ,ncols=4
    ,nrows=2
)

for i, feature in enumerate(cat_features):
    row=int(i/4)
    col=i%4
    sns.barplot(
        data=bike_df
        ,x=feature
        ,y='count'
        ,ax=axs[row][col]
    )
    
plt.show()
```
![image](https://github.com/user-attachments/assets/313c5add-a1ac-4d71-9612-3e1b2cc61f05)

```
# label 또는 중요 feature가 정규 분포를 따르는지 확인을 해야한다
# 정규 분포를 따르지 않으면 모델의 성능이 저하 될 수 있다
# 따라서 데이터 전처리 과정에서 데이터 분포를 확인하고 정규 분포로 변환 작업이 필요하다
# ex) log 변환, 제곱근 변환 등 정규 분포 형태로 변환이 필요 할 수 있다
# 트리 기반 모델은 정규 분포를 따르지 않아도 성능 저하가 없을 수 있다
bike_df['count'].hist(bins=30)
plt.show()
```
![image](https://github.com/user-attachments/assets/00671770-99dd-431e-ab2e-736825812d42)

```
# 평가 지표 계산하는 함수 선언
def rmsle_(y,pred):
    log_y=np.log1p(y)
    log_pred=np.log1p(pred)
    
    squared_error=(log_y-log_pred)**2
    rmsle=np.sqrt(np.mean(squared_error))
    return rmsle

def rmse_(y,pred):
    from sklearn.metrics import mean_squared_error
    return np.sqrt(np.mean(mean_squared_error(y, pred)))

def evaluate_regr(y,pred):
    from sklearn.metrics import mean_absolute_error
    rmsle=rmsle_(y,pred)
    rmse=rmse_(y,pred)
    mae_val=mean_absolute_error(y,pred)
    print(f'RMSLE : {rmsle}, RMSE : {rmse}, MAE : {mae_val}')
```
```
# 전처리 없이 모델 생성하고 학습하고 평가
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.linear_model import LinearRegression,Ridge,Lasso

# 데이터와 레이블 분리
y_target=bike_df['count']
X_features=bike_df.drop(['count'],axis=1,inplace=False)

# 학습/테스트 분리
X_train,X_test,y_train,y_test=train_test_split(
    X_features
    ,y_target
    ,test_size=0.3
    ,random_state=0
)

# 모델 생성 : LinearRegression() : 단순 선형 회귀 모델(규제가 없다)
lr_reg=LinearRegression()

#학습
lr_reg.fit(X_train,y_train)

# 예측값 추출
pred=lr_reg.predict(X_test)

evaluate_regr(y_test,pred)
```
![image](https://github.com/user-attachments/assets/f1260eae-4eb0-4be0-8c06-8d3ed0738d9c)

```
# 실제 데이터로 위 오차가 왜 나왔는지 확인
print(f'y_test shape : {y_test.shape}')
print('='*100)
print(y_test[:10])
print('='*100)
print(pred[:10])
print('='*100)

ry_test = y_test[:10]
py_test = pred[:10]
diff_ = ry_test - py_test

print(f'실제 대여수: {ry_test}\n\n예측 대여수 : {py_test}\n\n 차이 : {diff_}')
```
```
y_test shape : (3266,)
====================================================================================================
6638     244
7975     239
5915     229
8050     467
5894     335
1466      40
10710    329
5138       2
1726     141
3943     391
Name: count, dtype: int64
====================================================================================================
[320.78637463 251.1873687  241.70971289 388.81803967 291.19455149
 258.94555635 298.59067233  62.04770396 260.3810481  166.45421786]
====================================================================================================
실제 대여수: 6638     244
7975     239
5915     229
8050     467
5894     335
1466      40
10710    329
5138       2
1726     141
3943     391
Name: count, dtype: int64

예측 대여수 : [320.78637463 251.1873687  241.70971289 388.81803967 291.19455149
 258.94555635 298.59067233  62.04770396 260.3810481  166.45421786]

 차이 : 6638     -76.786375
7975     -12.187369
5915     -12.709713
8050      78.181960
5894      43.805449
1466    -218.945556
10710     30.409328
5138     -60.047704
1726    -119.381048
3943     224.545782
Name: count, dtype: float64
```

```
# 오차 상위 n개 확인 함수 : 정렬 필요
def get_top_error_data(y_test,pred,n_tops=5):
    result_df=pd.DataFrame(
        y_test.values
        ,columns=['real_count']
    )
    result_df['predict_count']=np.round(pred)
    result_df['diff']=np.abs(result_df['real_count']-result_df['predict_count'])
    print(result_df.sort_values('diff',ascending=False)[:n_tops])

get_top_error_data(y_test,pred)
```
![image](https://github.com/user-attachments/assets/e7ea91ff-a71b-490f-bbf1-08701a4dc43b)

```
y_target.hist()
plt.show()
```
![image](https://github.com/user-attachments/assets/b28c6056-1c3f-42f0-a28c-abf9c05d742f)

```
y_log_transform=np.log1p(y_target)
y_log_transform.hist()
plt.show()
```
![image](https://github.com/user-attachments/assets/dc23c3fc-9f1b-4422-9ca8-e019e62282dd)

```
# 시각화 QQ plot, 정량화된 값을 확인 : shaprio value
from scipy import stats
stats.probplot(y_target,dist='norm',plot=plt) 
plt.title('y_target Q-Q plot')
plt.show()
```
![image](https://github.com/user-attachments/assets/6f8005e8-d4aa-470b-b28e-0023ae004b9a)

```
from scipy.stats import shapiro
stat,p=shapiro(y_target)

if p>0.05:
    print('정규분포를 따른다')
else:
    print(f'P-value : {p}, 정규 분포를 안따른다, 로그 반환 필요!!!')
```
![image](https://github.com/user-attachments/assets/56d98c53-e479-4844-aade-0e031b073a41)

```
# target log
y_target_log=np.log1p(y_target)

X_tr,X_tst,y_tr,y_tst=train_test_split(
    X_features
    ,y_target_log
    ,test_size=0.3
    ,random_state=0
)

lr_reg=LinearRegression()
lr_reg.fit(X_tr,y_tr)
pred=lr_reg.predict(X_tst)

# 예측 대여 대수 로그 값을 가지고 잇다 => 지수함수 사용
y_tst_exp=np.expm1(y_tst) # y_tst log변환 된걸 원래 대수로 변경
pred_exp=np.expm1(pred)

evaluate_regr(y_tst_exp,pred_exp)
```
![image](https://github.com/user-attachments/assets/fbf9a379-5d24-4351-8089-7f0957180f57)
